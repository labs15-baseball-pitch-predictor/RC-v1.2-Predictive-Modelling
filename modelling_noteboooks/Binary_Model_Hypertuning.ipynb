{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/RC-v1.2-Predictive-Modelling/modelling_noteboooks'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "#import psycopg2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "#import category_encoders as ce\n",
    "#from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitcher = 'Greinke'\n",
    "#pitcher = 'Scherzer'\n",
    "#pitcher = 'deGrom'\n",
    "pitcher = 'Bauer'\n",
    "\n",
    "path = '/home/ec2-user/SageMaker/RC-v1.2-Predictive-Modelling/pitcher_df_pickles/' + pitcher + '_df.pkl'\n",
    "\n",
    "df = pd.read_pickle(path, compression='zip').reset_index()\n",
    "\n",
    "#make binary fastball/not-fastball target feature:\n",
    "df['fastball_target'] = (df['pitch_cat'] == 'fastball') * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    cat_cols = df.select_dtypes('category').columns.tolist()\n",
    "    cat_cols.remove('at_bat_number')\n",
    "    cat_cols.remove('pitch_count')\n",
    "    cat_cols.remove('pitch_cat')\n",
    "    cat_cols.remove('player_name')\n",
    "    df = pd.get_dummies(df, columns=cat_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = one_hot_encode(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategic Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_ordinal_ecode(df):\n",
    "    df = df.copy()\n",
    "        \n",
    "    #description cols:\n",
    "    desc_map = {'called_strike':1,\n",
    "                'swinging_strike':2,\n",
    "                'foul_tip':3,\n",
    "                'foul':4,\n",
    "                'swinging_strike_blocked':5,\n",
    "                'foul_bunt':6,\n",
    "                'missed_bunt':6,\n",
    "                'bunt_foul_tip':6,\n",
    "                'N/A':7,\n",
    "                'pitchout':7,\n",
    "                'hit_into_play':8,\n",
    "                'ball':9,\n",
    "                'blocked_ball':10,\n",
    "                'hit_by_pitch':11,\n",
    "                'hit_into_play_no_out':12,\n",
    "                'hit_into_play_score':13}\n",
    "    \n",
    "    desc_cols = ['L1_description', 'L2_description', 'L3_description']\n",
    "    df[desc_cols] = df[desc_cols].replace(desc_map).astype('int')\n",
    "\n",
    "    #pitch_result cols\n",
    "    pitch_result_map = {'S':1, 'N/A':2, 'X':3, 'B':4}\n",
    "    result_cols = ['L1_pitch_result', 'L2_pitch_result']\n",
    "    df[result_cols] = df[result_cols].replace(pitch_result_map).astype('int')\n",
    "\n",
    "    #pitch_type cols\n",
    "    pitch_type_map = {'FA':1, 'FF':1, 'FT':2, 'FC':2, 'FS':2, 'SI':2, 'SF':2, 'N/A':2.5, 'SL':3,\n",
    "                      'CB':4, 'CU':4, 'SC':5, 'KC':5, 'CH':6, 'KN':7, 'EP':8, 'FO':9, 'PO':9}\n",
    "    pitch_type_cols = ['L1_pitch_type', 'L2_pitch_type', 'L3_pitch_type', 'pitch_type']\n",
    "    df[pitch_type_cols] = df[pitch_type_cols].replace(pitch_type_map).astype('float')\n",
    "\n",
    "    #count_cat\n",
    "    count_cat_map = {'ahead':1,'neutral':2, 'behind':3}\n",
    "    df['count_cat'] = df['count_cat'].replace(count_cat_map).astype('int')\n",
    "\n",
    "    #count\n",
    "    _count_map = {'02':1, '12':2, '01':3, '22':4, '11':5, '00':6, '21':7, '32':8, '10':9, '20':10, '31':11, '30':12}\n",
    "    df['_count'] = df['_count'].replace(_count_map).astype('int')\n",
    "\n",
    "    #for swung and chased, make unknown (-1) set to 0, and 0 (didnt swing/chase) set to -1:\n",
    "    swung_and_chased_cols = ['L1_batter_swung', 'L1_chased', 'L2_chased', 'L3_chased']\n",
    "\n",
    "    def swung_chase_edit(x):\n",
    "        if x == 0:\n",
    "            return -1\n",
    "        elif x == -1:\n",
    "            return 0\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    for col in swung_and_chased_cols:\n",
    "        df[col] = df[col].apply(swung_chase_edit)\n",
    "\n",
    "    #fill remaining misc categories to numerics:\n",
    "    misc_map = {'L':-1, 'R':2, 'Top':-1, 'Bot': 1, 'Standard':0, 'Infield shift': 1, 'Strategic':2, '4th outfielder':3}\n",
    "    df = df.replace(misc_map)\n",
    "\n",
    "    #clean up category dtypes to ints\n",
    "    df['year'] = df['year'].cat.codes\n",
    "    df['catcher_id'] = df['catcher_id'].cat.codes\n",
    "    \n",
    "    cat_cols = ['outs_when_up', 'inning', 'at_bat_number', 'pitch_number', 'balls', 'strikes', 'pitch_count', 'L1_pitch_zone', \n",
    "                'L1_batter_swung', 'L1_chased', 'L2_pitch_zone', 'L2_chased', 'L3_pitch_zone', 'L3_chased', 'batting_order_slot', \n",
    "                'month']\n",
    "    \n",
    "    df[cat_cols] = df[cat_cols].astype('int')\n",
    "    df[['stand', 'inning_topbot', 'if_fielding_alignment', 'of_fielding_alignment']] = df[['stand', 'inning_topbot', 'if_fielding_alignment', 'of_fielding_alignment']].astype('int')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = custom_ordinal_ecode(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.551578\n",
       "0    0.448422\n",
       "Name: fastball_target, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fastball_target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_date(df, train_fraction):\n",
    "    train_idx = int(len(df) * train_fraction)\n",
    "    train_end_date = df.loc[train_idx].game_date\n",
    "    train = df[df['game_date'] < train_end_date]\n",
    "    test = df[df['game_date'] >= train_end_date]\n",
    "    print('train shape: ' + str(train.shape))\n",
    "    print('test shape: '+ str(test.shape))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (5093, 93)\n",
      "test shape: (1024, 93)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split_by_date(df, .85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5093, 86), (1024, 86), (5093,), (1024,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target = 'pitch_cat'\n",
    "target = 'fastball_target'\n",
    "\n",
    "drop_cols = ['index', 'player_name', 'game_date', 'pitch_cat', 'pitcher', 'pitch_type', target]\n",
    "\n",
    "X = train.drop(columns=drop_cols)\n",
    "X_test = test.drop(columns=drop_cols)\n",
    "\n",
    "y = train[target]\n",
    "y_test = test[target]\n",
    "\n",
    "X.shape, X_test.shape, y.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Float columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols = ['fastball_perc_faced', 'fastball_chase_perc', 'fastball_bip_swung_perc', 'fastball_taken_strike_perc',\n",
    "              'fastball_est_woba', 'fastball_babip', 'fastball_iso_value', 'breaking_perc_faced', 'breaking_chase_perc',\n",
    "              'breaking_bip_swung_perc', 'breaking_taken_strike_perc', 'breaking_est_woba', 'breaking_babip',\n",
    "              'breaking_iso_value', 'offspeed_perc_faced', 'offspeed_chase_perc', 'offspeed_bip_swung_perc',\n",
    "              'offspeed_taken_strike_perc', 'offspeed_est_woba', 'offspeed_babip', 'offspeed_iso_value',\n",
    "              'pitchout_perc_faced', 'overall_fastball_perc', 'count_cat_fastball_perc', 'overall_breaking_perc',\n",
    "              'count_cat_breaking_perc', 'overall_offspeed_perc', 'count_cat_offspeed_perc', 'L5_fastball_perc',\n",
    "              'L15_fastball_perc', 'L5_breaking_perc', 'L15_breaking_perc', 'L5_offspeed_perc', 'L15_offspeed_perc',\n",
    "              'L5_strike_perc', 'L15_strike_perc', 'PB_fastball', 'PB_breaking', 'PB_offspeed']\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X[scale_cols] = scaler.fit_transform(X[scale_cols].values)\n",
    "\n",
    "X_test[scale_cols] = scaler.transform(X_test[scale_cols].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#with bootstrap:\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 75, 100, 125, 150, 200, 300],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 15, 25],\n",
    "    'min_samples_split': [5, 8, 12, 18, 25],\n",
    "    'min_samples_leaf': [3, 5, 7, 10],\n",
    "    'max_features': ['auto', 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'class_weight': [None],\n",
    "    'warm_start': [False, True],\n",
    "    'oob_score': [False, True]\n",
    "}\n",
    "\n",
    "rfc_with_bootstrap = RandomForestClassifier(n_jobs=-1, random_state=42, criterion='gini', bootstrap=True)\n",
    "\n",
    "# search = GridSearchCV(\n",
    "#     estimator = rfc, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=4,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True)\n",
    "\n",
    "rfc_with_bootstrap_search = RandomizedSearchCV(estimator=rfc_with_bootstrap, param_distributions=param_grid, n_iter=500, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "rfc_with_bootstrap_search.fit(X, y)\n",
    "\n",
    "rfc_bootstrap_search_results = pd.DataFrame(rfc_with_bootstrap_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_bootstrap_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#w/o bootstrap:\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 75, 100, 125, 150, 200, 300],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 15, 25],\n",
    "    'min_samples_split': [5, 8, 12, 18, 25],\n",
    "    'min_samples_leaf': [3, 5, 7, 10, 15, 25],\n",
    "    'max_features': ['auto', 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'class_weight': [None],\n",
    "    'warm_start': [False, True]\n",
    "}\n",
    "\n",
    "rfc_without_bootstrap = RandomForestClassifier(n_jobs=-1, random_state=42, criterion='gini', bootstrap=False)\n",
    "\n",
    "# search = GridSearchCV(\n",
    "#     estimator = rfc, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=2,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True)\n",
    "\n",
    "rfc_without_bootstrap_search = RandomizedSearchCV(estimator=rfc_without_bootstrap, param_distributions=param_grid, n_iter=500, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "rfc_without_bootstrap_search.fit(X, y)\n",
    "\n",
    "rfc_without_bootstrap_search_results = pd.DataFrame(rfc_without_bootstrap_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_without_bootstrap_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_models(search_results, model_type, n=10, k=100, accuracy_metric='accuracy'):\n",
    "    results_list = []\n",
    "    for i in range(k):\n",
    "        model_dict = {}\n",
    "        params = search_results.iloc[i]['params']\n",
    "        if model_type == 'rfc_bootstrap':\n",
    "            model = RandomForestClassifier(n_jobs=-1, random_state=42, criterion='gini', class_weight=params['class_weight'],\n",
    "                                 max_depth=params['max_depth'], max_features=params['max_features'], min_samples_leaf=params['min_samples_leaf'],\n",
    "                                 min_samples_split=params['min_samples_split'], n_estimators=params['n_estimators'], oob_score=params['oob_score'],\n",
    "                                 warm_start=params['warm_start'])\n",
    "        elif model_type == 'rfc_without_bootstrap':\n",
    "            model = RandomForestClassifier(n_jobs=-1, random_state=42, criterion='gini', class_weight=params['class_weight'],\n",
    "                                 max_depth=params['max_depth'], max_features=params['max_features'], min_samples_leaf=params['min_samples_leaf'],\n",
    "                                 min_samples_split=params['min_samples_split'], n_estimators=params['n_estimators'], warm_start=params['warm_start'])\n",
    "            \n",
    "        elif model_type == 'gbc':\n",
    "            model = GradientBoostingClassifier(random_state=42, loss=params['loss'], learning_rate=params['learning_rate'], n_estimators=params['n_estimators'],\n",
    "                                subsample=params['subsample'], min_samples_split=params['min_samples_split'], min_samples_leaf=params['min_samples_leaf'],\n",
    "                                max_depth=params['max_depth'], max_features=params['max_features'], tol=params['tol'])\n",
    "    \n",
    "        elif model_type == 'svm':\n",
    "            model = SVC(random_state=42, degree=params['degree'], kernel=params['kernel'], tol=params['tol'],\n",
    "                       C=params['C'], shrinking=params['shrinking'], class_weight=params['class_weight'], max_iter=params['max_iter'],\n",
    "                       decision_function_shape=params['decision_function_shape'], gamma=params['gamma'])\n",
    "        \n",
    "        elif model_type == 'lin_SVC':            \n",
    "            model = LinearSVC(random_state=42, penalty=params['penalty'], loss=params['loss'], dual=params['dual'], tol=params['tol'],\n",
    "                             C=params['C'], class_weight=params['class_weight'], max_iter=params['max_iter'], fit_intercept=params['fit_intercept'])\n",
    "            \n",
    "        elif model_type == 'sgd':\n",
    "            model = SGDClassifier(random_state=42, penalty=params['penalty'], alpha=params['alpha'], loss=params['loss'], tol=params['tol'],\n",
    "                                  class_weight=params['class_weight'], max_iter=params['max_iter'], fit_intercept=params['fit_intercept'],\n",
    "                                  warm_start=params['warm_start'], learning_rate=params['learning_rate'], shuffle=params['shuffle'])\n",
    "            \n",
    "        elif model_type == 'lda':\n",
    "            model = lda = LinearDiscriminantAnalysis(solver=params['solver'], shrinkage=params['shrinkage'], tol=params['tol'], \n",
    "                                                    n_components=params['n_components'])\n",
    "        \n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        try:\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        except:\n",
    "            roc_auc = 'N/A'\n",
    "            \n",
    "        model_dict['model'] = [model]\n",
    "        model_dict['accuracy'] = accuracy\n",
    "        model_dict['f1_score'] = f1\n",
    "        model_dict['r2_score'] = r2\n",
    "        model_dict['roc_auc_score'] = roc_auc\n",
    "        #convert the dict to df and append to list\n",
    "        results_list.append(pd.DataFrame(model_dict))\n",
    "    \n",
    "    #return df with the top n highest accuracy models (on the test data)\n",
    "    results_df = pd.concat(results_list, axis=0).sort_values(by=accuracy_metric, ascending=False).head(n)\n",
    "    results_df['model_type'] = results_df['model'].astype(str).apply(lambda x: x.split('(')[0]).reset_index(drop=True)    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top10_rfc_bootstrap = get_top_n_models(rfc_bootstrap_search_results, 'rfc_bootstrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top10_rfc_without_bootstrap = get_top_n_models(rfc_without_bootstrap_search_results, 'rfc_without_bootstrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_rfc_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_rfc_without_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def con_matrix_analysis(model, X, X_test, y, y_test):\n",
    "  \n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X_test)\n",
    "  \n",
    "    print(classification_report(y_test, y_pred, target_names=['Not Fastball', 'Fastball']))\n",
    "\n",
    "    con_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                              columns=['Predicted Not Fastball', 'Predicted Fastball'],\n",
    "                              index=['Actual Not Fastball', 'Actual Fastball'])\n",
    "                            \n",
    "    sns.heatmap(data=con_matrix, cmap='cool')\n",
    "    plt.show();\n",
    "    return con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_rfc_bootstrap.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_rfc_without_bootstrap.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "feature_names = train.drop(columns=drop_cols).columns.tolist()\n",
    "model.fit(X, y)\n",
    "estimator = model.estimators_[5]\n",
    "\n",
    "\n",
    "dot_data = export_graphviz(estimator, \n",
    "                out_file=None, #'tree.dot', \n",
    "                feature_names = feature_names,\n",
    "                class_names = ['Not Fastball', 'Fastball'],\n",
    "                rounded = True, proportion = True, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed: 31.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed: 38.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 39.6min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'loss' : ['deviance', 'exponential'],\n",
    "    'learning_rate': [0.03, 0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "    'n_estimators': [50, 100, 200, 400, 500, 800, 1500],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'min_samples_split': [5, 8, 12, 18, 25],\n",
    "    'min_samples_leaf': [3, 5, 7, 10, 15, 25],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 15, 25],\n",
    "    'max_features': ['auto','log2', 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'tol': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# gbc_search = GridSearchCV(\n",
    "#     estimator = gbc, \n",
    "#     param_grid = param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=4,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "gbc_search = RandomizedSearchCV(estimator=gbc, param_distributions=param_grid, n_iter=400, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "gbc_search.fit(X, y)\n",
    "\n",
    "gbc_search_results = pd.DataFrame(gbc_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1.161283</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.040562</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>deviance</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'tol': 0.0001, 'subsample': 0.6, 'n_estimator...</td>\n",
       "      <td>0.689635</td>\n",
       "      <td>0.709069</td>\n",
       "      <td>0.665881</td>\n",
       "      <td>0.688199</td>\n",
       "      <td>0.017660</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703387</td>\n",
       "      <td>0.700736</td>\n",
       "      <td>0.718198</td>\n",
       "      <td>0.707441</td>\n",
       "      <td>0.007683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1.021592</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.035895</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'tol': 0.001, 'subsample': 0.6, 'n_estimators...</td>\n",
       "      <td>0.694346</td>\n",
       "      <td>0.702002</td>\n",
       "      <td>0.667649</td>\n",
       "      <td>0.688003</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2</td>\n",
       "      <td>0.722533</td>\n",
       "      <td>0.713108</td>\n",
       "      <td>0.737044</td>\n",
       "      <td>0.724228</td>\n",
       "      <td>0.009845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>5.716853</td>\n",
       "      <td>0.024134</td>\n",
       "      <td>0.059204</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>800</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>deviance</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>{'tol': 0.0001, 'subsample': 0.5, 'n_estimator...</td>\n",
       "      <td>0.697880</td>\n",
       "      <td>0.705536</td>\n",
       "      <td>0.657042</td>\n",
       "      <td>0.686825</td>\n",
       "      <td>0.021284</td>\n",
       "      <td>3</td>\n",
       "      <td>0.696318</td>\n",
       "      <td>0.688365</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>0.698114</td>\n",
       "      <td>0.008785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.333057</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>deviance</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'tol': 0.001, 'subsample': 0.5, 'n_estimators...</td>\n",
       "      <td>0.678445</td>\n",
       "      <td>0.707303</td>\n",
       "      <td>0.671184</td>\n",
       "      <td>0.685647</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>4</td>\n",
       "      <td>0.704860</td>\n",
       "      <td>0.699264</td>\n",
       "      <td>0.719965</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.008743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.002260</td>\n",
       "      <td>0.100121</td>\n",
       "      <td>0.121220</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>800</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'tol': 0.0001, 'subsample': 0.5, 'n_estimator...</td>\n",
       "      <td>0.694346</td>\n",
       "      <td>0.689046</td>\n",
       "      <td>0.664113</td>\n",
       "      <td>0.682505</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>5</td>\n",
       "      <td>0.803535</td>\n",
       "      <td>0.782032</td>\n",
       "      <td>0.792108</td>\n",
       "      <td>0.792558</td>\n",
       "      <td>0.008784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_tol  \\\n",
       "204       1.161283      0.002471         0.040562        0.000385    0.0001   \n",
       "389       1.021592      0.001169         0.035895        0.000465     0.001   \n",
       "358       5.716853      0.024134         0.059204        0.000201    0.0001   \n",
       "352       0.333057      0.000813         0.028583        0.000576     0.001   \n",
       "19       10.002260      0.100121         0.121220        0.004857    0.0001   \n",
       "\n",
       "    param_subsample param_n_estimators param_min_samples_split  \\\n",
       "204             0.6                400                      18   \n",
       "389             0.6                200                      25   \n",
       "358             0.5                800                      12   \n",
       "352             0.5                100                      25   \n",
       "19              0.5                800                      25   \n",
       "\n",
       "    param_min_samples_leaf param_max_features param_max_depth   param_loss  \\\n",
       "204                     10               log2               2     deviance   \n",
       "389                     10               log2               4  exponential   \n",
       "358                     25                0.6               2     deviance   \n",
       "352                      3               log2               2     deviance   \n",
       "19                      15               log2              25  exponential   \n",
       "\n",
       "    param_learning_rate                                             params  \\\n",
       "204               0.005  {'tol': 0.0001, 'subsample': 0.6, 'n_estimator...   \n",
       "389               0.005  {'tol': 0.001, 'subsample': 0.6, 'n_estimators...   \n",
       "358              0.0005  {'tol': 0.0001, 'subsample': 0.5, 'n_estimator...   \n",
       "352                0.03  {'tol': 0.001, 'subsample': 0.5, 'n_estimators...   \n",
       "19                0.001  {'tol': 0.0001, 'subsample': 0.5, 'n_estimator...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "204           0.689635           0.709069           0.665881         0.688199   \n",
       "389           0.694346           0.702002           0.667649         0.688003   \n",
       "358           0.697880           0.705536           0.657042         0.686825   \n",
       "352           0.678445           0.707303           0.671184         0.685647   \n",
       "19            0.694346           0.689046           0.664113         0.682505   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "204        0.017660                1            0.703387            0.700736   \n",
       "389        0.014724                2            0.722533            0.713108   \n",
       "358        0.021284                3            0.696318            0.688365   \n",
       "352        0.015599                4            0.704860            0.699264   \n",
       "19         0.013180                5            0.803535            0.782032   \n",
       "\n",
       "     split2_train_score  mean_train_score  std_train_score  \n",
       "204            0.718198          0.707441         0.007683  \n",
       "389            0.737044          0.724228         0.009845  \n",
       "358            0.709658          0.698114         0.008785  \n",
       "352            0.719965          0.708029         0.008743  \n",
       "19             0.792108          0.792558         0.008784  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 3.56 ms, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_gbc = get_top_n_models(gbc_search_results, 'gbc', k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.688477</td>\n",
       "      <td>0.724287</td>\n",
       "      <td>-0.263445</td>\n",
       "      <td>0.749134</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.686523</td>\n",
       "      <td>0.730930</td>\n",
       "      <td>-0.271366</td>\n",
       "      <td>0.743011</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.686523</td>\n",
       "      <td>0.731381</td>\n",
       "      <td>-0.271366</td>\n",
       "      <td>0.745405</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.686523</td>\n",
       "      <td>0.734051</td>\n",
       "      <td>-0.271366</td>\n",
       "      <td>0.747865</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.686523</td>\n",
       "      <td>0.723514</td>\n",
       "      <td>-0.271366</td>\n",
       "      <td>0.741162</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.684570</td>\n",
       "      <td>0.725106</td>\n",
       "      <td>-0.279287</td>\n",
       "      <td>0.741189</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.721170</td>\n",
       "      <td>-0.283248</td>\n",
       "      <td>0.749946</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>0.750576</td>\n",
       "      <td>-0.287208</td>\n",
       "      <td>0.737741</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>0.721985</td>\n",
       "      <td>-0.287208</td>\n",
       "      <td>0.750514</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>0.750576</td>\n",
       "      <td>-0.287208</td>\n",
       "      <td>0.717760</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy  f1_score  \\\n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...  0.688477  0.724287   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...  0.686523  0.730930   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...  0.686523  0.731381   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...  0.686523  0.734051   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...  0.686523  0.723514   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...  0.684570  0.725106   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...  0.683594  0.721170   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...  0.682617  0.750576   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...  0.682617  0.721985   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...  0.682617  0.750576   \n",
       "\n",
       "   r2_score  roc_auc_score                  model_type  \n",
       "0 -0.263445       0.749134  GradientBoostingClassifier  \n",
       "0 -0.271366       0.743011  GradientBoostingClassifier  \n",
       "0 -0.271366       0.745405  GradientBoostingClassifier  \n",
       "0 -0.271366       0.747865  GradientBoostingClassifier  \n",
       "0 -0.271366       0.741162  GradientBoostingClassifier  \n",
       "0 -0.279287       0.741189  GradientBoostingClassifier  \n",
       "0 -0.283248       0.749946  GradientBoostingClassifier  \n",
       "0 -0.287208       0.737741  GradientBoostingClassifier  \n",
       "0 -0.287208       0.750514  GradientBoostingClassifier  \n",
       "0 -0.287208       0.717760  GradientBoostingClassifier  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Fastball       0.65      0.63      0.64       452\n",
      "    Fastball       0.72      0.73      0.72       572\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      1024\n",
      "   macro avg       0.68      0.68      0.68      1024\n",
      "weighted avg       0.69      0.69      0.69      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Not Fastball</th>\n",
       "      <th>Predicted Fastball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Not Fastball</th>\n",
       "      <td>286</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Fastball</th>\n",
       "      <td>153</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Predicted Not Fastball  Predicted Fastball\n",
       "Actual Not Fastball                     286                 166\n",
       "Actual Fastball                         153                 419"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_gbc.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_accuracy_metrics(model, X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 hot encode instead of label encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum = 0\n",
    "# for col in cat_cols:\n",
    "#     sum += df[col].nunique()\n",
    "#     print(col + ': ' + str(df[col].nunique()))\n",
    "    \n",
    "# print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_cols = set(cat_cols) - set(['index', 'player_name', 'game_date', 'pitch_cat', 'pitcher', 'pitch_type', 'fastball_target'])\n",
    "\n",
    "# one_hot_df = pd.get_dummies(df, prefix_sep='_',columns=one_hot_cols)\n",
    "\n",
    "# train, test = train_test_split_by_date(one_hot_df, .9)\n",
    "\n",
    "# #target = 'pitch_cat'\n",
    "# target = 'fastball_target'\n",
    "\n",
    "# drop_cols = ['index', 'player_name', 'game_date', 'pitch_cat', 'pitcher', 'pitch_type', target]\n",
    "\n",
    "# X = train.drop(columns=drop_cols)\n",
    "# X_test = test.drop(columns=drop_cols)\n",
    "\n",
    "# y = train[target]\n",
    "# y_test = test[target]\n",
    "\n",
    "# X.shape, X_test.shape, y.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #scale the float cols:\n",
    "# scale_cols = ['fastball_perc_faced', 'fastball_chase_perc', 'fastball_bip_swung_perc', 'fastball_taken_strike_perc',\n",
    "#               'fastball_est_woba', 'fastball_babip', 'fastball_iso_value', 'breaking_perc_faced', 'breaking_chase_perc',\n",
    "#               'breaking_bip_swung_perc', 'breaking_taken_strike_perc', 'breaking_est_woba', 'breaking_babip',\n",
    "#               'breaking_iso_value', 'offspeed_perc_faced', 'offspeed_chase_perc', 'offspeed_bip_swung_perc',\n",
    "#               'offspeed_taken_strike_perc', 'offspeed_est_woba', 'offspeed_babip', 'offspeed_iso_value',\n",
    "#               'pitchout_perc_faced', 'overall_fastball_perc', 'count_cat_fastball_perc', 'overall_breaking_perc',\n",
    "#               'count_cat_breaking_perc', 'overall_offspeed_perc', 'count_cat_offspeed_perc', 'L5_fastball_perc',\n",
    "#               'L15_fastball_perc', 'L5_breaking_perc', 'L15_breaking_perc', 'L5_offspeed_perc', 'L15_offspeed_perc',\n",
    "#               'L5_strike_perc', 'L15_strike_perc', 'PB_fastball', 'PB_breaking', 'PB_offspeed']\n",
    "\n",
    "# scaler = RobustScaler()\n",
    "# X[scale_cols] = scaler.fit_transform(X[scale_cols].values)\n",
    "# X_test[scale_cols] = scaler.transform(X_test[scale_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:   56.4s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]CPU times: user 25.3 s, sys: 406 ms, total: 25.7 s\n",
      "Wall time: 2min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {\n",
    "    'degree': [2,3,4],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'tol': [0.0001, 0.00001],\n",
    "    'C': [0.2, 0.5, 1.0, 2.0, 3.5, 5.0],\n",
    "    'shrinking': [True, False],\n",
    "    'class_weight': [None],\n",
    "    'max_iter': [100, 250, 400, 700, 1200, 2000, 3500],\n",
    "    'decision_function_shape': ['ovo', 'ovr'],\n",
    "    'gamma': ['auto', 'scale']\n",
    "}\n",
    "\n",
    "svm = SVC(random_state=42, verbose=50)\n",
    "\n",
    "# svm_search = GridSearchCV(\n",
    "#     estimator = svm, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=3,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "svm_search = RandomizedSearchCV(estimator=svm, param_distributions=param_grid, n_iter=400, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "svm_search.fit(X, y)\n",
    "\n",
    "svm_search_results = pd.DataFrame(svm_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_shrinking</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_decision_function_shape</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2.090760</td>\n",
       "      <td>0.008779</td>\n",
       "      <td>1.016709</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>3500</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'tol': 0.0001, 'shrinking': False, 'max_iter'...</td>\n",
       "      <td>0.656655</td>\n",
       "      <td>0.671967</td>\n",
       "      <td>0.643489</td>\n",
       "      <td>0.657373</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889249</td>\n",
       "      <td>0.883652</td>\n",
       "      <td>0.886926</td>\n",
       "      <td>0.886609</td>\n",
       "      <td>0.002296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2.154621</td>\n",
       "      <td>0.029501</td>\n",
       "      <td>1.004853</td>\n",
       "      <td>0.017606</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>3500</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>ovo</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'tol': 1e-05, 'shrinking': True, 'max_iter': ...</td>\n",
       "      <td>0.656655</td>\n",
       "      <td>0.671967</td>\n",
       "      <td>0.643489</td>\n",
       "      <td>0.657373</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889249</td>\n",
       "      <td>0.883652</td>\n",
       "      <td>0.886926</td>\n",
       "      <td>0.886609</td>\n",
       "      <td>0.002296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2.131941</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>1.004246</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>3500</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>ovo</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'tol': 0.0001, 'shrinking': False, 'max_iter'...</td>\n",
       "      <td>0.656655</td>\n",
       "      <td>0.671967</td>\n",
       "      <td>0.643489</td>\n",
       "      <td>0.657373</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889249</td>\n",
       "      <td>0.883652</td>\n",
       "      <td>0.886926</td>\n",
       "      <td>0.886609</td>\n",
       "      <td>0.002296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2.030257</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.994260</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>2000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'tol': 0.0001, 'shrinking': True, 'max_iter':...</td>\n",
       "      <td>0.656655</td>\n",
       "      <td>0.671378</td>\n",
       "      <td>0.643489</td>\n",
       "      <td>0.657177</td>\n",
       "      <td>0.011391</td>\n",
       "      <td>4</td>\n",
       "      <td>0.888954</td>\n",
       "      <td>0.883652</td>\n",
       "      <td>0.886926</td>\n",
       "      <td>0.886511</td>\n",
       "      <td>0.002184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.026982</td>\n",
       "      <td>0.030309</td>\n",
       "      <td>1.004997</td>\n",
       "      <td>0.009097</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>2000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'tol': 0.0001, 'shrinking': False, 'max_iter'...</td>\n",
       "      <td>0.656655</td>\n",
       "      <td>0.671378</td>\n",
       "      <td>0.643489</td>\n",
       "      <td>0.657177</td>\n",
       "      <td>0.011391</td>\n",
       "      <td>4</td>\n",
       "      <td>0.888954</td>\n",
       "      <td>0.883652</td>\n",
       "      <td>0.886926</td>\n",
       "      <td>0.886511</td>\n",
       "      <td>0.002184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_tol  \\\n",
       "139       2.090760      0.008779         1.016709        0.004015    0.0001   \n",
       "217       2.154621      0.029501         1.004853        0.017606     1e-05   \n",
       "103       2.131941      0.024480         1.004246        0.003522    0.0001   \n",
       "104       2.030257      0.002060         0.994260        0.006734    0.0001   \n",
       "16        2.026982      0.030309         1.004997        0.009097    0.0001   \n",
       "\n",
       "    param_shrinking param_max_iter param_kernel param_gamma param_degree  \\\n",
       "139           False           3500          rbf        auto            2   \n",
       "217            True           3500          rbf        auto            3   \n",
       "103           False           3500          rbf        auto            3   \n",
       "104            True           2000          rbf        auto            3   \n",
       "16            False           2000          rbf        auto            4   \n",
       "\n",
       "    param_decision_function_shape param_class_weight param_C  \\\n",
       "139                           ovr               None     0.5   \n",
       "217                           ovo               None     0.5   \n",
       "103                           ovo               None     0.5   \n",
       "104                           ovr               None     0.5   \n",
       "16                            ovr               None     0.5   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "139  {'tol': 0.0001, 'shrinking': False, 'max_iter'...           0.656655   \n",
       "217  {'tol': 1e-05, 'shrinking': True, 'max_iter': ...           0.656655   \n",
       "103  {'tol': 0.0001, 'shrinking': False, 'max_iter'...           0.656655   \n",
       "104  {'tol': 0.0001, 'shrinking': True, 'max_iter':...           0.656655   \n",
       "16   {'tol': 0.0001, 'shrinking': False, 'max_iter'...           0.656655   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "139           0.671967           0.643489         0.657373        0.011637   \n",
       "217           0.671967           0.643489         0.657373        0.011637   \n",
       "103           0.671967           0.643489         0.657373        0.011637   \n",
       "104           0.671378           0.643489         0.657177        0.011391   \n",
       "16            0.671378           0.643489         0.657177        0.011391   \n",
       "\n",
       "     rank_test_score  split0_train_score  split1_train_score  \\\n",
       "139                1            0.889249            0.883652   \n",
       "217                1            0.889249            0.883652   \n",
       "103                1            0.889249            0.883652   \n",
       "104                4            0.888954            0.883652   \n",
       "16                 4            0.888954            0.883652   \n",
       "\n",
       "     split2_train_score  mean_train_score  std_train_score  \n",
       "139            0.886926          0.886609         0.002296  \n",
       "217            0.886926          0.886609         0.002296  \n",
       "103            0.886926          0.886609         0.002296  \n",
       "104            0.886926          0.886511         0.002184  \n",
       "16             0.886926          0.886511         0.002184  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 703 ms, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_svm = get_top_n_models(svm_search_results, 'svm', k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Fastball       0.73      0.28      0.41       452\n",
      "    Fastball       0.62      0.92      0.74       572\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      1024\n",
      "   macro avg       0.67      0.60      0.57      1024\n",
      "weighted avg       0.67      0.64      0.59      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Not Fastball</th>\n",
       "      <th>Predicted Fastball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Not Fastball</th>\n",
       "      <td>127</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Fastball</th>\n",
       "      <td>48</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Predicted Not Fastball  Predicted Fastball\n",
       "Actual Not Fastball                     127                 325\n",
       "Actual Fastball                          48                 524"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_svm.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 252 candidates, totalling 1008 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1999s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1967s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 273 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 346 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 400 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 429 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done 458 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done 489 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done 553 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 586 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=-1)]: Done 621 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 693 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 730 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done 769 tasks      | elapsed:   57.1s\n",
      "[Parallel(n_jobs=-1)]: Done 808 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 849 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 890 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 933 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]CPU times: user 18.6 s, sys: 370 ms, total: 18.9 s\n",
      "Wall time: 1min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1008 out of 1008 | elapsed:  1.3min finished\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#L1 Regularization\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1'],\n",
    "    'loss': ['squared_hinge'],\n",
    "    'dual': [False],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    'C': [0.2, 0.5, 1.0, 2.0, 3.5, 5.0],\n",
    "    'class_weight': [None],# 'balanced'\n",
    "    'max_iter': [50, 100, 250, 400, 700, 1200, 2000],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "l1_LinSVC = LinearSVC(random_state=42, verbose=50)\n",
    "\n",
    "l1_LinSVC_search = GridSearchCV(\n",
    "    estimator = l1_LinSVC, \n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=4,\n",
    "    verbose=10,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# l1_LinSVC_search = RandomizedSearchCV(estimator=svm, param_distributions=param_grid, n_iter=500, \n",
    "#                             scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=4, verbose=10, \n",
    "#                             random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "\n",
    "l1_LinSVC_search.fit(X, y)\n",
    "l1_LinSVC_search_results = pd.DataFrame(l1_LinSVC_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.231764</td>\n",
       "      <td>0.052845</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.671115</td>\n",
       "      <td>0.713501</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>0.691930</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724535</td>\n",
       "      <td>0.717203</td>\n",
       "      <td>0.723822</td>\n",
       "      <td>0.730437</td>\n",
       "      <td>0.723999</td>\n",
       "      <td>0.004689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.227844</td>\n",
       "      <td>0.047671</td>\n",
       "      <td>0.017139</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.671115</td>\n",
       "      <td>0.713501</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>0.691930</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724535</td>\n",
       "      <td>0.717203</td>\n",
       "      <td>0.723822</td>\n",
       "      <td>0.730437</td>\n",
       "      <td>0.723999</td>\n",
       "      <td>0.004689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.015375</td>\n",
       "      <td>0.017990</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>l1</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.671115</td>\n",
       "      <td>0.712716</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.697327</td>\n",
       "      <td>0.691145</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>3</td>\n",
       "      <td>0.722964</td>\n",
       "      <td>0.718775</td>\n",
       "      <td>0.723822</td>\n",
       "      <td>0.729914</td>\n",
       "      <td>0.723869</td>\n",
       "      <td>0.003978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.166297</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.671115</td>\n",
       "      <td>0.712716</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.697327</td>\n",
       "      <td>0.691145</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>3</td>\n",
       "      <td>0.722964</td>\n",
       "      <td>0.718775</td>\n",
       "      <td>0.723822</td>\n",
       "      <td>0.729914</td>\n",
       "      <td>0.723869</td>\n",
       "      <td>0.003978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.422454</td>\n",
       "      <td>0.168813</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>250</td>\n",
       "      <td>l1</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.663265</td>\n",
       "      <td>0.715071</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.700472</td>\n",
       "      <td>0.690556</td>\n",
       "      <td>0.019337</td>\n",
       "      <td>5</td>\n",
       "      <td>0.725844</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.723822</td>\n",
       "      <td>0.729914</td>\n",
       "      <td>0.724720</td>\n",
       "      <td>0.003822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "25       0.231764      0.052845         0.017044        0.000078     0.2   \n",
       "24       0.227844      0.047671         0.017139        0.000800     0.2   \n",
       "22       0.162320      0.015375         0.017990        0.000219     0.2   \n",
       "21       0.166297      0.015626         0.017467        0.000422     0.2   \n",
       "28       0.422454      0.168813         0.017061        0.000789     0.2   \n",
       "\n",
       "   param_class_weight param_dual param_fit_intercept     param_loss  \\\n",
       "25               None      False               False  squared_hinge   \n",
       "24               None      False               False  squared_hinge   \n",
       "22               None      False               False  squared_hinge   \n",
       "21               None      False               False  squared_hinge   \n",
       "28               None      False               False  squared_hinge   \n",
       "\n",
       "   param_max_iter param_penalty param_tol  \\\n",
       "25            100            l1     5e-05   \n",
       "24            100            l1    0.0001   \n",
       "22             50            l1     5e-05   \n",
       "21             50            l1    0.0001   \n",
       "28            250            l1     5e-05   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "25  {'C': 0.2, 'class_weight': None, 'dual': False...           0.671115   \n",
       "24  {'C': 0.2, 'class_weight': None, 'dual': False...           0.671115   \n",
       "22  {'C': 0.2, 'class_weight': None, 'dual': False...           0.671115   \n",
       "21  {'C': 0.2, 'class_weight': None, 'dual': False...           0.671115   \n",
       "28  {'C': 0.2, 'class_weight': None, 'dual': False...           0.663265   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "25           0.713501           0.683425           0.699686         0.691930   \n",
       "24           0.713501           0.683425           0.699686         0.691930   \n",
       "22           0.712716           0.683425           0.697327         0.691145   \n",
       "21           0.712716           0.683425           0.697327         0.691145   \n",
       "28           0.715071           0.683425           0.700472         0.690556   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "25        0.016059                1            0.724535            0.717203   \n",
       "24        0.016059                1            0.724535            0.717203   \n",
       "22        0.015531                3            0.722964            0.718775   \n",
       "21        0.015531                3            0.722964            0.718775   \n",
       "28        0.019337                5            0.725844            0.719298   \n",
       "\n",
       "    split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "25            0.723822            0.730437          0.723999         0.004689  \n",
       "24            0.723822            0.730437          0.723999         0.004689  \n",
       "22            0.723822            0.729914          0.723869         0.003978  \n",
       "21            0.723822            0.729914          0.723869         0.003978  \n",
       "28            0.723822            0.729914          0.724720         0.003822  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_LinSVC_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 3.18 s, total: 1min 8s\n",
      "Wall time: 9.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_l1_LinSVC = get_top_n_models(l1_LinSVC_search_results, 'lin_SVC', k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Fastball       0.66      0.60      0.63       452\n",
      "    Fastball       0.70      0.75      0.73       572\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1024\n",
      "   macro avg       0.68      0.68      0.68      1024\n",
      "weighted avg       0.68      0.68      0.68      1024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Not Fastball</th>\n",
       "      <th>Predicted Fastball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Not Fastball</th>\n",
       "      <td>272</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Fastball</th>\n",
       "      <td>143</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Predicted Not Fastball  Predicted Fastball\n",
       "Actual Not Fastball                     272                 180\n",
       "Actual Fastball                         143                 429"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_l1_LinSVC.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 432 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1810s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1127s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 267 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 315 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 340 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 367 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 394 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 423 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 452 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 483 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done 514 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 547 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done 580 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 615 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 650 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 687 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 724 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done 763 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 802 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=-1)]: Done 843 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=-1)]: Done 884 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done 927 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 970 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1015 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1060 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1107 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1154 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1203 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1252 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1303 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1354 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1407 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1460 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1515 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1570 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1627 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1684 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Fitting 4 folds for each of 216 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1945s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1201s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 267 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 315 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 340 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 367 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 394 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 423 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=-1)]: Done 452 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 483 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 514 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done 547 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done 580 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 615 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done 650 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-1)]: Done 687 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Done 724 tasks      | elapsed:   58.0s\n",
      "[Parallel(n_jobs=-1)]: Done 763 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 802 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]CPU times: user 48.3 s, sys: 869 ms, total: 49.2 s\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#L2 Regularization\n",
    "\n",
    "#The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l2'],#, 'l1'],\n",
    "    'loss': ['squared_hinge'],# 'hinge'],\n",
    "    'dual': [True, False],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    'C': [0.2, 0.5, 1.0, 2.0, 3.5, 5.0],\n",
    "    'class_weight': [None], # 'balanced'\n",
    "    'max_iter': [50, 100, 250, 400, 700, 1200],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "l2_LinSVC = LinearSVC(random_state=42, verbose=50)\n",
    "\n",
    "l2_LinSVC_search_A = GridSearchCV(\n",
    "    estimator = l2_LinSVC, \n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=4,\n",
    "    verbose=10,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "l2_LinSVC_search_A.fit(X, y)\n",
    "l2_LinSVC_search_results_A = pd.DataFrame(l2_LinSVC_search_A.cv_results_).sort_values(by='rank_test_score')\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l2'],\n",
    "    'loss': ['hinge'],\n",
    "    'dual': [True],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    'C': [0.2, 0.5, 1.0, 2.0, 3.5, 5.0],\n",
    "    'class_weight': [None], # 'balanced'\n",
    "    'max_iter': [50, 100, 250, 400, 700, 1200],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "l2_LinSVC_search_B = GridSearchCV(\n",
    "    estimator = l2_LinSVC, \n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=4,\n",
    "    verbose=10,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "l2_LinSVC_search_B.fit(X, y)\n",
    "l2_LinSVC_search_results_B = pd.DataFrame(l2_LinSVC_search_B.cv_results_).sort_values(by='rank_test_score')\n",
    "\n",
    "\n",
    "l2_LinSVC_search_results = pd.concat([l2_LinSVC_search_results_A, l2_LinSVC_search_results_B]).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.108096</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1200</td>\n",
       "      <td>l2</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.679749</td>\n",
       "      <td>0.718995</td>\n",
       "      <td>0.676355</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.693501</td>\n",
       "      <td>0.017049</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709610</td>\n",
       "      <td>0.698874</td>\n",
       "      <td>0.712565</td>\n",
       "      <td>0.730175</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.011248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.869922</td>\n",
       "      <td>0.022952</td>\n",
       "      <td>0.019161</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>hinge</td>\n",
       "      <td>700</td>\n",
       "      <td>l2</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>{'C': 0.5, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.550235</td>\n",
       "      <td>0.550235</td>\n",
       "      <td>0.549882</td>\n",
       "      <td>0.550314</td>\n",
       "      <td>0.550167</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550144</td>\n",
       "      <td>0.550144</td>\n",
       "      <td>0.550262</td>\n",
       "      <td>0.550118</td>\n",
       "      <td>0.550167</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.823070</td>\n",
       "      <td>0.017720</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>700</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.550235</td>\n",
       "      <td>0.550235</td>\n",
       "      <td>0.549882</td>\n",
       "      <td>0.550314</td>\n",
       "      <td>0.550167</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550144</td>\n",
       "      <td>0.550144</td>\n",
       "      <td>0.550262</td>\n",
       "      <td>0.550118</td>\n",
       "      <td>0.550167</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.858548</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>0.018656</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>hinge</td>\n",
       "      <td>700</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 0.5, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.550235</td>\n",
       "      <td>0.550235</td>\n",
       "      <td>0.549882</td>\n",
       "      <td>0.550314</td>\n",
       "      <td>0.550167</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550144</td>\n",
       "      <td>0.550144</td>\n",
       "      <td>0.550262</td>\n",
       "      <td>0.550118</td>\n",
       "      <td>0.550167</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.798267</td>\n",
       "      <td>0.018306</td>\n",
       "      <td>0.018653</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>700</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.550235</td>\n",
       "      <td>0.550235</td>\n",
       "      <td>0.549882</td>\n",
       "      <td>0.550314</td>\n",
       "      <td>0.550167</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550144</td>\n",
       "      <td>0.550144</td>\n",
       "      <td>0.550262</td>\n",
       "      <td>0.550118</td>\n",
       "      <td>0.550167</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "215       0.108096      0.020599         0.010368        0.000589       1   \n",
       "49        1.869922      0.022952         0.019161        0.000430     0.5   \n",
       "30        1.823070      0.017720         0.018605        0.000242     0.2   \n",
       "48        1.858548      0.015985         0.018656        0.000238     0.5   \n",
       "102       1.798267      0.018306         0.018653        0.000217       1   \n",
       "\n",
       "    param_class_weight param_dual param_fit_intercept     param_loss  \\\n",
       "215               None      False               False  squared_hinge   \n",
       "49                None       True                True          hinge   \n",
       "30                None       True               False          hinge   \n",
       "48                None       True                True          hinge   \n",
       "102               None       True               False          hinge   \n",
       "\n",
       "    param_max_iter param_penalty param_tol  \\\n",
       "215           1200            l2     1e-05   \n",
       "49             700            l2     5e-05   \n",
       "30             700            l2    0.0001   \n",
       "48             700            l2    0.0001   \n",
       "102            700            l2    0.0001   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "215  {'C': 1.0, 'class_weight': None, 'dual': False...           0.679749   \n",
       "49   {'C': 0.5, 'class_weight': None, 'dual': True,...           0.550235   \n",
       "30   {'C': 0.2, 'class_weight': None, 'dual': True,...           0.550235   \n",
       "48   {'C': 0.5, 'class_weight': None, 'dual': True,...           0.550235   \n",
       "102  {'C': 1.0, 'class_weight': None, 'dual': True,...           0.550235   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "215           0.718995           0.676355           0.698899         0.693501   \n",
       "49            0.550235           0.549882           0.550314         0.550167   \n",
       "30            0.550235           0.549882           0.550314         0.550167   \n",
       "48            0.550235           0.549882           0.550314         0.550167   \n",
       "102           0.550235           0.549882           0.550314         0.550167   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "215        0.017049                1            0.709610            0.698874   \n",
       "49         0.000167                1            0.550144            0.550144   \n",
       "30         0.000167                1            0.550144            0.550144   \n",
       "48         0.000167                1            0.550144            0.550144   \n",
       "102        0.000167                1            0.550144            0.550144   \n",
       "\n",
       "     split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "215            0.712565            0.730175          0.712806         0.011248  \n",
       "49             0.550262            0.550118          0.550167         0.000056  \n",
       "30             0.550262            0.550118          0.550167         0.000056  \n",
       "48             0.550262            0.550118          0.550167         0.000056  \n",
       "102            0.550262            0.550118          0.550167         0.000056  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_LinSVC_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 3.48 s, total: 1min 42s\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_l2_LinSVC = get_top_n_models(l2_LinSVC_search_results, 'lin_SVC', k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Fastball       0.65      0.61      0.63       452\n",
      "    Fastball       0.70      0.74      0.72       572\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1024\n",
      "   macro avg       0.68      0.67      0.68      1024\n",
      "weighted avg       0.68      0.68      0.68      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Not Fastball</th>\n",
       "      <th>Predicted Fastball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Not Fastball</th>\n",
       "      <td>274</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Fastball</th>\n",
       "      <td>147</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Predicted Not Fastball  Predicted Fastball\n",
       "Actual Not Fastball                     274                 178\n",
       "Actual Fastball                         147                 425"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_l2_LinSVC.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_accuracy_metrics(model, X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 3164.26, NNZs: 53, Bias: 0.000000, T: 5093, Avg. loss: 1873645935.729640\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2643.21, NNZs: 51, Bias: 0.000000, T: 10186, Avg. loss: 204072723.393964\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2613.40, NNZs: 52, Bias: 0.000000, T: 15279, Avg. loss: 118592487.051634\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2661.20, NNZs: 53, Bias: 0.000000, T: 20372, Avg. loss: 84332682.797916\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2653.35, NNZs: 53, Bias: 0.000000, T: 25465, Avg. loss: 64418146.324304\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2687.20, NNZs: 54, Bias: 0.000000, T: 30558, Avg. loss: 53084917.878124\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2718.66, NNZs: 54, Bias: 0.000000, T: 35651, Avg. loss: 44614130.800876\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2746.80, NNZs: 55, Bias: 0.000000, T: 40744, Avg. loss: 39641155.486787\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2761.27, NNZs: 55, Bias: 0.000000, T: 45837, Avg. loss: 33742398.603185\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2777.65, NNZs: 56, Bias: 0.000000, T: 50930, Avg. loss: 30636940.988292\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2793.60, NNZs: 56, Bias: 0.000000, T: 56023, Avg. loss: 27748930.335784\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2809.27, NNZs: 57, Bias: 0.000000, T: 61116, Avg. loss: 25194602.912460\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2815.97, NNZs: 57, Bias: 0.000000, T: 66209, Avg. loss: 22710868.946279\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2830.04, NNZs: 57, Bias: 0.000000, T: 71302, Avg. loss: 20999069.792798\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 2836.24, NNZs: 57, Bias: 0.000000, T: 76395, Avg. loss: 19320234.867575\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2841.02, NNZs: 57, Bias: 0.000000, T: 81488, Avg. loss: 18068760.555000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2855.69, NNZs: 57, Bias: 0.000000, T: 86581, Avg. loss: 17663995.217948\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2863.00, NNZs: 57, Bias: 0.000000, T: 91674, Avg. loss: 16478646.712522\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 2871.95, NNZs: 57, Bias: 0.000000, T: 96767, Avg. loss: 15461534.780924\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 2881.37, NNZs: 57, Bias: 0.000000, T: 101860, Avg. loss: 14813739.288905\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 2888.80, NNZs: 57, Bias: 0.000000, T: 106953, Avg. loss: 13940516.730853\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 2898.59, NNZs: 57, Bias: 0.000000, T: 112046, Avg. loss: 13470097.208090\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2907.36, NNZs: 57, Bias: 0.000000, T: 117139, Avg. loss: 12582563.982802\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2913.03, NNZs: 57, Bias: 0.000000, T: 122232, Avg. loss: 12230924.588904\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2922.33, NNZs: 57, Bias: 0.000000, T: 127325, Avg. loss: 11673134.648469\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2926.12, NNZs: 57, Bias: 0.000000, T: 132418, Avg. loss: 10893139.001008\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2933.20, NNZs: 57, Bias: 0.000000, T: 137511, Avg. loss: 10646457.664583\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2940.01, NNZs: 57, Bias: 0.000000, T: 142604, Avg. loss: 10361559.685804\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2942.64, NNZs: 57, Bias: 0.000000, T: 147697, Avg. loss: 9745013.078231\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2947.38, NNZs: 57, Bias: 0.000000, T: 152790, Avg. loss: 9563746.059714\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2955.09, NNZs: 57, Bias: 0.000000, T: 157883, Avg. loss: 9431605.329550\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2959.65, NNZs: 57, Bias: 0.000000, T: 162976, Avg. loss: 8855514.136486\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2964.00, NNZs: 57, Bias: 0.000000, T: 168069, Avg. loss: 8699693.357897\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2968.03, NNZs: 58, Bias: 0.000000, T: 173162, Avg. loss: 8271661.178180\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2972.73, NNZs: 58, Bias: 0.000000, T: 178255, Avg. loss: 8217957.575350\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2977.77, NNZs: 58, Bias: 0.000000, T: 183348, Avg. loss: 7831416.296320\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2982.51, NNZs: 58, Bias: 0.000000, T: 188441, Avg. loss: 7673471.331106\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2984.78, NNZs: 58, Bias: 0.000000, T: 193534, Avg. loss: 7510600.898475\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2984.32, NNZs: 58, Bias: 0.000000, T: 198627, Avg. loss: 7265832.674612\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2985.71, NNZs: 58, Bias: 0.000000, T: 203720, Avg. loss: 7039434.339971\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2991.33, NNZs: 58, Bias: 0.000000, T: 208813, Avg. loss: 6869144.668051\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2989.50, NNZs: 58, Bias: 0.000000, T: 213906, Avg. loss: 6783351.200758\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2993.14, NNZs: 58, Bias: 0.000000, T: 218999, Avg. loss: 6540987.138058\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2995.58, NNZs: 58, Bias: 0.000000, T: 224092, Avg. loss: 6294847.508110\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2999.20, NNZs: 58, Bias: 0.000000, T: 229185, Avg. loss: 6276932.649461\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3003.02, NNZs: 58, Bias: 0.000000, T: 234278, Avg. loss: 6044110.596347\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3004.80, NNZs: 58, Bias: 0.000000, T: 239371, Avg. loss: 5785558.882920\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3007.86, NNZs: 58, Bias: 0.000000, T: 244464, Avg. loss: 5728551.692216\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3011.67, NNZs: 58, Bias: 0.000000, T: 249557, Avg. loss: 5730576.821917\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3012.68, NNZs: 58, Bias: 0.000000, T: 254650, Avg. loss: 5560535.217908\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3015.32, NNZs: 58, Bias: 0.000000, T: 259743, Avg. loss: 5454955.067077\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3015.89, NNZs: 58, Bias: 0.000000, T: 264836, Avg. loss: 5254197.558858\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3019.03, NNZs: 58, Bias: 0.000000, T: 269929, Avg. loss: 5192231.075982\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3018.58, NNZs: 58, Bias: 0.000000, T: 275022, Avg. loss: 5043335.372848\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3022.48, NNZs: 58, Bias: 0.000000, T: 280115, Avg. loss: 5000447.178042\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3022.84, NNZs: 58, Bias: 0.000000, T: 285208, Avg. loss: 4823596.692331\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3023.79, NNZs: 58, Bias: 0.000000, T: 290301, Avg. loss: 4741680.940334\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3025.18, NNZs: 58, Bias: 0.000000, T: 295394, Avg. loss: 4593344.055254\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3028.89, NNZs: 58, Bias: 0.000000, T: 300487, Avg. loss: 4588974.956702\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3031.71, NNZs: 58, Bias: 0.000000, T: 305580, Avg. loss: 4647812.336203\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3034.56, NNZs: 58, Bias: 0.000000, T: 310673, Avg. loss: 4349015.240038\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3033.01, NNZs: 58, Bias: 0.000000, T: 315766, Avg. loss: 4403085.309335\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3034.35, NNZs: 58, Bias: 0.000000, T: 320859, Avg. loss: 4243837.017003\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3037.02, NNZs: 58, Bias: 0.000000, T: 325952, Avg. loss: 4182065.777173\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3039.81, NNZs: 58, Bias: 0.000000, T: 331045, Avg. loss: 4113653.009320\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3042.00, NNZs: 58, Bias: 0.000000, T: 336138, Avg. loss: 4089081.019447\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3043.09, NNZs: 58, Bias: 0.000000, T: 341231, Avg. loss: 3939656.104045\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3043.48, NNZs: 58, Bias: 0.000000, T: 346324, Avg. loss: 3945550.191732\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3045.07, NNZs: 58, Bias: 0.000000, T: 351417, Avg. loss: 3773915.733226\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3047.52, NNZs: 58, Bias: 0.000000, T: 356510, Avg. loss: 3807046.839283\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 3048.86, NNZs: 58, Bias: 0.000000, T: 361603, Avg. loss: 3740496.672947\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 3051.23, NNZs: 58, Bias: 0.000000, T: 366696, Avg. loss: 3694650.058528\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 3053.83, NNZs: 58, Bias: 0.000000, T: 371789, Avg. loss: 3724628.881355\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 3051.58, NNZs: 58, Bias: 0.000000, T: 376882, Avg. loss: 3504595.205271\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 3050.09, NNZs: 58, Bias: 0.000000, T: 381975, Avg. loss: 3515601.793980\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 3048.32, NNZs: 58, Bias: 0.000000, T: 387068, Avg. loss: 3432801.952917\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 3050.79, NNZs: 57, Bias: 0.000000, T: 392161, Avg. loss: 3445309.137516\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 3051.13, NNZs: 58, Bias: 0.000000, T: 397254, Avg. loss: 3295096.821360\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 3052.92, NNZs: 58, Bias: 0.000000, T: 402347, Avg. loss: 3242517.829414\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 3053.96, NNZs: 58, Bias: 0.000000, T: 407440, Avg. loss: 3269550.083835\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 3055.22, NNZs: 58, Bias: 0.000000, T: 412533, Avg. loss: 3182699.224852\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 3056.36, NNZs: 58, Bias: 0.000000, T: 417626, Avg. loss: 3189185.225635\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 3055.02, NNZs: 58, Bias: 0.000000, T: 422719, Avg. loss: 3199009.115921\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 3056.15, NNZs: 58, Bias: 0.000000, T: 427812, Avg. loss: 3107606.296510\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 3056.36, NNZs: 58, Bias: 0.000000, T: 432905, Avg. loss: 3007391.087036\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 3057.87, NNZs: 58, Bias: 0.000000, T: 437998, Avg. loss: 2981313.377554\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 3060.79, NNZs: 58, Bias: 0.000000, T: 443091, Avg. loss: 2997741.510930\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 3060.25, NNZs: 58, Bias: 0.000000, T: 448184, Avg. loss: 2905920.790179\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 3059.79, NNZs: 58, Bias: 0.000000, T: 453277, Avg. loss: 2940006.954620\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 3059.99, NNZs: 58, Bias: 0.000000, T: 458370, Avg. loss: 2896856.957129\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 3060.48, NNZs: 58, Bias: 0.000000, T: 463463, Avg. loss: 2809751.788110\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 3062.33, NNZs: 58, Bias: 0.000000, T: 468556, Avg. loss: 2783520.304663\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 3061.53, NNZs: 58, Bias: 0.000000, T: 473649, Avg. loss: 2744796.654438\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 3062.59, NNZs: 58, Bias: 0.000000, T: 478742, Avg. loss: 2684386.603988\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 3064.62, NNZs: 58, Bias: 0.000000, T: 483835, Avg. loss: 2666280.344919\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 3065.95, NNZs: 59, Bias: 0.000000, T: 488928, Avg. loss: 2699245.350719\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 3067.66, NNZs: 58, Bias: 0.000000, T: 494021, Avg. loss: 2532856.008459\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 3068.68, NNZs: 59, Bias: 0.000000, T: 499114, Avg. loss: 2548642.122684\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 3069.15, NNZs: 59, Bias: 0.000000, T: 504207, Avg. loss: 2533009.568855\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 3069.84, NNZs: 59, Bias: 0.000000, T: 509300, Avg. loss: 2529953.639394\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 3071.55, NNZs: 59, Bias: 0.000000, T: 514393, Avg. loss: 2503053.352519\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 3072.18, NNZs: 59, Bias: 0.000000, T: 519486, Avg. loss: 2475402.519683\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 3071.25, NNZs: 59, Bias: 0.000000, T: 524579, Avg. loss: 2453184.497903\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 3073.24, NNZs: 59, Bias: 0.000000, T: 529672, Avg. loss: 2456206.586232\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 3074.66, NNZs: 59, Bias: 0.000000, T: 534765, Avg. loss: 2339080.154568\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 3076.23, NNZs: 59, Bias: 0.000000, T: 539858, Avg. loss: 2427347.613741\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 3076.55, NNZs: 59, Bias: 0.000000, T: 544951, Avg. loss: 2345150.887835\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 3078.39, NNZs: 59, Bias: 0.000000, T: 550044, Avg. loss: 2332381.750865\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 3079.44, NNZs: 59, Bias: 0.000000, T: 555137, Avg. loss: 2285953.983813\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 3078.75, NNZs: 59, Bias: 0.000000, T: 560230, Avg. loss: 2288778.675132\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 3080.25, NNZs: 59, Bias: 0.000000, T: 565323, Avg. loss: 2190174.166612\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 3081.49, NNZs: 59, Bias: 0.000000, T: 570416, Avg. loss: 2234774.286865\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 3080.22, NNZs: 59, Bias: 0.000000, T: 575509, Avg. loss: 2181154.883429\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 3081.70, NNZs: 59, Bias: 0.000000, T: 580602, Avg. loss: 2117237.593461\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 3082.81, NNZs: 59, Bias: 0.000000, T: 585695, Avg. loss: 2114789.239303\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 3083.60, NNZs: 59, Bias: 0.000000, T: 590788, Avg. loss: 2100291.516190\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 3083.84, NNZs: 59, Bias: 0.000000, T: 595881, Avg. loss: 2096403.079659\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 3086.08, NNZs: 59, Bias: 0.000000, T: 600974, Avg. loss: 2099873.000328\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 3085.62, NNZs: 59, Bias: 0.000000, T: 606067, Avg. loss: 2075278.224407\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 3085.34, NNZs: 59, Bias: 0.000000, T: 611160, Avg. loss: 2044252.928382\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 3087.25, NNZs: 59, Bias: 0.000000, T: 616253, Avg. loss: 1952175.499741\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 3087.94, NNZs: 59, Bias: 0.000000, T: 621346, Avg. loss: 2005234.395094\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 3089.99, NNZs: 59, Bias: 0.000000, T: 626439, Avg. loss: 1951590.725773\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 3088.85, NNZs: 58, Bias: 0.000000, T: 631532, Avg. loss: 1969808.947560\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 3089.06, NNZs: 59, Bias: 0.000000, T: 636625, Avg. loss: 1946030.532750\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 3089.12, NNZs: 59, Bias: 0.000000, T: 641718, Avg. loss: 1885432.587615\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 3087.51, NNZs: 59, Bias: 0.000000, T: 646811, Avg. loss: 1897838.263437\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 3088.10, NNZs: 59, Bias: 0.000000, T: 651904, Avg. loss: 1878422.070509\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 3087.48, NNZs: 59, Bias: 0.000000, T: 656997, Avg. loss: 1850658.581635\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 3088.64, NNZs: 59, Bias: 0.000000, T: 662090, Avg. loss: 1794376.153905\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 3090.35, NNZs: 59, Bias: 0.000000, T: 667183, Avg. loss: 1779712.351064\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 3091.39, NNZs: 59, Bias: 0.000000, T: 672276, Avg. loss: 1791475.891513\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 3092.14, NNZs: 59, Bias: 0.000000, T: 677369, Avg. loss: 1824565.133483\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 3092.90, NNZs: 59, Bias: 0.000000, T: 682462, Avg. loss: 1777741.952065\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 3091.24, NNZs: 59, Bias: 0.000000, T: 687555, Avg. loss: 1717016.476740\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 3092.23, NNZs: 59, Bias: 0.000000, T: 692648, Avg. loss: 1699123.690673\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 3092.21, NNZs: 59, Bias: 0.000000, T: 697741, Avg. loss: 1690146.772522\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 3090.02, NNZs: 59, Bias: 0.000000, T: 702834, Avg. loss: 1717139.423491\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 3089.86, NNZs: 59, Bias: 0.000000, T: 707927, Avg. loss: 1716798.229533\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 3090.55, NNZs: 58, Bias: 0.000000, T: 713020, Avg. loss: 1620493.946070\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 3089.53, NNZs: 59, Bias: 0.000000, T: 718113, Avg. loss: 1695641.252103\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 3089.36, NNZs: 60, Bias: 0.000000, T: 723206, Avg. loss: 1645980.950294\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 3087.63, NNZs: 60, Bias: 0.000000, T: 728299, Avg. loss: 1643992.873307\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 3087.72, NNZs: 60, Bias: 0.000000, T: 733392, Avg. loss: 1672360.370783\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 3086.77, NNZs: 60, Bias: 0.000000, T: 738485, Avg. loss: 1616556.944766\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 3085.83, NNZs: 60, Bias: 0.000000, T: 743578, Avg. loss: 1586719.840808\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 3086.00, NNZs: 60, Bias: 0.000000, T: 748671, Avg. loss: 1607612.436447\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 3086.22, NNZs: 60, Bias: 0.000000, T: 753764, Avg. loss: 1553546.930399\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 3085.18, NNZs: 60, Bias: 0.000000, T: 758857, Avg. loss: 1532396.926850\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 3085.68, NNZs: 59, Bias: 0.000000, T: 763950, Avg. loss: 1560961.261606\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 3085.88, NNZs: 60, Bias: 0.000000, T: 769043, Avg. loss: 1557070.321025\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 3085.81, NNZs: 60, Bias: 0.000000, T: 774136, Avg. loss: 1516426.544161\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 3086.80, NNZs: 60, Bias: 0.000000, T: 779229, Avg. loss: 1492031.232262\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 3087.11, NNZs: 60, Bias: 0.000000, T: 784322, Avg. loss: 1461167.508930\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 3086.72, NNZs: 60, Bias: 0.000000, T: 789415, Avg. loss: 1476258.307010\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 3088.28, NNZs: 59, Bias: 0.000000, T: 794508, Avg. loss: 1396243.630558\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 3088.17, NNZs: 60, Bias: 0.000000, T: 799601, Avg. loss: 1449785.662396\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 3086.25, NNZs: 60, Bias: 0.000000, T: 804694, Avg. loss: 1440996.137854\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 3086.95, NNZs: 60, Bias: 0.000000, T: 809787, Avg. loss: 1429165.667131\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 3087.47, NNZs: 60, Bias: 0.000000, T: 814880, Avg. loss: 1380153.944622\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 3087.74, NNZs: 60, Bias: 0.000000, T: 819973, Avg. loss: 1415821.267732\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 3087.28, NNZs: 60, Bias: 0.000000, T: 825066, Avg. loss: 1431195.905346\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 3087.17, NNZs: 60, Bias: 0.000000, T: 830159, Avg. loss: 1351822.302192\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 3086.77, NNZs: 60, Bias: 0.000000, T: 835252, Avg. loss: 1371016.368588\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 3086.76, NNZs: 60, Bias: 0.000000, T: 840345, Avg. loss: 1339999.732902\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 3084.24, NNZs: 59, Bias: 0.000000, T: 845438, Avg. loss: 1396049.289458\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 3082.22, NNZs: 59, Bias: 0.000000, T: 850531, Avg. loss: 1373440.464444\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 3083.66, NNZs: 60, Bias: 0.000000, T: 855624, Avg. loss: 1344331.218722\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 3082.17, NNZs: 60, Bias: 0.000000, T: 860717, Avg. loss: 1363499.884919\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 3082.41, NNZs: 60, Bias: 0.000000, T: 865810, Avg. loss: 1236851.389626\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 3082.39, NNZs: 60, Bias: 0.000000, T: 870903, Avg. loss: 1328297.485758\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 3082.52, NNZs: 60, Bias: 0.000000, T: 875996, Avg. loss: 1264265.340587\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 3080.25, NNZs: 59, Bias: 0.000000, T: 881089, Avg. loss: 1316727.895387\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 3079.42, NNZs: 60, Bias: 0.000000, T: 886182, Avg. loss: 1302372.408938\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 3080.85, NNZs: 60, Bias: 0.000000, T: 891275, Avg. loss: 1225808.914546\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 3080.54, NNZs: 60, Bias: 0.000000, T: 896368, Avg. loss: 1238912.497753\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 3080.45, NNZs: 60, Bias: 0.000000, T: 901461, Avg. loss: 1228515.335592\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 3081.46, NNZs: 60, Bias: 0.000000, T: 906554, Avg. loss: 1193323.914504\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 3083.13, NNZs: 60, Bias: 0.000000, T: 911647, Avg. loss: 1195722.691992\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 3081.96, NNZs: 60, Bias: 0.000000, T: 916740, Avg. loss: 1216663.688018\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 3081.99, NNZs: 60, Bias: 0.000000, T: 921833, Avg. loss: 1189875.526782\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 3082.03, NNZs: 60, Bias: 0.000000, T: 926926, Avg. loss: 1220778.207245\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 3079.62, NNZs: 59, Bias: 0.000000, T: 932019, Avg. loss: 1195643.625814\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 3077.83, NNZs: 59, Bias: 0.000000, T: 937112, Avg. loss: 1221392.271442\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 3078.64, NNZs: 60, Bias: 0.000000, T: 942205, Avg. loss: 1180156.469183\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 3079.29, NNZs: 60, Bias: 0.000000, T: 947298, Avg. loss: 1152829.534966\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 3079.76, NNZs: 60, Bias: 0.000000, T: 952391, Avg. loss: 1147559.150565\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 3078.96, NNZs: 60, Bias: 0.000000, T: 957484, Avg. loss: 1150510.113490\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 3077.56, NNZs: 60, Bias: 0.000000, T: 962577, Avg. loss: 1168311.816163\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 3077.27, NNZs: 60, Bias: 0.000000, T: 967670, Avg. loss: 1123713.743637\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 3077.67, NNZs: 60, Bias: 0.000000, T: 972763, Avg. loss: 1098102.023725\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 3077.71, NNZs: 60, Bias: 0.000000, T: 977856, Avg. loss: 1088427.976417\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 3078.13, NNZs: 59, Bias: 0.000000, T: 982949, Avg. loss: 1062286.482056\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 3077.68, NNZs: 60, Bias: 0.000000, T: 988042, Avg. loss: 1061941.011173\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 3079.50, NNZs: 60, Bias: 0.000000, T: 993135, Avg. loss: 1036782.990446\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 3079.34, NNZs: 60, Bias: 0.000000, T: 998228, Avg. loss: 1065289.518562\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 3079.05, NNZs: 59, Bias: 0.000000, T: 1003321, Avg. loss: 1100679.473382\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 3078.12, NNZs: 59, Bias: 0.000000, T: 1008414, Avg. loss: 1089398.944975\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 3078.90, NNZs: 60, Bias: 0.000000, T: 1013507, Avg. loss: 1028856.775164\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 3079.31, NNZs: 60, Bias: 0.000000, T: 1018600, Avg. loss: 1021499.105861\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 3080.14, NNZs: 60, Bias: 0.000000, T: 1023693, Avg. loss: 997573.107114\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 3080.44, NNZs: 60, Bias: 0.000000, T: 1028786, Avg. loss: 1030764.292225\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 3079.42, NNZs: 59, Bias: 0.000000, T: 1033879, Avg. loss: 1051685.392497\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 204\n",
      "Norm: 3079.38, NNZs: 60, Bias: 0.000000, T: 1038972, Avg. loss: 1027367.868069\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 3078.60, NNZs: 60, Bias: 0.000000, T: 1044065, Avg. loss: 1021059.155330\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 3079.34, NNZs: 60, Bias: 0.000000, T: 1049158, Avg. loss: 970187.230918\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 3079.56, NNZs: 60, Bias: 0.000000, T: 1054251, Avg. loss: 983454.732161\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 3079.25, NNZs: 60, Bias: 0.000000, T: 1059344, Avg. loss: 959126.594631\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 3079.06, NNZs: 60, Bias: 0.000000, T: 1064437, Avg. loss: 947889.838103\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 3079.50, NNZs: 60, Bias: 0.000000, T: 1069530, Avg. loss: 981785.945966\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 3078.98, NNZs: 60, Bias: 0.000000, T: 1074623, Avg. loss: 919529.167539\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 3078.58, NNZs: 60, Bias: 0.000000, T: 1079716, Avg. loss: 959185.407432\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 3077.66, NNZs: 60, Bias: 0.000000, T: 1084809, Avg. loss: 962970.315360\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 3075.78, NNZs: 59, Bias: 0.000000, T: 1089902, Avg. loss: 971974.545120\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 3075.40, NNZs: 59, Bias: 0.000000, T: 1094995, Avg. loss: 904728.617611\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 3074.79, NNZs: 60, Bias: 0.000000, T: 1100088, Avg. loss: 958228.017279\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 3075.55, NNZs: 60, Bias: 0.000000, T: 1105181, Avg. loss: 919363.635395\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 3076.00, NNZs: 60, Bias: 0.000000, T: 1110274, Avg. loss: 935846.220910\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 3073.92, NNZs: 60, Bias: 0.000000, T: 1115367, Avg. loss: 952004.802744\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 3071.92, NNZs: 60, Bias: 0.000000, T: 1120460, Avg. loss: 943709.726595\n",
      "Total training time: 0.64 seconds.\n",
      "Convergence after 220 epochs took 0.64 seconds\n",
      "CPU times: user 27.4 s, sys: 510 ms, total: 27.9 s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.02, .05, 0.1],\n",
    "    'loss': ['squared_hinge', 'hinge', 'perceptron'],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    #'multi_class': ['ovr'],\n",
    "    'class_weight': [None],\n",
    "    'max_iter': [1000, 3000, 5000, 10000, 20000, 40000, 100000, 200000],\n",
    "    'fit_intercept': [True, False],\n",
    "    'warm_start': [True, False],\n",
    "    'learning_rate': ['optimal'],\n",
    "    'shuffle':[True, False]\n",
    "}\n",
    "\n",
    "sgd = SGDClassifier(random_state=42, verbose=50)\n",
    "\n",
    "# search = GridSearchCV(\n",
    "#     estimator = sgd, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=4,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "\n",
    "sgd_search = RandomizedSearchCV(estimator=sgd, param_distributions=param_grid, n_iter=500, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "sgd_search.fit(X, y)\n",
    "\n",
    "sgd_search_results = pd.DataFrame(sgd_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_warm_start</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_shuffle</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.643610</td>\n",
       "      <td>0.062262</td>\n",
       "      <td>0.019893</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>40000</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>optimal</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'warm_start': True, 'tol': 1e-05, 'shuffle': ...</td>\n",
       "      <td>0.592462</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.550383</td>\n",
       "      <td>0.564304</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597349</td>\n",
       "      <td>0.550221</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.565876</td>\n",
       "      <td>0.022255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.626085</td>\n",
       "      <td>0.065912</td>\n",
       "      <td>0.020052</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>False</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>40000</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>optimal</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'warm_start': False, 'tol': 5e-05, 'shuffle':...</td>\n",
       "      <td>0.592462</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.550383</td>\n",
       "      <td>0.564304</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597349</td>\n",
       "      <td>0.550221</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.565876</td>\n",
       "      <td>0.022255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.629488</td>\n",
       "      <td>0.073407</td>\n",
       "      <td>0.019659</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>3000</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>optimal</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'warm_start': False, 'tol': 0.0001, 'shuffle'...</td>\n",
       "      <td>0.592462</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.550383</td>\n",
       "      <td>0.564304</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597349</td>\n",
       "      <td>0.550221</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.565876</td>\n",
       "      <td>0.022255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.638316</td>\n",
       "      <td>0.082041</td>\n",
       "      <td>0.019891</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>10000</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>optimal</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'warm_start': False, 'tol': 1e-05, 'shuffle':...</td>\n",
       "      <td>0.592462</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.550383</td>\n",
       "      <td>0.564304</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597349</td>\n",
       "      <td>0.550221</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.565876</td>\n",
       "      <td>0.022255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.624864</td>\n",
       "      <td>0.080225</td>\n",
       "      <td>0.019820</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>200000</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>optimal</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'warm_start': False, 'tol': 0.0001, 'shuffle'...</td>\n",
       "      <td>0.592462</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.550383</td>\n",
       "      <td>0.564304</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597349</td>\n",
       "      <td>0.550221</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.565876</td>\n",
       "      <td>0.022255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "106       0.643610      0.062262         0.019893        0.000303   \n",
       "247       0.626085      0.065912         0.020052        0.000424   \n",
       "434       0.629488      0.073407         0.019659        0.000311   \n",
       "140       0.638316      0.082041         0.019891        0.000104   \n",
       "142       0.624864      0.080225         0.019820        0.000075   \n",
       "\n",
       "    param_warm_start param_tol param_shuffle param_penalty param_max_iter  \\\n",
       "106             True     1e-05          True    elasticnet          40000   \n",
       "247            False     5e-05          True    elasticnet          40000   \n",
       "434            False    0.0001          True    elasticnet           3000   \n",
       "140            False     1e-05          True    elasticnet          10000   \n",
       "142            False    0.0001          True    elasticnet         200000   \n",
       "\n",
       "     param_loss param_learning_rate param_fit_intercept param_class_weight  \\\n",
       "106  perceptron             optimal               False               None   \n",
       "247  perceptron             optimal               False               None   \n",
       "434  perceptron             optimal               False               None   \n",
       "140  perceptron             optimal               False               None   \n",
       "142  perceptron             optimal               False               None   \n",
       "\n",
       "    param_alpha                                             params  \\\n",
       "106        0.05  {'warm_start': True, 'tol': 1e-05, 'shuffle': ...   \n",
       "247        0.05  {'warm_start': False, 'tol': 5e-05, 'shuffle':...   \n",
       "434        0.05  {'warm_start': False, 'tol': 0.0001, 'shuffle'...   \n",
       "140        0.05  {'warm_start': False, 'tol': 1e-05, 'shuffle':...   \n",
       "142        0.05  {'warm_start': False, 'tol': 0.0001, 'shuffle'...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "106           0.592462           0.550059           0.550383         0.564304   \n",
       "247           0.592462           0.550059           0.550383         0.564304   \n",
       "434           0.592462           0.550059           0.550383         0.564304   \n",
       "140           0.592462           0.550059           0.550383         0.564304   \n",
       "142           0.592462           0.550059           0.550383         0.564304   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "106        0.019914                1            0.597349            0.550221   \n",
       "247        0.019914                1            0.597349            0.550221   \n",
       "434        0.019914                1            0.597349            0.550221   \n",
       "140        0.019914                1            0.597349            0.550221   \n",
       "142        0.019914                1            0.597349            0.550221   \n",
       "\n",
       "     split2_train_score  mean_train_score  std_train_score  \n",
       "106            0.550059          0.565876         0.022255  \n",
       "247            0.550059          0.565876         0.022255  \n",
       "434            0.550059          0.565876         0.022255  \n",
       "140            0.550059          0.565876         0.022255  \n",
       "142            0.550059          0.565876         0.022255  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 35s, sys: 7.1 s, total: 2min 42s\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_sgd = get_top_n_models(sgd_search_results, 'sgd', k=100, accuracy_metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.1, average=False, class_...</td>\n",
       "      <td>0.591797</td>\n",
       "      <td>0.727154</td>\n",
       "      <td>-0.655548</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.1, average=False, class_...</td>\n",
       "      <td>0.591797</td>\n",
       "      <td>0.727154</td>\n",
       "      <td>-0.655548</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.1, average=False, class_...</td>\n",
       "      <td>0.591797</td>\n",
       "      <td>0.727154</td>\n",
       "      <td>-0.655548</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.1, average=False, class_...</td>\n",
       "      <td>0.591797</td>\n",
       "      <td>0.727154</td>\n",
       "      <td>-0.655548</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.1, average=False, class_...</td>\n",
       "      <td>0.591797</td>\n",
       "      <td>0.727154</td>\n",
       "      <td>-0.655548</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.1, average=False, class_...</td>\n",
       "      <td>0.591797</td>\n",
       "      <td>0.727154</td>\n",
       "      <td>-0.655548</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.1, average=False, class_...</td>\n",
       "      <td>0.590820</td>\n",
       "      <td>0.726680</td>\n",
       "      <td>-0.659509</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.1, average=False, class_...</td>\n",
       "      <td>0.590820</td>\n",
       "      <td>0.726680</td>\n",
       "      <td>-0.659509</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.02, average=False, class...</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.716792</td>\n",
       "      <td>-0.790210</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.0001, average=False, cla...</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.716792</td>\n",
       "      <td>-0.790210</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy  f1_score  \\\n",
       "0  SGDClassifier(alpha=0.1, average=False, class_...  0.591797  0.727154   \n",
       "0  SGDClassifier(alpha=0.1, average=False, class_...  0.591797  0.727154   \n",
       "0  SGDClassifier(alpha=0.1, average=False, class_...  0.591797  0.727154   \n",
       "0  SGDClassifier(alpha=0.1, average=False, class_...  0.591797  0.727154   \n",
       "0  SGDClassifier(alpha=0.1, average=False, class_...  0.591797  0.727154   \n",
       "0  SGDClassifier(alpha=0.1, average=False, class_...  0.591797  0.727154   \n",
       "0  SGDClassifier(alpha=0.1, average=False, class_...  0.590820  0.726680   \n",
       "0  SGDClassifier(alpha=0.1, average=False, class_...  0.590820  0.726680   \n",
       "0  SGDClassifier(alpha=0.02, average=False, class...  0.558594  0.716792   \n",
       "0  SGDClassifier(alpha=0.0001, average=False, cla...  0.558594  0.716792   \n",
       "\n",
       "   r2_score roc_auc_score     model_type  \n",
       "0 -0.655548           N/A  SGDClassifier  \n",
       "0 -0.655548           N/A  SGDClassifier  \n",
       "0 -0.655548           N/A  SGDClassifier  \n",
       "0 -0.655548           N/A  SGDClassifier  \n",
       "0 -0.655548           N/A  SGDClassifier  \n",
       "0 -0.655548           N/A  SGDClassifier  \n",
       "0 -0.659509           N/A  SGDClassifier  \n",
       "0 -0.659509           N/A  SGDClassifier  \n",
       "0 -0.790210           N/A  SGDClassifier  \n",
       "0 -0.790210           N/A  SGDClassifier  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Fastball       0.77      0.11      0.19       452\n",
      "    Fastball       0.58      0.97      0.73       572\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      1024\n",
      "   macro avg       0.67      0.54      0.46      1024\n",
      "weighted avg       0.66      0.59      0.49      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Not Fastball</th>\n",
       "      <th>Predicted Fastball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Not Fastball</th>\n",
       "      <td>49</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Fastball</th>\n",
       "      <td>15</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Predicted Not Fastball  Predicted Fastball\n",
       "Actual Not Fastball                      49                 403\n",
       "Actual Fastball                          15                 557"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_sgd.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 60 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1488s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 346 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:    6.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "param_grid = {\n",
    "    'solver': ['lsqr'],#, 'eigen'],\n",
    "    'shrinkage': [None, 'auto', 0.1, 0.5],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    'n_components':[None, 25, 50, 75, 100],\n",
    "    #'store_covariance': [True, False]\n",
    "}\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda_search = GridSearchCV(\n",
    "    estimator = lda, \n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=8,\n",
    "    verbose=10,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "lda_search.fit(X, y)\n",
    "\n",
    "lda_search_results = pd.DataFrame(lda_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_components</th>\n",
       "      <th>param_shrinkage</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.163604</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.011201</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'n_components': 50, 'shrinkage': 'auto', 'sol...</td>\n",
       "      <td>0.65047</td>\n",
       "      <td>0.711599</td>\n",
       "      <td>0.717425</td>\n",
       "      <td>0.715409</td>\n",
       "      <td>0.65566</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.677673</td>\n",
       "      <td>0.694969</td>\n",
       "      <td>0.686629</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729517</td>\n",
       "      <td>0.716498</td>\n",
       "      <td>0.72307</td>\n",
       "      <td>0.725376</td>\n",
       "      <td>0.724254</td>\n",
       "      <td>0.729414</td>\n",
       "      <td>0.729414</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>0.725393</td>\n",
       "      <td>0.004111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.163925</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.011492</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'n_components': 50, 'shrinkage': 'auto', 'sol...</td>\n",
       "      <td>0.65047</td>\n",
       "      <td>0.711599</td>\n",
       "      <td>0.717425</td>\n",
       "      <td>0.715409</td>\n",
       "      <td>0.65566</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.677673</td>\n",
       "      <td>0.694969</td>\n",
       "      <td>0.686629</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729517</td>\n",
       "      <td>0.716498</td>\n",
       "      <td>0.72307</td>\n",
       "      <td>0.725376</td>\n",
       "      <td>0.724254</td>\n",
       "      <td>0.729414</td>\n",
       "      <td>0.729414</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>0.725393</td>\n",
       "      <td>0.004111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.159789</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.010676</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>{'n_components': 50, 'shrinkage': 'auto', 'sol...</td>\n",
       "      <td>0.65047</td>\n",
       "      <td>0.711599</td>\n",
       "      <td>0.717425</td>\n",
       "      <td>0.715409</td>\n",
       "      <td>0.65566</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.677673</td>\n",
       "      <td>0.694969</td>\n",
       "      <td>0.686629</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729517</td>\n",
       "      <td>0.716498</td>\n",
       "      <td>0.72307</td>\n",
       "      <td>0.725376</td>\n",
       "      <td>0.724254</td>\n",
       "      <td>0.729414</td>\n",
       "      <td>0.729414</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>0.725393</td>\n",
       "      <td>0.004111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.164680</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>0.011563</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>25</td>\n",
       "      <td>auto</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'n_components': 25, 'shrinkage': 'auto', 'sol...</td>\n",
       "      <td>0.65047</td>\n",
       "      <td>0.711599</td>\n",
       "      <td>0.717425</td>\n",
       "      <td>0.715409</td>\n",
       "      <td>0.65566</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.677673</td>\n",
       "      <td>0.694969</td>\n",
       "      <td>0.686629</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729517</td>\n",
       "      <td>0.716498</td>\n",
       "      <td>0.72307</td>\n",
       "      <td>0.725376</td>\n",
       "      <td>0.724254</td>\n",
       "      <td>0.729414</td>\n",
       "      <td>0.729414</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>0.725393</td>\n",
       "      <td>0.004111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.161443</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>25</td>\n",
       "      <td>auto</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>{'n_components': 25, 'shrinkage': 'auto', 'sol...</td>\n",
       "      <td>0.65047</td>\n",
       "      <td>0.711599</td>\n",
       "      <td>0.717425</td>\n",
       "      <td>0.715409</td>\n",
       "      <td>0.65566</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.677673</td>\n",
       "      <td>0.694969</td>\n",
       "      <td>0.686629</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729517</td>\n",
       "      <td>0.716498</td>\n",
       "      <td>0.72307</td>\n",
       "      <td>0.725376</td>\n",
       "      <td>0.724254</td>\n",
       "      <td>0.729414</td>\n",
       "      <td>0.729414</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>0.725393</td>\n",
       "      <td>0.004111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "29       0.163604      0.010257         0.011201        0.000410   \n",
       "27       0.163925      0.003688         0.011492        0.000445   \n",
       "28       0.159789      0.002517         0.010676        0.001529   \n",
       "17       0.164680      0.009135         0.011563        0.000612   \n",
       "16       0.161443      0.006466         0.011252        0.000553   \n",
       "\n",
       "   param_n_components param_shrinkage param_solver param_tol  \\\n",
       "29                 50            auto         lsqr     1e-05   \n",
       "27                 50            auto         lsqr    0.0001   \n",
       "28                 50            auto         lsqr     5e-05   \n",
       "17                 25            auto         lsqr     1e-05   \n",
       "16                 25            auto         lsqr     5e-05   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "29  {'n_components': 50, 'shrinkage': 'auto', 'sol...            0.65047   \n",
       "27  {'n_components': 50, 'shrinkage': 'auto', 'sol...            0.65047   \n",
       "28  {'n_components': 50, 'shrinkage': 'auto', 'sol...            0.65047   \n",
       "17  {'n_components': 25, 'shrinkage': 'auto', 'sol...            0.65047   \n",
       "16  {'n_components': 25, 'shrinkage': 'auto', 'sol...            0.65047   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "29           0.711599           0.717425           0.715409   \n",
       "27           0.711599           0.717425           0.715409   \n",
       "28           0.711599           0.717425           0.715409   \n",
       "17           0.711599           0.717425           0.715409   \n",
       "16           0.711599           0.717425           0.715409   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "29            0.65566           0.669811           0.677673   \n",
       "27            0.65566           0.669811           0.677673   \n",
       "28            0.65566           0.669811           0.677673   \n",
       "17            0.65566           0.669811           0.677673   \n",
       "16            0.65566           0.669811           0.677673   \n",
       "\n",
       "    split7_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "29           0.694969         0.686629        0.025253                1   \n",
       "27           0.694969         0.686629        0.025253                1   \n",
       "28           0.694969         0.686629        0.025253                1   \n",
       "17           0.694969         0.686629        0.025253                1   \n",
       "16           0.694969         0.686629        0.025253                1   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "29            0.729517            0.716498             0.72307   \n",
       "27            0.729517            0.716498             0.72307   \n",
       "28            0.729517            0.716498             0.72307   \n",
       "17            0.729517            0.716498             0.72307   \n",
       "16            0.729517            0.716498             0.72307   \n",
       "\n",
       "    split3_train_score  split4_train_score  split5_train_score  \\\n",
       "29            0.725376            0.724254            0.729414   \n",
       "27            0.725376            0.724254            0.729414   \n",
       "28            0.725376            0.724254            0.729414   \n",
       "17            0.725376            0.724254            0.729414   \n",
       "16            0.725376            0.724254            0.729414   \n",
       "\n",
       "    split6_train_score  split7_train_score  mean_train_score  std_train_score  \n",
       "29            0.729414              0.7256          0.725393         0.004111  \n",
       "27            0.729414              0.7256          0.725393         0.004111  \n",
       "28            0.729414              0.7256          0.725393         0.004111  \n",
       "17            0.729414              0.7256          0.725393         0.004111  \n",
       "16            0.729414              0.7256          0.725393         0.004111  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.2 s, sys: 1.75 s, total: 36 s\n",
      "Wall time: 4.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_lda = get_top_n_models(lda_search_results, 'lda', k=50)\n",
    "top10_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Fastball       0.67      0.59      0.62       452\n",
      "    Fastball       0.70      0.77      0.73       572\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      1024\n",
      "   macro avg       0.69      0.68      0.68      1024\n",
      "weighted avg       0.69      0.69      0.69      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Not Fastball</th>\n",
       "      <th>Predicted Fastball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Not Fastball</th>\n",
       "      <td>265</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Fastball</th>\n",
       "      <td>131</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Predicted Not Fastball  Predicted Fastball\n",
       "Actual Not Fastball                     265                 187\n",
       "Actual Fastball                         131                 441"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = top10_lda.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the top10s into one df and save to pickle file\n",
    "\n",
    "best_models = pd.concat([top10_rfc_bootstrap, top10_rfc_without_bootstrap, top10_gbc, top10_svm, top10_l1_LinSVC, top10_l2_LinSVC,\n",
    "                         top10_sgd, top10_lda])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models.to_pickle(path=(pitcher+'_best_models_v1.pkl'),compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_pickle(pitcher+'_best_models_v1.pkl', compression='zip')\n",
    "# test.sort_values(by='accuracy', ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
