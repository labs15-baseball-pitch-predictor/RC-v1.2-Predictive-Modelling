{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "#import psycopg2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "\n",
    "#import eli5\n",
    "#from eli5.sklearn import PermutationImportance\n",
    "#import category_encoders as ce\n",
    "#from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pitcher = 'Verlander'\n",
    "# pitcher = 'Greinke'\n",
    "# pitcher = 'Scherzer'\n",
    "# pitcher = 'deGrom'\n",
    "# pitcher = 'Bauer'\n",
    "# pitcher = 'Gibson'\n",
    "# pitcher = 'Lynn'\n",
    "pitcher = 'Corbin'\n",
    "# pitcher = 'Cole'\n",
    "# pitcher = 'Nola'\n",
    "\n",
    "path = '/home/ec2-user/SageMaker/RC-v1.2-Predictive-Modelling/pitcher_df_pickles/' + pitcher + '_df.pkl'\n",
    "\n",
    "df = pd.read_pickle(path, compression='zip').reset_index()\n",
    "\n",
    "#make binary fastball/not-fastball target feature:\n",
    "# df['fastball_target'] = (df['pitch_cat'] == 'fastball') * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace some categoricals with custom strategic ordinal encoding scale:\n",
    "\n",
    "def custom_ordinal_ecode(df):\n",
    "    df = df.copy()\n",
    "        \n",
    "    #description cols:\n",
    "    desc_map = {'called_strike':1,\n",
    "                'swinging_strike':2,\n",
    "                'foul_tip':3,\n",
    "                'foul':4,\n",
    "                'swinging_strike_blocked':5,\n",
    "                'foul_bunt':6,\n",
    "                'missed_bunt':6,\n",
    "                'bunt_foul_tip':6,\n",
    "                'N/A':7,\n",
    "                'pitchout':7,\n",
    "                'hit_into_play':8,\n",
    "                'ball':9,\n",
    "                'blocked_ball':10,\n",
    "                'hit_by_pitch':11,\n",
    "                'hit_into_play_no_out':12,\n",
    "                'hit_into_play_score':13}\n",
    "    \n",
    "    desc_cols = ['L1_description', 'L2_description', 'L3_description']\n",
    "    df[desc_cols] = df[desc_cols].replace(desc_map).astype('int')\n",
    "\n",
    "    #pitch_result cols\n",
    "    pitch_result_map = {'S':1, 'N/A':2, 'X':3, 'B':4}\n",
    "    result_cols = ['L1_pitch_result', 'L2_pitch_result']\n",
    "    df[result_cols] = df[result_cols].replace(pitch_result_map).astype('int')\n",
    "\n",
    "    #pitch_type cols\n",
    "    pitch_type_map = {'FA':1, 'FF':1, 'FT':2, 'FC':2, 'FS':2, 'SI':2, 'SF':2, 'N/A':2.5, 'SL':3,\n",
    "                      'CB':4, 'CU':4, 'SC':5, 'KC':5, 'CH':6, 'KN':7, 'EP':8, 'FO':9, 'PO':9}\n",
    "    pitch_type_cols = ['L1_pitch_type', 'L2_pitch_type', 'L3_pitch_type', 'pitch_type']\n",
    "    df[pitch_type_cols] = df[pitch_type_cols].replace(pitch_type_map).astype('float')\n",
    "\n",
    "    #count_cat\n",
    "    count_cat_map = {'ahead':1,'neutral':2, 'behind':3}\n",
    "    df['count_cat'] = df['count_cat'].replace(count_cat_map).astype('int')\n",
    "\n",
    "    #count\n",
    "    _count_map = {'02':1, '12':2, '01':3, '22':4, '11':5, '00':6, '21':7, '32':8, '10':9, '20':10, '31':11, '30':12}\n",
    "    df['_count'] = df['_count'].replace(_count_map).astype('int')\n",
    "\n",
    "    #for swung and chased, make unknown (-1) set to 0, and 0 (didnt swing/chase) set to -1:\n",
    "    swung_and_chased_cols = ['L1_batter_swung', 'L1_chased', 'L2_chased', 'L3_chased']\n",
    "\n",
    "    def swung_chase_edit(x):\n",
    "        if x == 0:\n",
    "            return -1\n",
    "        elif x == -1:\n",
    "            return 0\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    for col in swung_and_chased_cols:\n",
    "        df[col] = df[col].apply(swung_chase_edit)\n",
    "\n",
    "    #fill remaining misc categories to numerics:\n",
    "    misc_map = {'L':-1, 'R':2, 'Top':-1, 'Bot': 1, 'Standard':0, 'Infield shift': 1, 'Strategic':2, '4th outfielder':3}\n",
    "    df = df.replace(misc_map)\n",
    "\n",
    "    #clean up category dtypes to ints\n",
    "    df['year'] = df['year'].cat.codes\n",
    "    df['catcher_id'] = df['catcher_id'].cat.codes\n",
    "    \n",
    "    cat_cols = ['outs_when_up', 'inning', 'at_bat_number', 'pitch_number', 'balls', 'strikes', 'pitch_count', 'L1_pitch_zone', \n",
    "                'L1_batter_swung', 'L1_chased', 'L2_pitch_zone', 'L2_chased', 'L3_pitch_zone', 'L3_chased', 'batting_order_slot', \n",
    "                'month']\n",
    "    \n",
    "    df[cat_cols] = df[cat_cols].astype('int')\n",
    "    df[['stand', 'inning_topbot', 'if_fielding_alignment', 'of_fielding_alignment']] = df[['stand', 'inning_topbot', 'if_fielding_alignment', 'of_fielding_alignment']].astype('int')\n",
    "    return df\n",
    "\n",
    "def one_hot_encode(df):\n",
    "    \n",
    "    cat_cols = df.select_dtypes('category').columns.tolist()\n",
    "    debug_pitcher_list = ['Cole', 'Bauer']\n",
    "    if pitcher == 'Cole' or pitcher == 'Bauer':\n",
    "        cat_cols = cat_cols + df.select_dtypes('object').columns.tolist()\n",
    "    ignore_cols = ['at_bat_number', 'pitch_count', 'pitch_cat', 'player_name', 'pitch_type', 'pitcher']\n",
    "    for col in ignore_cols:\n",
    "        try:\n",
    "            cat_cols.remove(col)\n",
    "            #print(col + ' removed')\n",
    "        except:\n",
    "            print(col + ' not found')\n",
    "    pitch_type_map = {'FA':1, 'FF':1, 'FT':2, 'FC':2, 'FS':2, 'SI':2, 'SF':2, 'N/A':2.5, 'SL':3,\n",
    "                      'CB':4, 'CU':4, 'SC':5, 'KC':5, 'CH':6, 'KN':7, 'EP':8, 'FO':9, 'PO':9}\n",
    "    df['pitch_type'] = df['pitch_type'].replace(pitch_type_map).astype('float')\n",
    "    df[['at_bat_number', 'pitch_count']] = df[['at_bat_number', 'pitch_count']].astype('int')\n",
    "    df = pd.get_dummies(df, columns=cat_cols)\n",
    "    return df\n",
    "\n",
    "def pca_function(df, threshold, show_scree_plot=True, scaled=False, scaler_type='standard', excluded_cols=None):\n",
    "    '''\n",
    "    Takes a pandas dataframe and a desired threshold, scales the numeric features \n",
    "    and performs principal component analysis dimension reduction, and returns\n",
    "    a pandas dataframe of lower dimensionality and variance explained to the given\n",
    "    threshold\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "      The dataframe containing data to perform PCA on\n",
    "\n",
    "    threshold : The desired % of variance explained to be included in the return;\n",
    "              must be an number between 0 and 100\n",
    "\n",
    "    show_scree_plot : Bool indicating whether or not to display scree plot showing \n",
    "                    the % variance explained by each principal component; \n",
    "                    default set to True\n",
    "\n",
    "    scaled : Bool indicating whether the numeric data has been scaled; default set \n",
    "           to False\n",
    "\n",
    "    exclude_cols : list of numeric columns to exclude from PCA; default set to None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe:\n",
    "      a pandas dataframe where the numeric columns have been scaled and \n",
    "      dimensions reduced to the number of principal components which explain\n",
    "      the variance at a given threshold\n",
    "    '''\n",
    "\n",
    "    #confirm proper threshold input:\n",
    "    if threshold < 1 or threshold > 100:\n",
    "        return 'Incorrect threshold input, must be a number between 1 and 100'\n",
    "\n",
    "    #library imports\n",
    "    from sklearn.decomposition import PCA \n",
    "    from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "    import seaborn as sns\n",
    "\n",
    "    X = df.copy()\n",
    "\n",
    "    if excluded_cols != None:\n",
    "        X = X.drop(columns=excluded_cols)\n",
    "\n",
    "    #use only the numeric columns that have not been excluded\n",
    "    numeric_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "    X = X[numeric_cols].values\n",
    "\n",
    "    if scaled == False:\n",
    "        #scale the data:\n",
    "        if scaler_type == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "            scaled_X = scaler.fit_transform(X)\n",
    "        elif scaler_type == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "            scaled_X = scaler.fit_transform(X)        \n",
    "    else:\n",
    "        scaled_X = X\n",
    "\n",
    "    #calc the principal component variance\n",
    "    n = len(numeric_cols)\n",
    "    covar_matrix = PCA(n_components = n)\n",
    "    covar_matrix.fit(scaled_X)\n",
    "\n",
    "    ##calculate variance ratios\n",
    "    variance = covar_matrix.explained_variance_ratio_\n",
    "    cumulative_var = np.cumsum(np.round(covar_matrix.explained_variance_ratio_, decimals=3)*100)\n",
    "\n",
    "    #function for calculating number of principal components to use:\n",
    "    def calc_num_components(cum_var, threshold):\n",
    "        for i in range(n):\n",
    "            if cum_var[i] >= threshold:\n",
    "                return i+1\n",
    "\n",
    "    #call the function to calulate num_components:\n",
    "    n_components = calc_num_components(cumulative_var, threshold)\n",
    "\n",
    "    # create the PCA instance\n",
    "    pca = PCA(n_components = n_components)\n",
    "    principal_components = pca.fit_transform(scaled_X)\n",
    "\n",
    "    #scree plot function\n",
    "    '''\n",
    "    colors = ['red' if x == n_components else 'grey' for x in X_vals]\n",
    "    sb.barplot(x=idx, y=values, palette=colors)'''\n",
    "\n",
    "    def make_scree(cumulative_variance, threshold):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "\n",
    "        n = len(cumulative_variance)\n",
    "        y_vals = [num for num in cumulative_variance]\n",
    "        x_vals = [num for num in range(1,n+1)]\n",
    "\n",
    "        colors = ['red' if x == n_components else '#769ddb' for x in x_vals]\n",
    "        width = min(n/3, 20)\n",
    "        height = min(n/4, 16)\n",
    "        fig, ax = plt.subplots(figsize=(width,height))\n",
    "        ax.grid(True)\n",
    "        ax.set_title('Principal Components Cumulative Variance')\n",
    "        ax.set_ylabel('Cumulative Variance % Explained')\n",
    "        ax.set_xlabel('Principal Components')\n",
    "\n",
    "        # threshold var\n",
    "        ax.axhline(threshold, color='black', linewidth=1);\n",
    "        sns.barplot(x=x_vals, y=y_vals, ax=ax, palette=colors)\n",
    "        plt.show()\n",
    "\n",
    "    if show_scree_plot:\n",
    "        #plot it:\n",
    "        make_scree(cumulative_var, threshold)\n",
    "\n",
    "    #convert to pandas df:\n",
    "    pc_df = pd.DataFrame(data = principal_components, columns=['component_' + str(i) for i in range(1, n_components+1)])\n",
    "\n",
    "    #return df which is original df w/ the numeric cols dropped and replaced w/ principal components df\n",
    "\n",
    "    df = pd.concat([df, pc_df], axis=1).drop(columns = numeric_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SL    0.390081\n",
       "FT    0.310966\n",
       "FF    0.199417\n",
       "CU    0.067445\n",
       "CH    0.032092\n",
       "Name: pitch_type, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for Verlander, who only threw 20 cut fastballs, just recast as 4seam fastball \n",
    "#(not worth treating as own class, possibly misclassified anyway).. similar for Cole\n",
    "\n",
    "if pitcher == 'Verlander':\n",
    "    df = df.replace({'FC':'FF'})  \n",
    "if pitcher == 'Cole':\n",
    "    df = df.replace({'FT':'FF'})\n",
    "if pitcher == 'Bauer':\n",
    "    df = df.replace({'FT':'FC'})\n",
    "    \n",
    "#fill NaNs for pitcher Lynn in the pitchout percentage columns:\n",
    "if pitcher == 'Lynn':\n",
    "    df[['overall_pitchout_perc', 'count_cat_pitchout_perc']] = df[['overall_pitchout_perc', 'count_cat_pitchout_perc']].fillna(0.0)\n",
    "\n",
    "#For Corbin, gonna try combining all fastballs together\n",
    "if pitcher == 'Corbin':\n",
    "    df['pitch_type'] = df['pitch_type'].replace({2.0:1.0})\n",
    "    \n",
    "df.pitch_type.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pitch_type</th>\n",
       "      <th>game_date</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>on_3b</th>\n",
       "      <th>on_2b</th>\n",
       "      <th>on_1b</th>\n",
       "      <th>sz_top</th>\n",
       "      <th>sz_bot</th>\n",
       "      <th>at_bat_number</th>\n",
       "      <th>bat_score</th>\n",
       "      <th>score_diff</th>\n",
       "      <th>bases_loaded</th>\n",
       "      <th>fastball_perc_faced</th>\n",
       "      <th>fastball_chase_perc</th>\n",
       "      <th>fastball_bip_swung_perc</th>\n",
       "      <th>fastball_taken_strike_perc</th>\n",
       "      <th>fastball_est_woba</th>\n",
       "      <th>fastball_babip</th>\n",
       "      <th>fastball_iso_value</th>\n",
       "      <th>breaking_perc_faced</th>\n",
       "      <th>breaking_chase_perc</th>\n",
       "      <th>breaking_bip_swung_perc</th>\n",
       "      <th>breaking_taken_strike_perc</th>\n",
       "      <th>breaking_est_woba</th>\n",
       "      <th>breaking_babip</th>\n",
       "      <th>breaking_iso_value</th>\n",
       "      <th>offspeed_perc_faced</th>\n",
       "      <th>offspeed_chase_perc</th>\n",
       "      <th>offspeed_bip_swung_perc</th>\n",
       "      <th>offspeed_taken_strike_perc</th>\n",
       "      <th>offspeed_est_woba</th>\n",
       "      <th>offspeed_babip</th>\n",
       "      <th>offspeed_iso_value</th>\n",
       "      <th>pitchout_perc_faced</th>\n",
       "      <th>player_name</th>\n",
       "      <th>pitch_cat</th>\n",
       "      <th>overall_fastball_perc</th>\n",
       "      <th>count_cat_fastball_perc</th>\n",
       "      <th>overall_breaking_perc</th>\n",
       "      <th>count_cat_breaking_perc</th>\n",
       "      <th>overall_offspeed_perc</th>\n",
       "      <th>count_cat_offspeed_perc</th>\n",
       "      <th>pitch_count</th>\n",
       "      <th>L5_fastball_perc</th>\n",
       "      <th>L15_fastball_perc</th>\n",
       "      <th>L5_breaking_perc</th>\n",
       "      <th>L15_breaking_perc</th>\n",
       "      <th>L5_offspeed_perc</th>\n",
       "      <th>L15_offspeed_perc</th>\n",
       "      <th>L5_strike_perc</th>\n",
       "      <th>L15_strike_perc</th>\n",
       "      <th>pitcher_AB</th>\n",
       "      <th>prev_ab_run_scored</th>\n",
       "      <th>prev_ab_homerun</th>\n",
       "      <th>prev_ab_walk</th>\n",
       "      <th>prev_ab_basehit</th>\n",
       "      <th>prev_ab_strikeout</th>\n",
       "      <th>PB_fastball</th>\n",
       "      <th>PB_offspeed</th>\n",
       "      <th>PB_breaking</th>\n",
       "      <th>on_base</th>\n",
       "      <th>outs_when_up_0.0</th>\n",
       "      <th>outs_when_up_1.0</th>\n",
       "      <th>outs_when_up_2.0</th>\n",
       "      <th>inning_1.0</th>\n",
       "      <th>inning_2.0</th>\n",
       "      <th>inning_3.0</th>\n",
       "      <th>inning_4.0</th>\n",
       "      <th>inning_5.0</th>\n",
       "      <th>inning_6.0</th>\n",
       "      <th>inning_7.0</th>\n",
       "      <th>inning_8.0</th>\n",
       "      <th>inning_17.0</th>\n",
       "      <th>catcher_id_435064.0</th>\n",
       "      <th>catcher_id_460269.0</th>\n",
       "      <th>catcher_id_488771.0</th>\n",
       "      <th>catcher_id_553902.0</th>\n",
       "      <th>catcher_id_641598.0</th>\n",
       "      <th>pitch_number_1.0</th>\n",
       "      <th>pitch_number_2.0</th>\n",
       "      <th>pitch_number_3.0</th>\n",
       "      <th>pitch_number_4.0</th>\n",
       "      <th>pitch_number_5.0</th>\n",
       "      <th>pitch_number_6.0</th>\n",
       "      <th>pitch_number_7.0</th>\n",
       "      <th>pitch_number_8.0</th>\n",
       "      <th>pitch_number_9.0</th>\n",
       "      <th>pitch_number_10.0</th>\n",
       "      <th>pitch_number_11.0</th>\n",
       "      <th>pitch_number_12.0</th>\n",
       "      <th>pitch_number_13.0</th>\n",
       "      <th>stand_L</th>\n",
       "      <th>stand_R</th>\n",
       "      <th>inning_topbot_Bot</th>\n",
       "      <th>inning_topbot_Top</th>\n",
       "      <th>if_fielding_alignment_Infield shift</th>\n",
       "      <th>if_fielding_alignment_Standard</th>\n",
       "      <th>if_fielding_alignment_Strategic</th>\n",
       "      <th>balls_0</th>\n",
       "      <th>balls_1</th>\n",
       "      <th>balls_2</th>\n",
       "      <th>balls_3</th>\n",
       "      <th>strikes_0</th>\n",
       "      <th>strikes_1</th>\n",
       "      <th>strikes_2</th>\n",
       "      <th>of_fielding_alignment_4th outfielder</th>\n",
       "      <th>of_fielding_alignment_Standard</th>\n",
       "      <th>of_fielding_alignment_Strategic</th>\n",
       "      <th>_count_00</th>\n",
       "      <th>_count_01</th>\n",
       "      <th>_count_02</th>\n",
       "      <th>_count_10</th>\n",
       "      <th>_count_11</th>\n",
       "      <th>_count_12</th>\n",
       "      <th>_count_20</th>\n",
       "      <th>_count_21</th>\n",
       "      <th>_count_22</th>\n",
       "      <th>_count_30</th>\n",
       "      <th>_count_31</th>\n",
       "      <th>_count_32</th>\n",
       "      <th>count_cat_ahead</th>\n",
       "      <th>count_cat_behind</th>\n",
       "      <th>count_cat_neutral</th>\n",
       "      <th>L1_pitch_type_CH</th>\n",
       "      <th>L1_pitch_type_CU</th>\n",
       "      <th>L1_pitch_type_FF</th>\n",
       "      <th>L1_pitch_type_FT</th>\n",
       "      <th>L1_pitch_type_N/A</th>\n",
       "      <th>L1_pitch_type_SL</th>\n",
       "      <th>L1_pitch_result_B</th>\n",
       "      <th>L1_pitch_result_N/A</th>\n",
       "      <th>L1_pitch_result_S</th>\n",
       "      <th>L1_pitch_result_X</th>\n",
       "      <th>L1_description_N/A</th>\n",
       "      <th>L1_description_ball</th>\n",
       "      <th>L1_description_blocked_ball</th>\n",
       "      <th>L1_description_called_strike</th>\n",
       "      <th>L1_description_foul</th>\n",
       "      <th>L1_description_foul_bunt</th>\n",
       "      <th>L1_description_foul_tip</th>\n",
       "      <th>L1_description_hit_by_pitch</th>\n",
       "      <th>L1_description_hit_into_play</th>\n",
       "      <th>L1_description_hit_into_play_no_out</th>\n",
       "      <th>L1_description_hit_into_play_score</th>\n",
       "      <th>L1_description_missed_bunt</th>\n",
       "      <th>L1_description_swinging_strike</th>\n",
       "      <th>L1_description_swinging_strike_blocked</th>\n",
       "      <th>L1_pitch_zone_-1.0</th>\n",
       "      <th>L1_pitch_zone_1.0</th>\n",
       "      <th>L1_pitch_zone_2.0</th>\n",
       "      <th>L1_pitch_zone_3.0</th>\n",
       "      <th>L1_pitch_zone_4.0</th>\n",
       "      <th>L1_pitch_zone_5.0</th>\n",
       "      <th>L1_pitch_zone_6.0</th>\n",
       "      <th>L1_pitch_zone_7.0</th>\n",
       "      <th>L1_pitch_zone_8.0</th>\n",
       "      <th>L1_pitch_zone_9.0</th>\n",
       "      <th>L1_pitch_zone_11.0</th>\n",
       "      <th>L1_pitch_zone_12.0</th>\n",
       "      <th>L1_pitch_zone_13.0</th>\n",
       "      <th>L1_pitch_zone_14.0</th>\n",
       "      <th>L1_batter_swung_-1.0</th>\n",
       "      <th>L1_batter_swung_0.0</th>\n",
       "      <th>L1_batter_swung_1.0</th>\n",
       "      <th>L1_chased_-1.0</th>\n",
       "      <th>L1_chased_0.0</th>\n",
       "      <th>L1_chased_1.0</th>\n",
       "      <th>L2_pitch_type_CH</th>\n",
       "      <th>L2_pitch_type_CU</th>\n",
       "      <th>L2_pitch_type_FF</th>\n",
       "      <th>L2_pitch_type_FT</th>\n",
       "      <th>L2_pitch_type_N/A</th>\n",
       "      <th>L2_pitch_type_SL</th>\n",
       "      <th>L2_pitch_result_B</th>\n",
       "      <th>L2_pitch_result_N/A</th>\n",
       "      <th>L2_pitch_result_S</th>\n",
       "      <th>L2_pitch_result_X</th>\n",
       "      <th>L2_description_N/A</th>\n",
       "      <th>L2_description_ball</th>\n",
       "      <th>L2_description_blocked_ball</th>\n",
       "      <th>L2_description_called_strike</th>\n",
       "      <th>L2_description_foul</th>\n",
       "      <th>L2_description_foul_bunt</th>\n",
       "      <th>L2_description_foul_tip</th>\n",
       "      <th>L2_description_hit_by_pitch</th>\n",
       "      <th>L2_description_hit_into_play</th>\n",
       "      <th>L2_description_hit_into_play_no_out</th>\n",
       "      <th>L2_description_hit_into_play_score</th>\n",
       "      <th>L2_description_missed_bunt</th>\n",
       "      <th>L2_description_swinging_strike</th>\n",
       "      <th>L2_description_swinging_strike_blocked</th>\n",
       "      <th>L2_pitch_zone_-1.0</th>\n",
       "      <th>L2_pitch_zone_1.0</th>\n",
       "      <th>L2_pitch_zone_2.0</th>\n",
       "      <th>L2_pitch_zone_3.0</th>\n",
       "      <th>L2_pitch_zone_4.0</th>\n",
       "      <th>L2_pitch_zone_5.0</th>\n",
       "      <th>L2_pitch_zone_6.0</th>\n",
       "      <th>L2_pitch_zone_7.0</th>\n",
       "      <th>L2_pitch_zone_8.0</th>\n",
       "      <th>L2_pitch_zone_9.0</th>\n",
       "      <th>L2_pitch_zone_11.0</th>\n",
       "      <th>L2_pitch_zone_12.0</th>\n",
       "      <th>L2_pitch_zone_13.0</th>\n",
       "      <th>L2_pitch_zone_14.0</th>\n",
       "      <th>L2_chased_-1.0</th>\n",
       "      <th>L2_chased_0.0</th>\n",
       "      <th>L2_chased_1.0</th>\n",
       "      <th>L3_pitch_type_CH</th>\n",
       "      <th>L3_pitch_type_CU</th>\n",
       "      <th>L3_pitch_type_FF</th>\n",
       "      <th>L3_pitch_type_FT</th>\n",
       "      <th>L3_pitch_type_N/A</th>\n",
       "      <th>L3_pitch_type_SL</th>\n",
       "      <th>L3_description_N/A</th>\n",
       "      <th>L3_description_ball</th>\n",
       "      <th>L3_description_blocked_ball</th>\n",
       "      <th>L3_description_called_strike</th>\n",
       "      <th>L3_description_foul</th>\n",
       "      <th>L3_description_foul_bunt</th>\n",
       "      <th>L3_description_foul_tip</th>\n",
       "      <th>L3_description_hit_by_pitch</th>\n",
       "      <th>L3_description_hit_into_play</th>\n",
       "      <th>L3_description_hit_into_play_no_out</th>\n",
       "      <th>L3_description_hit_into_play_score</th>\n",
       "      <th>L3_description_missed_bunt</th>\n",
       "      <th>L3_description_swinging_strike</th>\n",
       "      <th>L3_description_swinging_strike_blocked</th>\n",
       "      <th>L3_pitch_zone_-1.0</th>\n",
       "      <th>L3_pitch_zone_1.0</th>\n",
       "      <th>L3_pitch_zone_2.0</th>\n",
       "      <th>L3_pitch_zone_3.0</th>\n",
       "      <th>L3_pitch_zone_4.0</th>\n",
       "      <th>L3_pitch_zone_5.0</th>\n",
       "      <th>L3_pitch_zone_6.0</th>\n",
       "      <th>L3_pitch_zone_7.0</th>\n",
       "      <th>L3_pitch_zone_8.0</th>\n",
       "      <th>L3_pitch_zone_9.0</th>\n",
       "      <th>L3_pitch_zone_11.0</th>\n",
       "      <th>L3_pitch_zone_12.0</th>\n",
       "      <th>L3_pitch_zone_13.0</th>\n",
       "      <th>L3_pitch_zone_14.0</th>\n",
       "      <th>L3_chased_-1.0</th>\n",
       "      <th>L3_chased_0.0</th>\n",
       "      <th>L3_chased_1.0</th>\n",
       "      <th>batting_order_slot_1.0</th>\n",
       "      <th>batting_order_slot_2.0</th>\n",
       "      <th>batting_order_slot_3.0</th>\n",
       "      <th>batting_order_slot_4.0</th>\n",
       "      <th>batting_order_slot_5.0</th>\n",
       "      <th>batting_order_slot_6.0</th>\n",
       "      <th>batting_order_slot_7.0</th>\n",
       "      <th>batting_order_slot_8.0</th>\n",
       "      <th>batting_order_slot_9.0</th>\n",
       "      <th>batting_order_slot_10.0</th>\n",
       "      <th>batting_order_slot_11.0</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>year_2018</th>\n",
       "      <th>year_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>502043.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6311</td>\n",
       "      <td>1.5714</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.324272</td>\n",
       "      <td>27.808220</td>\n",
       "      <td>28.756958</td>\n",
       "      <td>37.196262</td>\n",
       "      <td>0.519561</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>29.661421</td>\n",
       "      <td>34.715027</td>\n",
       "      <td>26.459145</td>\n",
       "      <td>47.881355</td>\n",
       "      <td>0.470353</td>\n",
       "      <td>0.138158</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>10.014306</td>\n",
       "      <td>38.297871</td>\n",
       "      <td>38.679245</td>\n",
       "      <td>24.637682</td>\n",
       "      <td>0.462878</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Kyle Gibson</td>\n",
       "      <td>fastball</td>\n",
       "      <td>59.780908</td>\n",
       "      <td>64.197531</td>\n",
       "      <td>20.422535</td>\n",
       "      <td>19.341564</td>\n",
       "      <td>19.796557</td>\n",
       "      <td>16.460905</td>\n",
       "      <td>1</td>\n",
       "      <td>54.652983</td>\n",
       "      <td>54.652983</td>\n",
       "      <td>32.440424</td>\n",
       "      <td>32.440424</td>\n",
       "      <td>12.906592</td>\n",
       "      <td>12.906592</td>\n",
       "      <td>43.31188</td>\n",
       "      <td>43.31188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>502043.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5538</td>\n",
       "      <td>1.5042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.324272</td>\n",
       "      <td>27.808220</td>\n",
       "      <td>28.756958</td>\n",
       "      <td>37.196262</td>\n",
       "      <td>0.519561</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>29.661421</td>\n",
       "      <td>34.715027</td>\n",
       "      <td>26.459145</td>\n",
       "      <td>47.881355</td>\n",
       "      <td>0.470353</td>\n",
       "      <td>0.138158</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>10.014306</td>\n",
       "      <td>38.297871</td>\n",
       "      <td>38.679245</td>\n",
       "      <td>24.637682</td>\n",
       "      <td>0.462878</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Kyle Gibson</td>\n",
       "      <td>fastball</td>\n",
       "      <td>59.780908</td>\n",
       "      <td>73.913043</td>\n",
       "      <td>20.422535</td>\n",
       "      <td>6.719368</td>\n",
       "      <td>19.796557</td>\n",
       "      <td>19.367589</td>\n",
       "      <td>2</td>\n",
       "      <td>54.652983</td>\n",
       "      <td>54.652983</td>\n",
       "      <td>32.440424</td>\n",
       "      <td>32.440424</td>\n",
       "      <td>12.906592</td>\n",
       "      <td>12.906592</td>\n",
       "      <td>43.31188</td>\n",
       "      <td>43.31188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>502043.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8157</td>\n",
       "      <td>1.8805</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.031658</td>\n",
       "      <td>30.121817</td>\n",
       "      <td>43.618515</td>\n",
       "      <td>28.175896</td>\n",
       "      <td>0.439553</td>\n",
       "      <td>0.199495</td>\n",
       "      <td>0.176768</td>\n",
       "      <td>30.668777</td>\n",
       "      <td>38.163265</td>\n",
       "      <td>39.130436</td>\n",
       "      <td>28.421053</td>\n",
       "      <td>0.371922</td>\n",
       "      <td>0.163551</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>9.259992</td>\n",
       "      <td>40.397350</td>\n",
       "      <td>40.740742</td>\n",
       "      <td>10.843373</td>\n",
       "      <td>0.425091</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>Kyle Gibson</td>\n",
       "      <td>fastball</td>\n",
       "      <td>56.006006</td>\n",
       "      <td>62.785863</td>\n",
       "      <td>34.459459</td>\n",
       "      <td>30.977131</td>\n",
       "      <td>9.534535</td>\n",
       "      <td>6.237006</td>\n",
       "      <td>3</td>\n",
       "      <td>54.652983</td>\n",
       "      <td>54.652983</td>\n",
       "      <td>32.440424</td>\n",
       "      <td>32.440424</td>\n",
       "      <td>12.906592</td>\n",
       "      <td>12.906592</td>\n",
       "      <td>43.31188</td>\n",
       "      <td>43.31188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>502043.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6814</td>\n",
       "      <td>1.7561</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.031658</td>\n",
       "      <td>30.121817</td>\n",
       "      <td>43.618515</td>\n",
       "      <td>28.175896</td>\n",
       "      <td>0.439553</td>\n",
       "      <td>0.199495</td>\n",
       "      <td>0.176768</td>\n",
       "      <td>30.668777</td>\n",
       "      <td>38.163265</td>\n",
       "      <td>39.130436</td>\n",
       "      <td>28.421053</td>\n",
       "      <td>0.371922</td>\n",
       "      <td>0.163551</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>9.259992</td>\n",
       "      <td>40.397350</td>\n",
       "      <td>40.740742</td>\n",
       "      <td>10.843373</td>\n",
       "      <td>0.425091</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>Kyle Gibson</td>\n",
       "      <td>breaking</td>\n",
       "      <td>56.006006</td>\n",
       "      <td>46.740859</td>\n",
       "      <td>34.459459</td>\n",
       "      <td>42.130366</td>\n",
       "      <td>9.534535</td>\n",
       "      <td>11.128776</td>\n",
       "      <td>4</td>\n",
       "      <td>54.652983</td>\n",
       "      <td>54.652983</td>\n",
       "      <td>32.440424</td>\n",
       "      <td>32.440424</td>\n",
       "      <td>12.906592</td>\n",
       "      <td>12.906592</td>\n",
       "      <td>43.31188</td>\n",
       "      <td>43.31188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>502043.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7385</td>\n",
       "      <td>1.8133</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.031658</td>\n",
       "      <td>30.121817</td>\n",
       "      <td>43.618515</td>\n",
       "      <td>28.175896</td>\n",
       "      <td>0.439553</td>\n",
       "      <td>0.199495</td>\n",
       "      <td>0.176768</td>\n",
       "      <td>30.668777</td>\n",
       "      <td>38.163265</td>\n",
       "      <td>39.130436</td>\n",
       "      <td>28.421053</td>\n",
       "      <td>0.371922</td>\n",
       "      <td>0.163551</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>9.259992</td>\n",
       "      <td>40.397350</td>\n",
       "      <td>40.740742</td>\n",
       "      <td>10.843373</td>\n",
       "      <td>0.425091</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>Kyle Gibson</td>\n",
       "      <td>fastball</td>\n",
       "      <td>56.006006</td>\n",
       "      <td>46.740859</td>\n",
       "      <td>34.459459</td>\n",
       "      <td>42.130366</td>\n",
       "      <td>9.534535</td>\n",
       "      <td>11.128776</td>\n",
       "      <td>5</td>\n",
       "      <td>54.652983</td>\n",
       "      <td>54.652983</td>\n",
       "      <td>32.440424</td>\n",
       "      <td>32.440424</td>\n",
       "      <td>12.906592</td>\n",
       "      <td>12.906592</td>\n",
       "      <td>43.31188</td>\n",
       "      <td>43.31188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pitch_type  game_date   pitcher  on_3b  on_2b  on_1b  sz_top  \\\n",
       "0  10018         1.0 2018-03-31  502043.0    0.0    0.0    0.0  3.6311   \n",
       "1  10019         2.0 2018-03-31  502043.0    0.0    0.0    0.0  3.5538   \n",
       "2  10020         1.0 2018-03-31  502043.0    0.0    0.0    0.0  3.8157   \n",
       "3  10021         3.0 2018-03-31  502043.0    0.0    0.0    0.0  3.6814   \n",
       "4  10022         1.0 2018-03-31  502043.0    0.0    0.0    0.0  3.7385   \n",
       "\n",
       "   sz_bot  at_bat_number  bat_score  score_diff  bases_loaded  \\\n",
       "0  1.5714              1        0.0         1.0             0   \n",
       "1  1.5042              1        0.0         1.0             0   \n",
       "2  1.8805              2        0.0         1.0             0   \n",
       "3  1.7561              2        0.0         1.0             0   \n",
       "4  1.8133              2        0.0         1.0             0   \n",
       "\n",
       "   fastball_perc_faced  fastball_chase_perc  fastball_bip_swung_perc  \\\n",
       "0            60.324272            27.808220                28.756958   \n",
       "1            60.324272            27.808220                28.756958   \n",
       "2            60.031658            30.121817                43.618515   \n",
       "3            60.031658            30.121817                43.618515   \n",
       "4            60.031658            30.121817                43.618515   \n",
       "\n",
       "   fastball_taken_strike_perc  fastball_est_woba  fastball_babip  \\\n",
       "0                   37.196262           0.519561        0.133333   \n",
       "1                   37.196262           0.519561        0.133333   \n",
       "2                   28.175896           0.439553        0.199495   \n",
       "3                   28.175896           0.439553        0.199495   \n",
       "4                   28.175896           0.439553        0.199495   \n",
       "\n",
       "   fastball_iso_value  breaking_perc_faced  breaking_chase_perc  \\\n",
       "0            0.203333            29.661421            34.715027   \n",
       "1            0.203333            29.661421            34.715027   \n",
       "2            0.176768            30.668777            38.163265   \n",
       "3            0.176768            30.668777            38.163265   \n",
       "4            0.176768            30.668777            38.163265   \n",
       "\n",
       "   breaking_bip_swung_perc  breaking_taken_strike_perc  breaking_est_woba  \\\n",
       "0                26.459145                   47.881355           0.470353   \n",
       "1                26.459145                   47.881355           0.470353   \n",
       "2                39.130436                   28.421053           0.371922   \n",
       "3                39.130436                   28.421053           0.371922   \n",
       "4                39.130436                   28.421053           0.371922   \n",
       "\n",
       "   breaking_babip  breaking_iso_value  offspeed_perc_faced  \\\n",
       "0        0.138158            0.111842            10.014306   \n",
       "1        0.138158            0.111842            10.014306   \n",
       "2        0.163551            0.186916             9.259992   \n",
       "3        0.163551            0.186916             9.259992   \n",
       "4        0.163551            0.186916             9.259992   \n",
       "\n",
       "   offspeed_chase_perc  offspeed_bip_swung_perc  offspeed_taken_strike_perc  \\\n",
       "0            38.297871                38.679245                   24.637682   \n",
       "1            38.297871                38.679245                   24.637682   \n",
       "2            40.397350                40.740742                   10.843373   \n",
       "3            40.397350                40.740742                   10.843373   \n",
       "4            40.397350                40.740742                   10.843373   \n",
       "\n",
       "   offspeed_est_woba  offspeed_babip  offspeed_iso_value  pitchout_perc_faced  \\\n",
       "0           0.462878        0.156250            0.265625             0.000000   \n",
       "1           0.462878        0.156250            0.265625             0.000000   \n",
       "2           0.425091        0.205479            0.315068             0.039573   \n",
       "3           0.425091        0.205479            0.315068             0.039573   \n",
       "4           0.425091        0.205479            0.315068             0.039573   \n",
       "\n",
       "   player_name pitch_cat  overall_fastball_perc  count_cat_fastball_perc  \\\n",
       "0  Kyle Gibson  fastball              59.780908                64.197531   \n",
       "1  Kyle Gibson  fastball              59.780908                73.913043   \n",
       "2  Kyle Gibson  fastball              56.006006                62.785863   \n",
       "3  Kyle Gibson  breaking              56.006006                46.740859   \n",
       "4  Kyle Gibson  fastball              56.006006                46.740859   \n",
       "\n",
       "   overall_breaking_perc  count_cat_breaking_perc  overall_offspeed_perc  \\\n",
       "0              20.422535                19.341564              19.796557   \n",
       "1              20.422535                 6.719368              19.796557   \n",
       "2              34.459459                30.977131               9.534535   \n",
       "3              34.459459                42.130366               9.534535   \n",
       "4              34.459459                42.130366               9.534535   \n",
       "\n",
       "   count_cat_offspeed_perc  pitch_count  L5_fastball_perc  L15_fastball_perc  \\\n",
       "0                16.460905            1         54.652983          54.652983   \n",
       "1                19.367589            2         54.652983          54.652983   \n",
       "2                 6.237006            3         54.652983          54.652983   \n",
       "3                11.128776            4         54.652983          54.652983   \n",
       "4                11.128776            5         54.652983          54.652983   \n",
       "\n",
       "   L5_breaking_perc  L15_breaking_perc  L5_offspeed_perc  L15_offspeed_perc  \\\n",
       "0         32.440424          32.440424         12.906592          12.906592   \n",
       "1         32.440424          32.440424         12.906592          12.906592   \n",
       "2         32.440424          32.440424         12.906592          12.906592   \n",
       "3         32.440424          32.440424         12.906592          12.906592   \n",
       "4         32.440424          32.440424         12.906592          12.906592   \n",
       "\n",
       "   L5_strike_perc  L15_strike_perc  pitcher_AB  prev_ab_run_scored  \\\n",
       "0        43.31188         43.31188         0.0                 0.0   \n",
       "1        43.31188         43.31188         0.0                 0.0   \n",
       "2        43.31188         43.31188         0.0                 0.0   \n",
       "3        43.31188         43.31188         0.0                 0.0   \n",
       "4        43.31188         43.31188         0.0                 0.0   \n",
       "\n",
       "   prev_ab_homerun  prev_ab_walk  prev_ab_basehit  prev_ab_strikeout  \\\n",
       "0              0.0           0.0              0.0                0.0   \n",
       "1              0.0           0.0              0.0                0.0   \n",
       "2              0.0           0.0              0.0                0.0   \n",
       "3              0.0           0.0              0.0                0.0   \n",
       "4              0.0           0.0              0.0                0.0   \n",
       "\n",
       "   PB_fastball  PB_offspeed  PB_breaking  on_base  outs_when_up_0.0  \\\n",
       "0    66.666667    33.333333     0.000000        0                 1   \n",
       "1    75.000000    25.000000     0.000000        0                 1   \n",
       "2    71.428571     0.000000    28.571429        0                 0   \n",
       "3    33.333333    33.333333    33.333333        0                 0   \n",
       "4    33.333333    33.333333    33.333333        0                 0   \n",
       "\n",
       "   outs_when_up_1.0  outs_when_up_2.0  inning_1.0  inning_2.0  inning_3.0  \\\n",
       "0                 0                 0           1           0           0   \n",
       "1                 0                 0           1           0           0   \n",
       "2                 1                 0           1           0           0   \n",
       "3                 1                 0           1           0           0   \n",
       "4                 1                 0           1           0           0   \n",
       "\n",
       "   inning_4.0  inning_5.0  inning_6.0  inning_7.0  inning_8.0  inning_17.0  \\\n",
       "0           0           0           0           0           0            0   \n",
       "1           0           0           0           0           0            0   \n",
       "2           0           0           0           0           0            0   \n",
       "3           0           0           0           0           0            0   \n",
       "4           0           0           0           0           0            0   \n",
       "\n",
       "   catcher_id_435064.0  catcher_id_460269.0  catcher_id_488771.0  \\\n",
       "0                    0                    0                    1   \n",
       "1                    0                    0                    1   \n",
       "2                    0                    0                    1   \n",
       "3                    0                    0                    1   \n",
       "4                    0                    0                    1   \n",
       "\n",
       "   catcher_id_553902.0  catcher_id_641598.0  pitch_number_1.0  \\\n",
       "0                    0                    0                 1   \n",
       "1                    0                    0                 0   \n",
       "2                    0                    0                 1   \n",
       "3                    0                    0                 0   \n",
       "4                    0                    0                 0   \n",
       "\n",
       "   pitch_number_2.0  pitch_number_3.0  pitch_number_4.0  pitch_number_5.0  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 1                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 1                 0                 0                 0   \n",
       "4                 0                 1                 0                 0   \n",
       "\n",
       "   pitch_number_6.0  pitch_number_7.0  pitch_number_8.0  pitch_number_9.0  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   pitch_number_10.0  pitch_number_11.0  pitch_number_12.0  pitch_number_13.0  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   stand_L  stand_R  inning_topbot_Bot  inning_topbot_Top  \\\n",
       "0        1        0                  1                  0   \n",
       "1        1        0                  1                  0   \n",
       "2        0        1                  1                  0   \n",
       "3        0        1                  1                  0   \n",
       "4        0        1                  1                  0   \n",
       "\n",
       "   if_fielding_alignment_Infield shift  if_fielding_alignment_Standard  \\\n",
       "0                                    1                               0   \n",
       "1                                    1                               0   \n",
       "2                                    0                               1   \n",
       "3                                    0                               1   \n",
       "4                                    0                               1   \n",
       "\n",
       "   if_fielding_alignment_Strategic  balls_0  balls_1  balls_2  balls_3  \\\n",
       "0                                0        1        0        0        0   \n",
       "1                                0        0        1        0        0   \n",
       "2                                0        1        0        0        0   \n",
       "3                                0        1        0        0        0   \n",
       "4                                0        0        1        0        0   \n",
       "\n",
       "   strikes_0  strikes_1  strikes_2  of_fielding_alignment_4th outfielder  \\\n",
       "0          1          0          0                                     0   \n",
       "1          1          0          0                                     0   \n",
       "2          1          0          0                                     0   \n",
       "3          0          1          0                                     0   \n",
       "4          0          1          0                                     0   \n",
       "\n",
       "   of_fielding_alignment_Standard  of_fielding_alignment_Strategic  _count_00  \\\n",
       "0                               1                                0          1   \n",
       "1                               1                                0          0   \n",
       "2                               1                                0          1   \n",
       "3                               1                                0          0   \n",
       "4                               1                                0          0   \n",
       "\n",
       "   _count_01  _count_02  _count_10  _count_11  _count_12  _count_20  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          1          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          1          0          0          0          0          0   \n",
       "4          0          0          0          1          0          0   \n",
       "\n",
       "   _count_21  _count_22  _count_30  _count_31  _count_32  count_cat_ahead  \\\n",
       "0          0          0          0          0          0                0   \n",
       "1          0          0          0          0          0                0   \n",
       "2          0          0          0          0          0                0   \n",
       "3          0          0          0          0          0                1   \n",
       "4          0          0          0          0          0                1   \n",
       "\n",
       "   count_cat_behind  count_cat_neutral  L1_pitch_type_CH  L1_pitch_type_CU  \\\n",
       "0                 0                  1                 0                 0   \n",
       "1                 1                  0                 0                 0   \n",
       "2                 0                  1                 0                 0   \n",
       "3                 0                  0                 0                 0   \n",
       "4                 0                  0                 0                 0   \n",
       "\n",
       "   L1_pitch_type_FF  L1_pitch_type_FT  L1_pitch_type_N/A  L1_pitch_type_SL  \\\n",
       "0                 0                 0                  1                 0   \n",
       "1                 1                 0                  0                 0   \n",
       "2                 0                 1                  0                 0   \n",
       "3                 1                 0                  0                 0   \n",
       "4                 0                 0                  0                 1   \n",
       "\n",
       "   L1_pitch_result_B  L1_pitch_result_N/A  L1_pitch_result_S  \\\n",
       "0                  0                    1                  0   \n",
       "1                  1                    0                  0   \n",
       "2                  0                    0                  0   \n",
       "3                  0                    0                  1   \n",
       "4                  1                    0                  0   \n",
       "\n",
       "   L1_pitch_result_X  L1_description_N/A  L1_description_ball  \\\n",
       "0                  0                   1                    0   \n",
       "1                  0                   0                    1   \n",
       "2                  1                   0                    0   \n",
       "3                  0                   0                    0   \n",
       "4                  0                   0                    1   \n",
       "\n",
       "   L1_description_blocked_ball  L1_description_called_strike  \\\n",
       "0                            0                             0   \n",
       "1                            0                             0   \n",
       "2                            0                             0   \n",
       "3                            0                             1   \n",
       "4                            0                             0   \n",
       "\n",
       "   L1_description_foul  L1_description_foul_bunt  L1_description_foul_tip  \\\n",
       "0                    0                         0                        0   \n",
       "1                    0                         0                        0   \n",
       "2                    0                         0                        0   \n",
       "3                    0                         0                        0   \n",
       "4                    0                         0                        0   \n",
       "\n",
       "   L1_description_hit_by_pitch  L1_description_hit_into_play  \\\n",
       "0                            0                             0   \n",
       "1                            0                             0   \n",
       "2                            0                             1   \n",
       "3                            0                             0   \n",
       "4                            0                             0   \n",
       "\n",
       "   L1_description_hit_into_play_no_out  L1_description_hit_into_play_score  \\\n",
       "0                                    0                                   0   \n",
       "1                                    0                                   0   \n",
       "2                                    0                                   0   \n",
       "3                                    0                                   0   \n",
       "4                                    0                                   0   \n",
       "\n",
       "   L1_description_missed_bunt  L1_description_swinging_strike  \\\n",
       "0                           0                               0   \n",
       "1                           0                               0   \n",
       "2                           0                               0   \n",
       "3                           0                               0   \n",
       "4                           0                               0   \n",
       "\n",
       "   L1_description_swinging_strike_blocked  L1_pitch_zone_-1.0  \\\n",
       "0                                       0                   1   \n",
       "1                                       0                   0   \n",
       "2                                       0                   0   \n",
       "3                                       0                   0   \n",
       "4                                       0                   0   \n",
       "\n",
       "   L1_pitch_zone_1.0  L1_pitch_zone_2.0  L1_pitch_zone_3.0  L1_pitch_zone_4.0  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   L1_pitch_zone_5.0  L1_pitch_zone_6.0  L1_pitch_zone_7.0  L1_pitch_zone_8.0  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  1   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   L1_pitch_zone_9.0  L1_pitch_zone_11.0  L1_pitch_zone_12.0  \\\n",
       "0                  0                   0                   0   \n",
       "1                  0                   0                   0   \n",
       "2                  0                   0                   0   \n",
       "3                  1                   0                   0   \n",
       "4                  0                   0                   0   \n",
       "\n",
       "   L1_pitch_zone_13.0  L1_pitch_zone_14.0  L1_batter_swung_-1.0  \\\n",
       "0                   0                   0                     1   \n",
       "1                   0                   1                     0   \n",
       "2                   0                   0                     0   \n",
       "3                   0                   0                     0   \n",
       "4                   0                   1                     0   \n",
       "\n",
       "   L1_batter_swung_0.0  L1_batter_swung_1.0  L1_chased_-1.0  L1_chased_0.0  \\\n",
       "0                    0                    0               1              0   \n",
       "1                    1                    0               0              1   \n",
       "2                    0                    1               0              1   \n",
       "3                    1                    0               0              1   \n",
       "4                    1                    0               0              1   \n",
       "\n",
       "   L1_chased_1.0  L2_pitch_type_CH  L2_pitch_type_CU  L2_pitch_type_FF  \\\n",
       "0              0                 0                 0                 0   \n",
       "1              0                 0                 0                 0   \n",
       "2              0                 0                 0                 1   \n",
       "3              0                 0                 0                 0   \n",
       "4              0                 0                 0                 1   \n",
       "\n",
       "   L2_pitch_type_FT  L2_pitch_type_N/A  L2_pitch_type_SL  L2_pitch_result_B  \\\n",
       "0                 0                  1                 0                  0   \n",
       "1                 0                  1                 0                  0   \n",
       "2                 0                  0                 0                  1   \n",
       "3                 1                  0                 0                  0   \n",
       "4                 0                  0                 0                  0   \n",
       "\n",
       "   L2_pitch_result_N/A  L2_pitch_result_S  L2_pitch_result_X  \\\n",
       "0                    1                  0                  0   \n",
       "1                    1                  0                  0   \n",
       "2                    0                  0                  0   \n",
       "3                    0                  0                  1   \n",
       "4                    0                  1                  0   \n",
       "\n",
       "   L2_description_N/A  L2_description_ball  L2_description_blocked_ball  \\\n",
       "0                   1                    0                            0   \n",
       "1                   1                    0                            0   \n",
       "2                   0                    1                            0   \n",
       "3                   0                    0                            0   \n",
       "4                   0                    0                            0   \n",
       "\n",
       "   L2_description_called_strike  L2_description_foul  \\\n",
       "0                             0                    0   \n",
       "1                             0                    0   \n",
       "2                             0                    0   \n",
       "3                             0                    0   \n",
       "4                             1                    0   \n",
       "\n",
       "   L2_description_foul_bunt  L2_description_foul_tip  \\\n",
       "0                         0                        0   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         0                        0   \n",
       "\n",
       "   L2_description_hit_by_pitch  L2_description_hit_into_play  \\\n",
       "0                            0                             0   \n",
       "1                            0                             0   \n",
       "2                            0                             0   \n",
       "3                            0                             1   \n",
       "4                            0                             0   \n",
       "\n",
       "   L2_description_hit_into_play_no_out  L2_description_hit_into_play_score  \\\n",
       "0                                    0                                   0   \n",
       "1                                    0                                   0   \n",
       "2                                    0                                   0   \n",
       "3                                    0                                   0   \n",
       "4                                    0                                   0   \n",
       "\n",
       "   L2_description_missed_bunt  L2_description_swinging_strike  \\\n",
       "0                           0                               0   \n",
       "1                           0                               0   \n",
       "2                           0                               0   \n",
       "3                           0                               0   \n",
       "4                           0                               0   \n",
       "\n",
       "   L2_description_swinging_strike_blocked  L2_pitch_zone_-1.0  \\\n",
       "0                                       0                   1   \n",
       "1                                       0                   1   \n",
       "2                                       0                   0   \n",
       "3                                       0                   0   \n",
       "4                                       0                   0   \n",
       "\n",
       "   L2_pitch_zone_1.0  L2_pitch_zone_2.0  L2_pitch_zone_3.0  L2_pitch_zone_4.0  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   L2_pitch_zone_5.0  L2_pitch_zone_6.0  L2_pitch_zone_7.0  L2_pitch_zone_8.0  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  1   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   L2_pitch_zone_9.0  L2_pitch_zone_11.0  L2_pitch_zone_12.0  \\\n",
       "0                  0                   0                   0   \n",
       "1                  0                   0                   0   \n",
       "2                  0                   0                   0   \n",
       "3                  0                   0                   0   \n",
       "4                  1                   0                   0   \n",
       "\n",
       "   L2_pitch_zone_13.0  L2_pitch_zone_14.0  L2_chased_-1.0  L2_chased_0.0  \\\n",
       "0                   0                   0               1              0   \n",
       "1                   0                   0               1              0   \n",
       "2                   0                   1               0              1   \n",
       "3                   0                   0               0              1   \n",
       "4                   0                   0               0              1   \n",
       "\n",
       "   L2_chased_1.0  L3_pitch_type_CH  L3_pitch_type_CU  L3_pitch_type_FF  \\\n",
       "0              0                 0                 0                 0   \n",
       "1              0                 0                 0                 0   \n",
       "2              0                 0                 0                 0   \n",
       "3              0                 0                 0                 1   \n",
       "4              0                 0                 0                 0   \n",
       "\n",
       "   L3_pitch_type_FT  L3_pitch_type_N/A  L3_pitch_type_SL  L3_description_N/A  \\\n",
       "0                 0                  1                 0                   1   \n",
       "1                 0                  1                 0                   1   \n",
       "2                 0                  1                 0                   1   \n",
       "3                 0                  0                 0                   0   \n",
       "4                 1                  0                 0                   0   \n",
       "\n",
       "   L3_description_ball  L3_description_blocked_ball  \\\n",
       "0                    0                            0   \n",
       "1                    0                            0   \n",
       "2                    0                            0   \n",
       "3                    1                            0   \n",
       "4                    0                            0   \n",
       "\n",
       "   L3_description_called_strike  L3_description_foul  \\\n",
       "0                             0                    0   \n",
       "1                             0                    0   \n",
       "2                             0                    0   \n",
       "3                             0                    0   \n",
       "4                             0                    0   \n",
       "\n",
       "   L3_description_foul_bunt  L3_description_foul_tip  \\\n",
       "0                         0                        0   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         0                        0   \n",
       "\n",
       "   L3_description_hit_by_pitch  L3_description_hit_into_play  \\\n",
       "0                            0                             0   \n",
       "1                            0                             0   \n",
       "2                            0                             0   \n",
       "3                            0                             0   \n",
       "4                            0                             1   \n",
       "\n",
       "   L3_description_hit_into_play_no_out  L3_description_hit_into_play_score  \\\n",
       "0                                    0                                   0   \n",
       "1                                    0                                   0   \n",
       "2                                    0                                   0   \n",
       "3                                    0                                   0   \n",
       "4                                    0                                   0   \n",
       "\n",
       "   L3_description_missed_bunt  L3_description_swinging_strike  \\\n",
       "0                           0                               0   \n",
       "1                           0                               0   \n",
       "2                           0                               0   \n",
       "3                           0                               0   \n",
       "4                           0                               0   \n",
       "\n",
       "   L3_description_swinging_strike_blocked  L3_pitch_zone_-1.0  \\\n",
       "0                                       0                   1   \n",
       "1                                       0                   1   \n",
       "2                                       0                   1   \n",
       "3                                       0                   0   \n",
       "4                                       0                   0   \n",
       "\n",
       "   L3_pitch_zone_1.0  L3_pitch_zone_2.0  L3_pitch_zone_3.0  L3_pitch_zone_4.0  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   L3_pitch_zone_5.0  L3_pitch_zone_6.0  L3_pitch_zone_7.0  L3_pitch_zone_8.0  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  1   \n",
       "\n",
       "   L3_pitch_zone_9.0  L3_pitch_zone_11.0  L3_pitch_zone_12.0  \\\n",
       "0                  0                   0                   0   \n",
       "1                  0                   0                   0   \n",
       "2                  0                   0                   0   \n",
       "3                  0                   0                   0   \n",
       "4                  0                   0                   0   \n",
       "\n",
       "   L3_pitch_zone_13.0  L3_pitch_zone_14.0  L3_chased_-1.0  L3_chased_0.0  \\\n",
       "0                   0                   0               1              0   \n",
       "1                   0                   0               1              0   \n",
       "2                   0                   0               1              0   \n",
       "3                   0                   1               0              1   \n",
       "4                   0                   0               0              1   \n",
       "\n",
       "   L3_chased_1.0  batting_order_slot_1.0  batting_order_slot_2.0  \\\n",
       "0              0                       1                       0   \n",
       "1              0                       1                       0   \n",
       "2              0                       0                       1   \n",
       "3              0                       0                       1   \n",
       "4              0                       0                       1   \n",
       "\n",
       "   batting_order_slot_3.0  batting_order_slot_4.0  batting_order_slot_5.0  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "\n",
       "   batting_order_slot_6.0  batting_order_slot_7.0  batting_order_slot_8.0  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "\n",
       "   batting_order_slot_9.0  batting_order_slot_10.0  batting_order_slot_11.0  \\\n",
       "0                       0                        0                        0   \n",
       "1                       0                        0                        0   \n",
       "2                       0                        0                        0   \n",
       "3                       0                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "\n",
       "   month_3  month_4  month_5  month_6  month_7  month_8  month_9  year_2018  \\\n",
       "0        1        0        0        0        0        0        0          1   \n",
       "1        1        0        0        0        0        0        0          1   \n",
       "2        1        0        0        0        0        0        0          1   \n",
       "3        1        0        0        0        0        0        0          1   \n",
       "4        1        0        0        0        0        0        0          1   \n",
       "\n",
       "   year_2019  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cat_encode(df, encode_type):\n",
    "    if encode_type == 'one_hot':\n",
    "        return one_hot_encode(df)\n",
    "    elif encode_type == 'custom_ordinal':\n",
    "        return custom_ordinal_ecode(df)\n",
    "\n",
    "\n",
    "df = cat_encode(df, 'one_hot')\n",
    "# df = cat_encode(df, 'custom_ordinal')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = True\n",
    "pca = False\n",
    "\n",
    "threshold = 99.45\n",
    "excluded_cols = ['index', 'player_name', 'game_date', 'pitch_cat', 'pitcher', 'pitch_type']\n",
    "\n",
    "if pca:\n",
    "    pca_df = pca_function(df, threshold, show_scree_plot=True, scaled=True, scaler_type= 'robust', excluded_cols=excluded_cols)\n",
    "    pca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_date(df, train_fraction):\n",
    "    train_idx = int(len(df) * train_fraction)\n",
    "    train_end_date = df.loc[train_idx].game_date\n",
    "    train = df[df['game_date'] < train_end_date]\n",
    "    test = df[df['game_date'] >= train_end_date]\n",
    "    print('train shape: ' + str(train.shape))\n",
    "    print('test shape: '+ str(test.shape))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (4858, 266)\n",
      "test shape: (891, 266)\n"
     ]
    }
   ],
   "source": [
    "if pca:\n",
    "    train, test = train_test_split_by_date(pca_df, .85)\n",
    "else:\n",
    "    train, test = train_test_split_by_date(df, .85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4858, 260), (891, 260), (4858,), (891,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'pitch_type'\n",
    "#target = 'fastball_target'\n",
    "\n",
    "#drop_cols = ['index', 'player_name', 'game_date', 'pitch_cat', 'pitcher', 'pitch_type', target]\n",
    "drop_cols = ['index', 'player_name', 'game_date', 'pitch_cat', 'pitcher', target]\n",
    "\n",
    "X = train.drop(columns=drop_cols)\n",
    "X_test = test.drop(columns=drop_cols)\n",
    "\n",
    "y = train[target]\n",
    "y_test = test[target]\n",
    "\n",
    "X.shape, X_test.shape, y.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    0.340263\n",
       "1.0    0.214903\n",
       "3.0    0.210169\n",
       "6.0    0.122273\n",
       "4.0    0.112392\n",
       "Name: pitch_type, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    0.307520\n",
       "3.0    0.199776\n",
       "1.0    0.191919\n",
       "6.0    0.166105\n",
       "4.0    0.134680\n",
       "Name: pitch_type, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Float columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols = ['fastball_perc_faced', 'fastball_chase_perc', 'fastball_bip_swung_perc', 'fastball_taken_strike_perc',\n",
    "              'fastball_est_woba', 'fastball_babip', 'fastball_iso_value', 'breaking_perc_faced', 'breaking_chase_perc',\n",
    "              'breaking_bip_swung_perc', 'breaking_taken_strike_perc', 'breaking_est_woba', 'breaking_babip',\n",
    "              'breaking_iso_value', 'offspeed_perc_faced', 'offspeed_chase_perc', 'offspeed_bip_swung_perc',\n",
    "              'offspeed_taken_strike_perc', 'offspeed_est_woba', 'offspeed_babip', 'offspeed_iso_value',\n",
    "              'pitchout_perc_faced', 'overall_fastball_perc', 'count_cat_fastball_perc', 'overall_breaking_perc',\n",
    "              'count_cat_breaking_perc', 'overall_offspeed_perc', 'count_cat_offspeed_perc', 'L5_fastball_perc',\n",
    "              'L15_fastball_perc', 'L5_breaking_perc', 'L15_breaking_perc', 'L5_offspeed_perc', 'L15_offspeed_perc',\n",
    "              'L5_strike_perc', 'L15_strike_perc', 'PB_fastball', 'PB_breaking', 'PB_offspeed']\n",
    "\n",
    "scaler = RobustScaler()\n",
    "if pca == False:\n",
    "    X[scale_cols] = scaler.fit_transform(X[scale_cols].values)\n",
    "    X_test[scale_cols] = scaler.transform(X_test[scale_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4858, 260), (891, 260), (4858,), (891,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_test.shape, y.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 6.16 s, total: 22.8 s\n",
      "Wall time: 6min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#with bootstrap:\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 75, 100, 125, 150, 200, 300],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 15, 25],\n",
    "    'min_samples_split': [5, 8, 12, 18, 25],\n",
    "    'min_samples_leaf': [3, 5, 7, 10],\n",
    "    'max_features': ['auto', 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'warm_start': [False, True],\n",
    "    'oob_score': [False, True]\n",
    "}\n",
    "\n",
    "rfc_with_bootstrap = RandomForestClassifier(n_jobs=-1, random_state=42, criterion='gini', bootstrap=True)\n",
    "\n",
    "# search = GridSearchCV(\n",
    "#     estimator = rfc, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=4,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True)\n",
    "\n",
    "rfc_with_bootstrap_search = RandomizedSearchCV(estimator=rfc_with_bootstrap, param_distributions=param_grid, n_iter=300, \n",
    "                            scoring={'Accuracy':'accuracy', 'Balanced_accuracy':'balanced_accuracy'}, n_jobs=-1, iid='warn', refit='Accuracy', cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "rfc_with_bootstrap_search.fit(X, y)\n",
    "\n",
    "rfc_bootstrap_search_results = pd.DataFrame(rfc_with_bootstrap_search.cv_results_).sort_values(by='rank_test_Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_warm_start</th>\n",
       "      <th>param_oob_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_Accuracy</th>\n",
       "      <th>split1_test_Accuracy</th>\n",
       "      <th>split2_test_Accuracy</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>split0_train_Accuracy</th>\n",
       "      <th>split1_train_Accuracy</th>\n",
       "      <th>split2_train_Accuracy</th>\n",
       "      <th>mean_train_Accuracy</th>\n",
       "      <th>std_train_Accuracy</th>\n",
       "      <th>split0_test_Balanced_accuracy</th>\n",
       "      <th>split1_test_Balanced_accuracy</th>\n",
       "      <th>split2_test_Balanced_accuracy</th>\n",
       "      <th>mean_test_Balanced_accuracy</th>\n",
       "      <th>std_test_Balanced_accuracy</th>\n",
       "      <th>rank_test_Balanced_accuracy</th>\n",
       "      <th>split0_train_Balanced_accuracy</th>\n",
       "      <th>split1_train_Balanced_accuracy</th>\n",
       "      <th>split2_train_Balanced_accuracy</th>\n",
       "      <th>mean_train_Balanced_accuracy</th>\n",
       "      <th>std_train_Balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1.283145</td>\n",
       "      <td>0.083889</td>\n",
       "      <td>0.561637</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>{'warm_start': True, 'oob_score': True, 'n_est...</td>\n",
       "      <td>0.452619</td>\n",
       "      <td>0.488810</td>\n",
       "      <td>0.452241</td>\n",
       "      <td>0.464559</td>\n",
       "      <td>0.017151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499411</td>\n",
       "      <td>0.488954</td>\n",
       "      <td>0.518399</td>\n",
       "      <td>0.502255</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>0.290716</td>\n",
       "      <td>0.352590</td>\n",
       "      <td>0.336232</td>\n",
       "      <td>0.326502</td>\n",
       "      <td>0.026185</td>\n",
       "      <td>198</td>\n",
       "      <td>0.374149</td>\n",
       "      <td>0.358279</td>\n",
       "      <td>0.389955</td>\n",
       "      <td>0.374128</td>\n",
       "      <td>0.012932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.270003</td>\n",
       "      <td>0.122291</td>\n",
       "      <td>0.894931</td>\n",
       "      <td>0.155743</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>{'warm_start': False, 'oob_score': True, 'n_es...</td>\n",
       "      <td>0.434373</td>\n",
       "      <td>0.485277</td>\n",
       "      <td>0.451651</td>\n",
       "      <td>0.457098</td>\n",
       "      <td>0.021140</td>\n",
       "      <td>2</td>\n",
       "      <td>0.530053</td>\n",
       "      <td>0.516937</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.527291</td>\n",
       "      <td>0.007583</td>\n",
       "      <td>0.284524</td>\n",
       "      <td>0.360402</td>\n",
       "      <td>0.335872</td>\n",
       "      <td>0.326921</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>197</td>\n",
       "      <td>0.409561</td>\n",
       "      <td>0.401908</td>\n",
       "      <td>0.410183</td>\n",
       "      <td>0.407218</td>\n",
       "      <td>0.003763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.639285</td>\n",
       "      <td>0.216937</td>\n",
       "      <td>1.393852</td>\n",
       "      <td>0.132487</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>{'warm_start': False, 'oob_score': False, 'n_e...</td>\n",
       "      <td>0.443790</td>\n",
       "      <td>0.502356</td>\n",
       "      <td>0.418632</td>\n",
       "      <td>0.454938</td>\n",
       "      <td>0.035072</td>\n",
       "      <td>3</td>\n",
       "      <td>0.474956</td>\n",
       "      <td>0.477761</td>\n",
       "      <td>0.492788</td>\n",
       "      <td>0.481835</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.289948</td>\n",
       "      <td>0.377607</td>\n",
       "      <td>0.314047</td>\n",
       "      <td>0.327199</td>\n",
       "      <td>0.036982</td>\n",
       "      <td>196</td>\n",
       "      <td>0.373325</td>\n",
       "      <td>0.359302</td>\n",
       "      <td>0.390862</td>\n",
       "      <td>0.374497</td>\n",
       "      <td>0.012911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.710974</td>\n",
       "      <td>0.277859</td>\n",
       "      <td>0.773051</td>\n",
       "      <td>0.187189</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>150</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>{'warm_start': False, 'oob_score': False, 'n_e...</td>\n",
       "      <td>0.430253</td>\n",
       "      <td>0.488810</td>\n",
       "      <td>0.442217</td>\n",
       "      <td>0.453760</td>\n",
       "      <td>0.025265</td>\n",
       "      <td>4</td>\n",
       "      <td>0.538892</td>\n",
       "      <td>0.516642</td>\n",
       "      <td>0.539005</td>\n",
       "      <td>0.531513</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.282478</td>\n",
       "      <td>0.362360</td>\n",
       "      <td>0.330821</td>\n",
       "      <td>0.325209</td>\n",
       "      <td>0.032860</td>\n",
       "      <td>200</td>\n",
       "      <td>0.414665</td>\n",
       "      <td>0.399211</td>\n",
       "      <td>0.417077</td>\n",
       "      <td>0.410318</td>\n",
       "      <td>0.007915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2.846613</td>\n",
       "      <td>0.106674</td>\n",
       "      <td>1.362875</td>\n",
       "      <td>0.072144</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>{'warm_start': False, 'oob_score': False, 'n_e...</td>\n",
       "      <td>0.444379</td>\n",
       "      <td>0.485866</td>\n",
       "      <td>0.418632</td>\n",
       "      <td>0.449637</td>\n",
       "      <td>0.027694</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474956</td>\n",
       "      <td>0.478351</td>\n",
       "      <td>0.492788</td>\n",
       "      <td>0.482031</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.290263</td>\n",
       "      <td>0.353109</td>\n",
       "      <td>0.314047</td>\n",
       "      <td>0.319136</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>216</td>\n",
       "      <td>0.373325</td>\n",
       "      <td>0.358359</td>\n",
       "      <td>0.390862</td>\n",
       "      <td>0.374182</td>\n",
       "      <td>0.013283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "276       1.283145      0.083889         0.561637        0.089108   \n",
       "178       1.270003      0.122291         0.894931        0.155743   \n",
       "1         3.639285      0.216937         1.393852        0.132487   \n",
       "85        1.710974      0.277859         0.773051        0.187189   \n",
       "77        2.846613      0.106674         1.362875        0.072144   \n",
       "\n",
       "    param_warm_start param_oob_score param_n_estimators  \\\n",
       "276             True            True                125   \n",
       "178            False            True                 25   \n",
       "1              False           False                300   \n",
       "85             False           False                150   \n",
       "77             False           False                200   \n",
       "\n",
       "    param_min_samples_split param_min_samples_leaf param_max_features  \\\n",
       "276                       5                      3               auto   \n",
       "178                       8                     10               auto   \n",
       "1                         8                      5                0.5   \n",
       "85                       25                      5               auto   \n",
       "77                        8                      7                0.5   \n",
       "\n",
       "    param_max_depth param_class_weight  \\\n",
       "276               4               None   \n",
       "178               6               None   \n",
       "1                 2               None   \n",
       "85                6               None   \n",
       "77                2               None   \n",
       "\n",
       "                                                params  split0_test_Accuracy  \\\n",
       "276  {'warm_start': True, 'oob_score': True, 'n_est...              0.452619   \n",
       "178  {'warm_start': False, 'oob_score': True, 'n_es...              0.434373   \n",
       "1    {'warm_start': False, 'oob_score': False, 'n_e...              0.443790   \n",
       "85   {'warm_start': False, 'oob_score': False, 'n_e...              0.430253   \n",
       "77   {'warm_start': False, 'oob_score': False, 'n_e...              0.444379   \n",
       "\n",
       "     split1_test_Accuracy  split2_test_Accuracy  mean_test_Accuracy  \\\n",
       "276              0.488810              0.452241            0.464559   \n",
       "178              0.485277              0.451651            0.457098   \n",
       "1                0.502356              0.418632            0.454938   \n",
       "85               0.488810              0.442217            0.453760   \n",
       "77               0.485866              0.418632            0.449637   \n",
       "\n",
       "     std_test_Accuracy  rank_test_Accuracy  split0_train_Accuracy  \\\n",
       "276           0.017151                   1               0.499411   \n",
       "178           0.021140                   2               0.530053   \n",
       "1             0.035072                   3               0.474956   \n",
       "85            0.025265                   4               0.538892   \n",
       "77            0.027694                   5               0.474956   \n",
       "\n",
       "     split1_train_Accuracy  split2_train_Accuracy  mean_train_Accuracy  \\\n",
       "276               0.488954               0.518399             0.502255   \n",
       "178               0.516937               0.534884             0.527291   \n",
       "1                 0.477761               0.492788             0.481835   \n",
       "85                0.516642               0.539005             0.531513   \n",
       "77                0.478351               0.492788             0.482031   \n",
       "\n",
       "     std_train_Accuracy  split0_test_Balanced_accuracy  \\\n",
       "276            0.012188                       0.290716   \n",
       "178            0.007583                       0.284524   \n",
       "1              0.007829                       0.289948   \n",
       "85             0.010515                       0.282478   \n",
       "77             0.007731                       0.290263   \n",
       "\n",
       "     split1_test_Balanced_accuracy  split2_test_Balanced_accuracy  \\\n",
       "276                       0.352590                       0.336232   \n",
       "178                       0.360402                       0.335872   \n",
       "1                         0.377607                       0.314047   \n",
       "85                        0.362360                       0.330821   \n",
       "77                        0.353109                       0.314047   \n",
       "\n",
       "     mean_test_Balanced_accuracy  std_test_Balanced_accuracy  \\\n",
       "276                     0.326502                    0.026185   \n",
       "178                     0.326921                    0.031623   \n",
       "1                       0.327199                    0.036982   \n",
       "85                      0.325209                    0.032860   \n",
       "77                      0.319136                    0.025914   \n",
       "\n",
       "     rank_test_Balanced_accuracy  split0_train_Balanced_accuracy  \\\n",
       "276                          198                        0.374149   \n",
       "178                          197                        0.409561   \n",
       "1                            196                        0.373325   \n",
       "85                           200                        0.414665   \n",
       "77                           216                        0.373325   \n",
       "\n",
       "     split1_train_Balanced_accuracy  split2_train_Balanced_accuracy  \\\n",
       "276                        0.358279                        0.389955   \n",
       "178                        0.401908                        0.410183   \n",
       "1                          0.359302                        0.390862   \n",
       "85                         0.399211                        0.417077   \n",
       "77                         0.358359                        0.390862   \n",
       "\n",
       "     mean_train_Balanced_accuracy  std_train_Balanced_accuracy  \n",
       "276                      0.374128                     0.012932  \n",
       "178                      0.407218                     0.003763  \n",
       "1                        0.374497                     0.012911  \n",
       "85                       0.410318                     0.007915  \n",
       "77                       0.374182                     0.013283  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_bootstrap_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.81 s, sys: 413 ms, total: 10.2 s\n",
      "Wall time: 9min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#w/o bootstrap:\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 75, 100, 125, 150, 200, 300],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 15, 25],\n",
    "    'min_samples_split': [5, 8, 12, 18, 25],\n",
    "    'min_samples_leaf': [3, 5, 7, 10, 15, 25],\n",
    "    'max_features': ['auto', 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'class_weight': [None],\n",
    "    'warm_start': [False, True]\n",
    "}\n",
    "\n",
    "rfc_without_bootstrap = RandomForestClassifier(n_jobs=-1, random_state=42, criterion='gini', bootstrap=False)\n",
    "\n",
    "# search = GridSearchCV(\n",
    "#     estimator = rfc, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=2,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True)\n",
    "\n",
    "rfc_without_bootstrap_search = RandomizedSearchCV(estimator=rfc_without_bootstrap, param_distributions=param_grid, n_iter=300, \n",
    "                            scoring={'Accuracy':'accuracy', 'Balanced_accuracy':'balanced_accuracy'}, n_jobs=-1, iid='warn', refit='Accuracy', cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "rfc_without_bootstrap_search.fit(X, y)\n",
    "\n",
    "rfc_without_bootstrap_search_results = pd.DataFrame(rfc_without_bootstrap_search.cv_results_).sort_values(by='rank_test_Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_warm_start</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_Accuracy</th>\n",
       "      <th>split1_test_Accuracy</th>\n",
       "      <th>split2_test_Accuracy</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>split0_train_Accuracy</th>\n",
       "      <th>split1_train_Accuracy</th>\n",
       "      <th>split2_train_Accuracy</th>\n",
       "      <th>mean_train_Accuracy</th>\n",
       "      <th>std_train_Accuracy</th>\n",
       "      <th>split0_test_Balanced_accuracy</th>\n",
       "      <th>split1_test_Balanced_accuracy</th>\n",
       "      <th>split2_test_Balanced_accuracy</th>\n",
       "      <th>mean_test_Balanced_accuracy</th>\n",
       "      <th>std_test_Balanced_accuracy</th>\n",
       "      <th>rank_test_Balanced_accuracy</th>\n",
       "      <th>split0_train_Balanced_accuracy</th>\n",
       "      <th>split1_train_Balanced_accuracy</th>\n",
       "      <th>split2_train_Balanced_accuracy</th>\n",
       "      <th>mean_train_Balanced_accuracy</th>\n",
       "      <th>std_train_Balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>5.685020</td>\n",
       "      <td>0.586447</td>\n",
       "      <td>2.058844</td>\n",
       "      <td>0.035073</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>{'warm_start': False, 'n_estimators': 300, 'mi...</td>\n",
       "      <td>0.453796</td>\n",
       "      <td>0.492344</td>\n",
       "      <td>0.455189</td>\n",
       "      <td>0.467112</td>\n",
       "      <td>0.017854</td>\n",
       "      <td>1</td>\n",
       "      <td>0.498527</td>\n",
       "      <td>0.486009</td>\n",
       "      <td>0.516044</td>\n",
       "      <td>0.500193</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.290969</td>\n",
       "      <td>0.363046</td>\n",
       "      <td>0.337244</td>\n",
       "      <td>0.330409</td>\n",
       "      <td>0.029826</td>\n",
       "      <td>2</td>\n",
       "      <td>0.373670</td>\n",
       "      <td>0.361894</td>\n",
       "      <td>0.387218</td>\n",
       "      <td>0.374261</td>\n",
       "      <td>0.010347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1.381062</td>\n",
       "      <td>0.024753</td>\n",
       "      <td>1.373914</td>\n",
       "      <td>0.117872</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>{'warm_start': False, 'n_estimators': 50, 'min...</td>\n",
       "      <td>0.452031</td>\n",
       "      <td>0.487633</td>\n",
       "      <td>0.459316</td>\n",
       "      <td>0.466326</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>2</td>\n",
       "      <td>0.496464</td>\n",
       "      <td>0.485420</td>\n",
       "      <td>0.514277</td>\n",
       "      <td>0.498720</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.292045</td>\n",
       "      <td>0.351382</td>\n",
       "      <td>0.341662</td>\n",
       "      <td>0.328350</td>\n",
       "      <td>0.025992</td>\n",
       "      <td>8</td>\n",
       "      <td>0.374388</td>\n",
       "      <td>0.356442</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.372642</td>\n",
       "      <td>0.012576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1.280115</td>\n",
       "      <td>0.151250</td>\n",
       "      <td>1.093478</td>\n",
       "      <td>0.093455</td>\n",
       "      <td>False</td>\n",
       "      <td>125</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>{'warm_start': False, 'n_estimators': 125, 'mi...</td>\n",
       "      <td>0.450265</td>\n",
       "      <td>0.484099</td>\n",
       "      <td>0.458137</td>\n",
       "      <td>0.464167</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>3</td>\n",
       "      <td>0.498232</td>\n",
       "      <td>0.485420</td>\n",
       "      <td>0.515160</td>\n",
       "      <td>0.499604</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.289458</td>\n",
       "      <td>0.351133</td>\n",
       "      <td>0.340507</td>\n",
       "      <td>0.327020</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>12</td>\n",
       "      <td>0.374336</td>\n",
       "      <td>0.357634</td>\n",
       "      <td>0.387121</td>\n",
       "      <td>0.373030</td>\n",
       "      <td>0.012073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.811469</td>\n",
       "      <td>0.389769</td>\n",
       "      <td>1.086159</td>\n",
       "      <td>0.095428</td>\n",
       "      <td>True</td>\n",
       "      <td>125</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>{'warm_start': True, 'n_estimators': 125, 'min...</td>\n",
       "      <td>0.450265</td>\n",
       "      <td>0.484099</td>\n",
       "      <td>0.458137</td>\n",
       "      <td>0.464167</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>3</td>\n",
       "      <td>0.498232</td>\n",
       "      <td>0.485420</td>\n",
       "      <td>0.515160</td>\n",
       "      <td>0.499604</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.289458</td>\n",
       "      <td>0.351133</td>\n",
       "      <td>0.340507</td>\n",
       "      <td>0.327020</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>12</td>\n",
       "      <td>0.374336</td>\n",
       "      <td>0.357634</td>\n",
       "      <td>0.387121</td>\n",
       "      <td>0.373030</td>\n",
       "      <td>0.012073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.560679</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>1.224703</td>\n",
       "      <td>0.051937</td>\n",
       "      <td>False</td>\n",
       "      <td>75</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>{'warm_start': False, 'n_estimators': 75, 'min...</td>\n",
       "      <td>0.447322</td>\n",
       "      <td>0.485277</td>\n",
       "      <td>0.456368</td>\n",
       "      <td>0.462988</td>\n",
       "      <td>0.016189</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500884</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.516044</td>\n",
       "      <td>0.500881</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.288826</td>\n",
       "      <td>0.351591</td>\n",
       "      <td>0.337874</td>\n",
       "      <td>0.326085</td>\n",
       "      <td>0.026950</td>\n",
       "      <td>14</td>\n",
       "      <td>0.377139</td>\n",
       "      <td>0.358362</td>\n",
       "      <td>0.387875</td>\n",
       "      <td>0.374459</td>\n",
       "      <td>0.012197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "268       5.685020      0.586447         2.058844        0.035073   \n",
       "216       1.381062      0.024753         1.373914        0.117872   \n",
       "256       1.280115      0.151250         1.093478        0.093455   \n",
       "20        1.811469      0.389769         1.086159        0.095428   \n",
       "69        1.560679      0.187943         1.224703        0.051937   \n",
       "\n",
       "    param_warm_start param_n_estimators param_min_samples_split  \\\n",
       "268            False                300                       8   \n",
       "216            False                 50                      12   \n",
       "256            False                125                      25   \n",
       "20              True                125                      18   \n",
       "69             False                 75                      18   \n",
       "\n",
       "    param_min_samples_leaf param_max_features param_max_depth  \\\n",
       "268                      5               auto               4   \n",
       "216                     10               auto               4   \n",
       "256                     15               auto               4   \n",
       "20                      15               auto               4   \n",
       "69                       5               auto               4   \n",
       "\n",
       "    param_class_weight                                             params  \\\n",
       "268               None  {'warm_start': False, 'n_estimators': 300, 'mi...   \n",
       "216               None  {'warm_start': False, 'n_estimators': 50, 'min...   \n",
       "256               None  {'warm_start': False, 'n_estimators': 125, 'mi...   \n",
       "20                None  {'warm_start': True, 'n_estimators': 125, 'min...   \n",
       "69                None  {'warm_start': False, 'n_estimators': 75, 'min...   \n",
       "\n",
       "     split0_test_Accuracy  split1_test_Accuracy  split2_test_Accuracy  \\\n",
       "268              0.453796              0.492344              0.455189   \n",
       "216              0.452031              0.487633              0.459316   \n",
       "256              0.450265              0.484099              0.458137   \n",
       "20               0.450265              0.484099              0.458137   \n",
       "69               0.447322              0.485277              0.456368   \n",
       "\n",
       "     mean_test_Accuracy  std_test_Accuracy  rank_test_Accuracy  \\\n",
       "268            0.467112           0.017854                   1   \n",
       "216            0.466326           0.015359                   2   \n",
       "256            0.464167           0.014458                   3   \n",
       "20             0.464167           0.014458                   3   \n",
       "69             0.462988           0.016189                   5   \n",
       "\n",
       "     split0_train_Accuracy  split1_train_Accuracy  split2_train_Accuracy  \\\n",
       "268               0.498527               0.486009               0.516044   \n",
       "216               0.496464               0.485420               0.514277   \n",
       "256               0.498232               0.485420               0.515160   \n",
       "20                0.498232               0.485420               0.515160   \n",
       "69                0.500884               0.485714               0.516044   \n",
       "\n",
       "     mean_train_Accuracy  std_train_Accuracy  split0_test_Balanced_accuracy  \\\n",
       "268             0.500193            0.012318                       0.290969   \n",
       "216             0.498720            0.011889                       0.292045   \n",
       "256             0.499604            0.012180                       0.289458   \n",
       "20              0.499604            0.012180                       0.289458   \n",
       "69              0.500881            0.012382                       0.288826   \n",
       "\n",
       "     split1_test_Balanced_accuracy  split2_test_Balanced_accuracy  \\\n",
       "268                       0.363046                       0.337244   \n",
       "216                       0.351382                       0.341662   \n",
       "256                       0.351133                       0.340507   \n",
       "20                        0.351133                       0.340507   \n",
       "69                        0.351591                       0.337874   \n",
       "\n",
       "     mean_test_Balanced_accuracy  std_test_Balanced_accuracy  \\\n",
       "268                     0.330409                    0.029826   \n",
       "216                     0.328350                    0.025992   \n",
       "256                     0.327020                    0.026928   \n",
       "20                      0.327020                    0.026928   \n",
       "69                      0.326085                    0.026950   \n",
       "\n",
       "     rank_test_Balanced_accuracy  split0_train_Balanced_accuracy  \\\n",
       "268                            2                        0.373670   \n",
       "216                            8                        0.374388   \n",
       "256                           12                        0.374336   \n",
       "20                            12                        0.374336   \n",
       "69                            14                        0.377139   \n",
       "\n",
       "     split1_train_Balanced_accuracy  split2_train_Balanced_accuracy  \\\n",
       "268                        0.361894                        0.387218   \n",
       "216                        0.356442                        0.387097   \n",
       "256                        0.357634                        0.387121   \n",
       "20                         0.357634                        0.387121   \n",
       "69                         0.358362                        0.387875   \n",
       "\n",
       "     mean_train_Balanced_accuracy  std_train_Balanced_accuracy  \n",
       "268                      0.374261                     0.010347  \n",
       "216                      0.372642                     0.012576  \n",
       "256                      0.373030                     0.012073  \n",
       "20                       0.373030                     0.012073  \n",
       "69                       0.374459                     0.012197  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_without_bootstrap_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_models(search_results, model_type, n=10, k=100, accuracy_metric='accuracy'):\n",
    "    results_list = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        model_dict = {}\n",
    "        #grab the params from the params column of the dataframe for the model in this row:\n",
    "        params = search_results.iloc[i]['params']\n",
    "        if model_type == 'rfc_bootstrap':\n",
    "            model = RandomForestClassifier(n_jobs=-1, random_state=42, criterion='gini', class_weight=params['class_weight'],\n",
    "                                 max_depth=params['max_depth'], max_features=params['max_features'], min_samples_leaf=params['min_samples_leaf'],\n",
    "                                 min_samples_split=params['min_samples_split'], n_estimators=params['n_estimators'], oob_score=params['oob_score'],\n",
    "                                 warm_start=params['warm_start'])\n",
    "        elif model_type == 'rfc_without_bootstrap':\n",
    "            model = RandomForestClassifier(n_jobs=-1, random_state=42, criterion='gini', class_weight=params['class_weight'],\n",
    "                                 max_depth=params['max_depth'], max_features=params['max_features'], min_samples_leaf=params['min_samples_leaf'],\n",
    "                                 min_samples_split=params['min_samples_split'], n_estimators=params['n_estimators'], warm_start=params['warm_start'])\n",
    "            \n",
    "        elif model_type == 'gbc':\n",
    "            model = GradientBoostingClassifier(random_state=42, loss=params['loss'], learning_rate=params['learning_rate'], n_estimators=params['n_estimators'],\n",
    "                                subsample=params['subsample'], min_samples_split=params['min_samples_split'], min_samples_leaf=params['min_samples_leaf'],\n",
    "                                max_depth=params['max_depth'], max_features=params['max_features'], tol=params['tol'])\n",
    "            \n",
    "        elif model_type == 'xgb':\n",
    "            model = XGBClassifier(verbosity=0, n_jobs=-1, random_state=42, num_class=num_classes, objective='multi:softmax',\n",
    "                                     booster=params['booster'], eta=params['eta'], gamma=params['gamma'], max_depth=params['max_depth'],\n",
    "                                     min_child_weight=params['min_child_weight'], max_delta_step=params['max_delta_step'], \n",
    "                                     colsample_bytree=params['colsample_bytree'], colsample_bylevel=params['colsample_bylevel'],\n",
    "                                     colsample_bynode=params['colsample_bynode'])\n",
    "    \n",
    "        elif model_type == 'svm':\n",
    "            model = SVC(random_state=42, degree=params['degree'], kernel=params['kernel'], tol=params['tol'],\n",
    "                       C=params['C'], shrinking=params['shrinking'], class_weight=params['class_weight'], max_iter=params['max_iter'],\n",
    "                       decision_function_shape=params['decision_function_shape'], gamma=params['gamma'])\n",
    "        \n",
    "        elif model_type == 'lin_SVC':            \n",
    "            model = LinearSVC(random_state=42, penalty=params['penalty'], loss=params['loss'], dual=params['dual'], tol=params['tol'],\n",
    "                             C=params['C'], class_weight=params['class_weight'], max_iter=params['max_iter'], fit_intercept=params['fit_intercept'])\n",
    "            \n",
    "        elif model_type == 'sgd':\n",
    "            model = SGDClassifier(random_state=42, penalty=params['penalty'], alpha=params['alpha'], loss=params['loss'], tol=params['tol'],\n",
    "                                  class_weight=params['class_weight'], max_iter=params['max_iter'], fit_intercept=params['fit_intercept'],\n",
    "                                  warm_start=params['warm_start'], learning_rate=params['learning_rate'], shuffle=params['shuffle'])\n",
    "            \n",
    "        elif model_type == 'lda':\n",
    "            model = lda = LinearDiscriminantAnalysis(solver=params['solver'], shrinkage=params['shrinkage'], tol=params['tol'], \n",
    "                                                    n_components=params['n_components'])\n",
    "            \n",
    "        elif model_type == 'knn':\n",
    "            model = KNeighborsClassifier(n_neighbors=params['n_neighbors'], weights=params['weights'], \n",
    "                                        algorithm=params['algorithm'], leaf_size=params['leaf_size'], p=params['p'])\n",
    "        \n",
    "        elif model_type == 'lr':\n",
    "            model = LogisticRegression(random_state=42, n_jobs=-1, penalty=params['penalty'], dual=params['dual'], tol=params['tol'],\n",
    "                                      C=params['C'], fit_intercept=params['fit_intercept'], class_weight=params['class_weight'],\n",
    "                                      solver=params['solver'], max_iter=params['max_iter'], multi_class=params['multi_class'], \n",
    "                                      warm_start=params['warm_start'])\n",
    "\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        try:\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "        except:\n",
    "            f1 = 'N/A'\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        try:\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        except:\n",
    "            roc_auc = 'N/A'\n",
    "            \n",
    "        model_dict['model'] = [model]\n",
    "        model_dict['accuracy'] = accuracy\n",
    "        model_dict['balanced_accuracy'] = balanced_accuracy\n",
    "        model_dict['f1_score'] = f1\n",
    "        model_dict['r2_score'] = r2\n",
    "        model_dict['roc_auc_score'] = roc_auc\n",
    "        \n",
    "        #convert the dict to df and append to list\n",
    "        results_list.append(pd.DataFrame(model_dict))\n",
    "    \n",
    "    #return df with the top n highest accuracy models (on the test data)\n",
    "    results_df = pd.concat(results_list, axis=0).sort_values(by=accuracy_metric, ascending=False).head(n)\n",
    "    results_df['model_type'] = results_df['model'].astype(str).apply(lambda x: x.split('(')[0]).reset_index(drop=True)    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 51s, sys: 1.71 s, total: 3min 53s\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_rfc_bootstrap = get_top_n_models(rfc_bootstrap_search_results, 'rfc_bootstrap', k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 1.79 s, total: 1min 17s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_rfc_without_bootstrap = get_top_n_models(rfc_without_bootstrap_search_results, 'rfc_without_bootstrap', k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.462891</td>\n",
       "      <td>0.354989</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.351739</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.346947</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.355142</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.348985</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.344252</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.346073</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.346974</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.346298</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.356503</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.348051</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.349697</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.347716</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.369776</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.346298</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.355142</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>0.345929</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.352419</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>0.345138</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.352419</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy  \\\n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.462891   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.460938   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.460938   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.459961   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.459961   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.459961   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.459961   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.459961   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.458984   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.458984   \n",
       "\n",
       "   balanced_accuracy f1_score  r2_score roc_auc_score              model_type  \n",
       "0           0.354989      N/A -0.351739           N/A  RandomForestClassifier  \n",
       "0           0.346947      N/A -0.355142           N/A  RandomForestClassifier  \n",
       "0           0.348985      N/A -0.344252           N/A  RandomForestClassifier  \n",
       "0           0.346073      N/A -0.346974           N/A  RandomForestClassifier  \n",
       "0           0.346298      N/A -0.356503           N/A  RandomForestClassifier  \n",
       "0           0.348051      N/A -0.349697           N/A  RandomForestClassifier  \n",
       "0           0.347716      N/A -0.369776           N/A  RandomForestClassifier  \n",
       "0           0.346298      N/A -0.355142           N/A  RandomForestClassifier  \n",
       "0           0.345929      N/A -0.352419           N/A  RandomForestClassifier  \n",
       "0           0.345138      N/A -0.352419           N/A  RandomForestClassifier  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_rfc_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.455078</td>\n",
       "      <td>0.341766</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.397001</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.455078</td>\n",
       "      <td>0.340673</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.370456</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.455078</td>\n",
       "      <td>0.340673</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.370456</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.339716</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.402786</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.452148</td>\n",
       "      <td>0.341932</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.387812</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.452148</td>\n",
       "      <td>0.339918</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.385770</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.451172</td>\n",
       "      <td>0.339599</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.401765</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.451172</td>\n",
       "      <td>0.339835</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.398022</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.450195</td>\n",
       "      <td>0.336451</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.364671</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.450195</td>\n",
       "      <td>0.338225</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.409593</td>\n",
       "      <td>N/A</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy  \\\n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.455078   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.455078   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.455078   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.453125   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.452148   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.452148   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.451172   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.451172   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.450195   \n",
       "0  (DecisionTreeClassifier(class_weight=None, cri...  0.450195   \n",
       "\n",
       "   balanced_accuracy f1_score  r2_score roc_auc_score              model_type  \n",
       "0           0.341766      N/A -0.397001           N/A  RandomForestClassifier  \n",
       "0           0.340673      N/A -0.370456           N/A  RandomForestClassifier  \n",
       "0           0.340673      N/A -0.370456           N/A  RandomForestClassifier  \n",
       "0           0.339716      N/A -0.402786           N/A  RandomForestClassifier  \n",
       "0           0.341932      N/A -0.387812           N/A  RandomForestClassifier  \n",
       "0           0.339918      N/A -0.385770           N/A  RandomForestClassifier  \n",
       "0           0.339599      N/A -0.401765           N/A  RandomForestClassifier  \n",
       "0           0.339835      N/A -0.398022           N/A  RandomForestClassifier  \n",
       "0           0.336451      N/A -0.364671           N/A  RandomForestClassifier  \n",
       "0           0.338225      N/A -0.409593           N/A  RandomForestClassifier  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_rfc_without_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if pitcher == 'Verlander':\n",
    "    target_names = ['Fastball', 'Slider', 'Curveball', 'Changeup']\n",
    "elif pitcher == 'Gibson':\n",
    "    target_names = ['FF','FT','SL','CU','CH']\n",
    "elif pitcher == 'Lynn':\n",
    "    target_names = ['FF','FT','CU','CH']\n",
    "elif pitcher == 'Corbin':\n",
    "    target_names = ['Fastball','Slider','Curveball','Changeup']\n",
    "elif pitcher == 'Cole':\n",
    "    target_names = ['FF', 'SL', 'KC', 'CH']\n",
    "elif pitcher == 'Bauer':\n",
    "    target_names = ['FF', 'FC', 'SL', 'KC', 'CH']\n",
    "    \n",
    "    \n",
    "cols = ['Predicted ' + target for target in target_names]\n",
    "idx = ['Actual ' + target for target in target_names]\n",
    "\n",
    "def con_matrix_analysis(model, X, X_test, y, y_test):\n",
    "  \n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X_test)\n",
    "  \n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "    con_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                              columns=cols,\n",
    "                              index=idx)\n",
    "                            \n",
    "    sns.heatmap(data=con_matrix, cmap='Blues')\n",
    "    plt.show();\n",
    "    return con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FF       0.46      0.71      0.56       371\n",
      "          FC       0.38      0.04      0.08       201\n",
      "          SL       0.45      0.43      0.44       181\n",
      "          KC       0.49      0.57      0.53       214\n",
      "          CH       0.50      0.02      0.03        57\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      1024\n",
      "   macro avg       0.45      0.35      0.33      1024\n",
      "weighted avg       0.45      0.46      0.41      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted FF</th>\n",
       "      <th>Predicted FC</th>\n",
       "      <th>Predicted SL</th>\n",
       "      <th>Predicted KC</th>\n",
       "      <th>Predicted CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual FF</th>\n",
       "      <td>264</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual FC</th>\n",
       "      <td>140</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual SL</th>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual KC</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual CH</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted FF  Predicted FC  Predicted SL  Predicted KC  \\\n",
       "Actual FF           264             9            38            60   \n",
       "Actual FC           140             9            18            33   \n",
       "Actual SL            82             5            78            16   \n",
       "Actual KC            56             0            36           122   \n",
       "Actual CH            35             1             4            16   \n",
       "\n",
       "           Predicted CH  \n",
       "Actual FF             0  \n",
       "Actual FC             1  \n",
       "Actual SL             0  \n",
       "Actual KC             0  \n",
       "Actual CH             1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = rfc_with_bootstrap_search.best_estimator_\n",
    "model = top10_rfc_bootstrap.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "# y_pred = model.predict(X_test)\n",
    "# pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:308: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FF       0.45      0.71      0.55       371\n",
      "          FC       0.44      0.05      0.10       201\n",
      "          SL       0.44      0.34      0.38       181\n",
      "          KC       0.47      0.60      0.53       214\n",
      "          CH       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      1024\n",
      "   macro avg       0.36      0.34      0.31      1024\n",
      "weighted avg       0.43      0.46      0.40      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEzCAYAAADaRc8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X+8XHV95/HXOwmSIBBIKREEwSKFglR+pOAW2FLEKrQ2oKwlD1sJpY3dylarWLTral3lRylKoe5DNhYBKRVBpCJiWkBSZaHVQECIoM1DQgX5Uc0WsGGB4Hv/mHPJcOfm3pl7z5wz5+T95HEe99zvzJz5DOfmvOf7Pb9km4iIiG6z6i4gIiJGT8IhIiJ6JBwiIqJHwiEiInokHCIiokfCISIieiQcIiKiR8IhIiJ6JBwiIqLHnLoLqNO8g05r3enhj952Yd0lDMUTTz9XdwlD8cP1T9ddQukO3HOHuksYirlz0EyXMcg25+nVn5zx+81Eeg4REdFji+45RERUSs35Pp5wiIioimodKRpIwiEioiqzZtddQd8SDhERVcmwUkRE9MiwUkRE9EjPISIiejSo59CcGIuIaLpZs/ufpiBpd0m3SPqOpDWS3lW0/5mkhyXdVUzHdb3mA5LWSvqupDdMtvz0HCIiqlLusNJG4L2275S0HXCHpBuLx863fd6L3lraDzgJ2B/YFbhJ0s/bfn6ihafnEBFRFan/aQq2H7F9ZzH/FHAf8PJJXrIYuNL2M7YfANYCh27uyQmHiIiqaFb/0yCLlfYEDgL+uWg6TdK3JX1G0o5F28uBH3S97CEmCZOEQ0REVQYIB0nLJK3qmpZNuEhpW+Aa4N22nwQ+BewFHAg8Anx8OqVmn0NERFVm9X+0ku3lwPLJniNpKzrBcIXtLxave6zr8U8D1xe/Pgzs3vXy3Yq2iUvtu9KIiJiZco9WEnAxcJ/tT3S179L1tBOAe4v564CTJG0t6ZXA3sA3N7f89BwiIqpS7tFKhwO/A9wj6a6i7U+BJZIOBAysA94BYHuNpKuA79A50umdmztSCRIOERHVKfEkONu3woQ3ILphktecCZzZz/IHjjFJx0uypH37eO5SSbsO+h5drz9K0vWbaX+i6ySPm4r28Sd/nDPd946IKN2QjlYahun0HJYAtxY/PzzFc5fSGe/64TTeZyrfsP0bE7T3nPwRETES2nr5jOKQqSOAU+mcadf92BmS7pF0t6RzJJ0ILAKuKL7Fz5O0TtJOxfMXSVpZzB8q6XZJqyXdJmmfMj5cRMRIaVDPYdAKFgMrbH8P+LGkQwAkHVs8dpjt1wDn2v4CsAp4m+0DbU92J/X7gSNtHwR8CDirj1qO7Bo++u9d7X/c1T7ptUMiIipV4tFKwzbosNIS4IJi/sri9zuAY4BLbG8AsL1+wOXOBy6TtDedPexb9fGaaQ0rFSeSLAOYs9tRzNlp/wFLjYiYpgYNK/UdDpIWAEcDB0gyMBuwpPcN8H4b2dRbmdvV/lHgFtsnFKeBrxxgmQPpPrFk3kGneVjvExHRYwSGi/o1SKUnApfb3sP2nrZ3Bx4AjgRuBE6RtA28ECQATwHbdS1jHXBIMf+Wrvb5bDpTb+kgHyAiojFaus9hCXDtuLZrgCW2V9A5+25VcTLG6cXjlwIXje2QBj4CXCBpFdB98sW5wNmSVpNzLyKirUq8KuvQS7W33JGVNg4rPXrbhXWXMBRPPP1c3SUMxQ/XT3acRjMduOcOdZcwFHPnTHjC2UDmHb+8723O03+3rNaEyLf0iIiqjMBwUb8SDhERVRmB4aJ+JRwiIiqihENERIyXcIiIiF7NyYaEQ0REVWbNyg7piIgYJ8NKERHRI+EQERG9mpMNCYeIiKqk5xARET0SDhER0SNHK0VERK/mdBwSDhERVcmwUkRE9Eg4REREj4RDQ5x0xjvqLqF07/7SGs5fvF/dZZRu263b+ae68/y5Uz8pWkOzEg5RkzYGQ0RbpOcQERE9Eg4REdEj4RAREb2akw0Jh4iIqqTnEBERPZp0+YzmVBoR0XQaYJpqUdLukm6R9B1JayS9q2hfIOlGSf9S/NyxaJekCyWtlfRtSQdPtvyEQ0RERST1PfVhI/Be2/sBrwXeKWk/4P3Azbb3Bm4ufgc4Fti7mJYBn5ps4QmHiIiKlBkOth+xfWcx/xRwH/ByYDFwWfG0y4Dji/nFwGfd8U/ADpJ22dzys88hIqIiw9ohLWlP4CDgn4GFth8pHnoUWFjMvxz4QdfLHiraHmEC6TlERFREs9T/JC2TtKprWjbhMqVtgWuAd9t+svsx2wY8nVrTc4iIqMggPQfby4HlUyxvKzrBcIXtLxbNj0naxfYjxbDR40X7w8DuXS/frWibUHoOEREVKXOfgzpPuhi4z/Ynuh66Dji5mD8Z+FJX+9uLo5ZeCzzRNfzUIz2HiIiKlLzL4XDgd4B7JN1VtP0pcA5wlaRTgQeBtxaP3QAcB6wFNgCnTLbwhENEREXK3CFt+1Y2f0bE6yZ4voF39rv8hENEREUadPWMhENERFVm5WY/ERExXpPCYaCjlSQdL8mS9u3juUsl7TrdwiQdJen6zbQ/IemuYrqp67G3S7pX0j2SVks6fbrvHxFRNqn/qW6DHsq6BLi1+DmVpcC0w2EK37B9YDEdAyDpWODdwK/ZPoDOtUaeGNL7R0QMrORrKw1V3+FQnIV3BHAqcNK4x84ovq3fLekcSScCi4Arim/38yStk7RT8fxFklYW84dKur34pn+bpH2m+Vk+AJxu+4cAtp+x/elpLisionRN6jkMss9hMbDC9vck/VjSIbbvKL6xLwYOs71B0gLb6yWdRmdjvQomPYTrfuBI2xslHQOcBbxlilqO7Dqu92rbZwKvBu4Y4PNERFRqFHoE/RpkWGkJcGUxfyWbhpaOAS6xvQHA9voBa5gPXC3pXuB8YP8+XtM9rHTmIG/Wfb2S7978hQFLjYiYvlmz1PdUt756DpIWAEcDB0gyMBuwpPcN8F4b2RRGc7vaPwrcYvuE4sqCKwdYZrc1wCHA1yZ7Uvf1Sk658p5pXZAqImI62thzOBG43PYetve0vTvwAHAkcCNwiqRt4IUgAXgK2K5rGevobLzhxcNG89l08aelg36ALmcDfyHpZUUdL5H0ezNYXkREqZq0z6HfcFgCXDuu7Rpgie0VdC7otKrYDzB2+OilwEVjO6SBjwAXSFoFPN+1nHOBsyWtZgbnXdi+AfgkcJOkNcCdwPbTXV5ERNmadLSSOpfb2DK1cVjp/MX71V3CUPz0p3VXMBz/vuG5ukso3a47zp36SQ00d04/d3ae3KKP3dL3NmfVB3+11oTIGdIRERUZhR3N/Uo4RERUZBSGi/qVcIiIqEiDsiHhEBFRlfQcIiKiR4OyIeEQEVGV9BwiIqJHjlaKiIge6TlERESPBmVDwiEioirpOURERI8GZUPCISKiKuk5REREj9k5WikiIsZrUMch4RARUZUMK0VERI8GjSpt2eHwm/v9bN0llO4ls/u9uV+zrHn0ybpLGIqF89t5Y5yYWHoOERHRY1bCISIixsuwUkRE9GjSsFI7B6gjIkaQ1P809bL0GUmPS7q3q+3PJD0s6a5iOq7rsQ9IWivpu5LeMNXy03OIiKhIyfscLgU+CXx2XPv5ts/rbpC0H3ASsD+wK3CTpJ+3/fxmay2z0oiI2Lwyew62vw6s7/OtFwNX2n7G9gPAWuDQyV6QcIiIqMisWep7moHTJH27GHbasWh7OfCDruc8VLRtvtaZVBAREf2bJfU9SVomaVXXtKyPt/gUsBdwIPAI8PHp1pp9DhERFRmkP2B7ObB8kOXbfuyF95I+DVxf/PowsHvXU3cr2jYrPYeIiIqo0yPoa5rm8nfp+vUEYOxIpuuAkyRtLemVwN7ANydbVnoOEREVKfMkOEmfA44CdpL0EPBh4ChJBwIG1gHvALC9RtJVwHeAjcA7JztSCRIOERGVKfMkONtLJmi+eJLnnwmc2e/yEw4RERWZ4VFIlUo4RERUpEHZkHCIiKhKk66tlHCIiKhIc6Ih4RARUZkm3c9h4PMcJB0vyZL27eO5SyXtOr3SQNJRkq6foH0bSVdIukfSvZJulbRt8dhPpvt+ERHDVNHlM8qpdRqvWQLcWvycylI6VwAs27uAx2wfYPvVwKnAc0N4n4iI0pR54b1hGygcim/nR9DZGJ807rEzim/yd0s6R9KJwCLgiuK64vMkrZO0U/H8RZJWFvOHSrpd0mpJt0naZ4pSdqHr1G/b37X9zCCfJSKiaoNcW6lug+5zWAyssP09ST+WdIjtOyQdWzx2mO0NkhbYXi/pNOB026tg0j319wNH2t4o6RjgLOAtk9TxGeAfigC6GbjM9r8M+FkiIio1Atv8vg06rLQEuLKYv5JNQ0vHAJfY3gBgu99rjI+ZD1xd3NHofDo3pNgs23cBPwf8BbAA+JakX+jnjbqvdPgPX7h8wDIjIqZv2NdWKlPfPQdJC4CjgQMkGZgNWNL7Bni/jWwKpLld7R8FbrF9gqQ9gZVTLcj2T4AvAl+U9FPgOOC+Pl73wpUOr/32ox6g9oiIGWnSlU4HqfVE4HLbe9je0/buwAPAkcCNwCmStoEXggTgKWC7rmWsAw4p5ruHjeazaR/C0qkKkXT42E0sJL0E2A94cIDPEhFRudmz1PdUt0HCYQlw7bi2a4AltlfQuSTsKkl3AacXj18KXDS2Qxr4CHCBpFVA9xUBzwXOlrSa/nozewH/KOkeYDWwqqgFYBtJD3VN7xngM0ZEDM0s9T/VTfaWO7LSxmGlN+y7sO4ShmLNw0/WXcJQLJw/d+onNczO229ddwlDMXfOzE9wfu+Xv9v3Nufjb9qn1ojIGdIRERUZhR5BvxIOEREVGYGDkPqWcIiIqMicBqVDwiEioiINyoaEQ0REVUbhshj9SjhERFSkQdmQcIiIqEqOVoqIiB4ZVoqIiB6zG3RxpYRDRERF1KC7SCccIiIqkn0OERHRI+EQERE9RuEmPv1KOEREVCQ9h4iI6DEKN/HpV8IhIqIiDcqGLTscXrnDS+suoXSzmvTXN4Cdt2/fTXEA/vLWB+ouoXRnHbdv3SWMrAbtctiywyEiokqzGnSeQ4PO14uIaDap/2nqZekzkh6XdG9X2wJJN0r6l+LnjkW7JF0oaa2kb0s6eKrlJxwiIioyZ5b6nvpwKfDGcW3vB262vTdwc/E7wLHA3sW0DPjUVAtPOEREVKTMnoPtrwPrxzUvBi4r5i8Dju9q/6w7/gnYQdIuky0/+xwiIipSwVVZF9p+pJh/FFhYzL8c+EHX8x4q2h5hM9JziIioyCA9B0nLJK3qmpYN8l62DXi6tabnEBFRkUG+jdteDiwf8C0ek7SL7UeKYaPHi/aHgd27nrdb0bZZ6TlERFREUt/TNF0HnFzMnwx8qav97cVRS68FnugafppQeg4RERWZXeI+B0mfA44CdpL0EPBh4BzgKkmnAg8Cby2efgNwHLAW2ACcMtXyEw4RERUpc3e07SWbeeh1EzzXwDsHWX7CISKiIrl8RkRE9Mj9HCIiokeTjgBKOEREVCQ9h4iI6FHBGdKlSThERFQkw0oREdEjw0oREdGjOdEwQC9H0vGSLGnKewBKWipp1+kWJekoSddP1S7pY5JWSNpa0laSzilucnGnpNslHTvdGiIiylbmJbuHbZAhsCXArcXPqSwFph0O/ZD0QeBw4ATbzwAfBXYBXm37YDrXMd9umDVERAxittT3VLe+wkHStsARwKnASeMeO0PSPZLuLr65nwgsAq6QdJekeZLWSdqpeP4iSSuL+UOLb/irJd0maZ8+63kvnTsbvcn205K2AX4f+G9FUGD7MdtX9bO8iIgqaID/6tbvPofFwArb35P0Y0mH2L6jGLZZDBxme4OkBbbXSzoNON32Kph0J8z9wJG2N0o6BjgLeMsUtRwO7AMcYvsnRdurgH+1/WSfnycionIj0CHoW7/DSkuAK4v5K9k0tHQMcIntDQC2x9+ybirzgauLG2SfD+zfx2vW0tmv8/oB3wt48Q00rvnbS6aziIiIaZmF+p7qNmXPQdIC4GjgAEkGZgOW9L4B3mcjm4Joblf7R4FbbJ8gaU9gZR/Legx4G3CzpPW2b6ETGK+QtP1UvYfuG2jc9a9PTfsuSRERg2pbz+FE4HLbe9je0/buwAPAkcCNwCnFmP9YkAA8xYt3Bq8DDinmu4eN5rPpbkRL+y3a9veANwN/I+nAoudyMXCBpJcUtfyspP/S7zIjIoatbUcrLQGuHdd2DbDE9go6dxhaJeku4PTi8UuBi8Z2SAMfobPhXgU837Wcc4GzJa1mwHMubH+Lzg0rrpO0F/BB4N+A7xTDVNcD2QcRESOjSUcrqXMPiC1TG4eV9t21nUfvPvbEM3WXMBQX/J8H6i6hdGcdN+WpUI00d87MdwR87f4f973NOXrfn6k1IXKGdERERUagQ9C3hENEREVG4fyFfiUcIiIqMqs52ZBwiIioSnoOERHRIz2HiIjokTvBRUREj+ZEQ8IhIqI6DUqHhENEREWyQzoiInpkh3RERPRKOERExHgZVoqIiB4NOpI14RARUZUGZUPCISKiMg1Kh4RDRERFyj5DWtI6OnfefB7YaHtRcUfOzwN70rkL51tt/9+Bl70l3+xn7eNPt+7D77ZgXt0lDMVPW/p3uuGZ56d+UsNsO7ed3znLuNnP3QPcYOw1r9huyvcrwmGR7R91tZ0LrLd9jqT3AzvaPmPQWvu5TWhERJRBA0zTtxi4rJi/DDh+OgtJOEREVEQD/NcnA/8g6Q5Jy4q2hbYfKeYfBRZOp9Z29v8iIkbQILscio39sq6m5baXj3vaEbYflrQzcKOk+7sftG1J0xqTTThERFRkkNGiIgjGh8H45zxc/Hxc0rXAocBjknax/YikXYDHp1NrhpUiIioiqe+pj2W9VNJ2Y/PArwH3AtcBJxdPOxn40nRqTc8hIqIiJR/JuhC4tgiSOcDf2l4h6VvAVZJOBR4E3jqdhSccIiIqUmY22P4+8JoJ2n8MvG6my084RERUJWdIR0TEeLkqa0RE9MjNfiIiolfCISIixsuwUkRE9MjNfiIiokeDsiHhEBFRmQalQ8IhIqIiZd/sZ5gSDhERFWlONPR54T1Jx0uypH37eO5SSbtOtyBJR0m6fjOPHSrp65K+K2m1pL+WtE3xnp8c99yVkhZNt46IiNJVc7OfUvR7VdYlwK3Fz6ksBaYdDpsjaSFwNXCG7X1sHwSsALYr+70iIoZhCDf7GZopw0HStsARwKnASeMeO0PSPZLulnSOpBOBRcAVku6SNE/SOkk7Fc9fJGllMX+opNuLHsBtkvaZopR3ApfZvn2swfYXbD82yAeOiKiL1P9Ut372OSwGVtj+nqQfSzrE9h2Sji0eO8z2BkkLbK+XdBpwuu1VwGTXJb8fONL2RknHAGcBb5mkjlez6b6oE/ktSUd0/f6qPj5bRERlmnT5jH6GlZYAVxbzV7JpaOkY4BLbGwBsrx/wvecDV0u6Fzgf2H/A14/3edsHjk3AqomeJGmZpFWSVl352Ytn+JYREYNozk6HSXsOkhYARwMHFPchnQ1Y0vsGeI+NbAqhuV3tHwVusX2CpD2BlVMsZw1wCNO8q9GY7lvvrX386WndWzUiYjpGYbioX1P1HE4ELre9h+09be8OPAAcCdwInCJpG3ghSACe4sU7idfR2ajDi4eN5gMPF/NL+6j1k8DJkg4ba5D05mJHdUTEyGtOv2HqcFgCXDuu7Rpgie0VdO5VukrSXcDpxeOXAheN7ZAGPgJcIGkV8HzXcs4Fzpa0mj72fRQ7nk8CzisOZb0PeAOdMIqIGHlN2iEte8sdWWnjsNJuC+bVXcJQ/LSlf6cbnnl+6ic1zLZz23lu7dw5M/9C/+gTz/X9h/yy+VvVGhHtXIsRESNoFHoE/Uo4RERUJOEQERE9RuHM534lHCIiqtKcbEg4RERUpUHZkHCIiKhK9jlERESPJt3sp99LdkdExBYkPYeIiIo0qOOQcIiIqEoOZY2IiB7pOURERI+EQ0RE9GjSsFKOVoqIqEiZl+yW9Mbi9gVrJb2/7FoTDhERFSnrZj+SZgP/CzgW2A9YImm/MmtNOEREVKW8W8EdCqy1/X3bzwJXAovLLDXhEBFREQ3w3xReDvyg6/eHirbSbNE7pF+187zK9g5JWmZ7eVXvV5XqPld1O/KqXFfbbFXdP8E2/g027TPN26r/P2RJy4BlXU3Lq/ys6TlUZ9nUT2mkNn6uNn4maOfnauNnAsD2ctuLuqbuYHgY2L3r992KttIkHCIimudbwN6SXinpJcBJwHVlvsEWPawUEdFEtjdKOg34e2A28Bnba8p8j4RDdRozLjqgNn6uNn4maOfnauNn6ovtG4AbhrV82R7WsiMioqGyzyEiInokHCImIOmwumuIqFPCoWSS3tw1v2OdtZRJ0hsknThB+4mSXl9HTUN2dd0FTJekV0k6fIL2wyXtVUdN0TwJh/J9sGv+5tqqKN+HgH+coH0l8D+rLaUSzbl8Zq+/BJ6coP3J4rHGkfSUpCcnmJ6SNNFnjRnK0Url02bmm25r2/82vtH2jyS9tI6ChqzJR2ostH3P+Ebb90jas/pyZs72dmPzklbbPqjOerYECYfyzZN0EJ1e2dxi/oWQsH1nbZXNzPaS5tje2N0oaStgXk01zYikLzNxCAj4mYrLKdMOkzzWyHU1TpODuzFyKGvJJK1k83+8tn10heWURtI5wELgNNv/UbRtC1wA/Mj2GXXWNx2SfmWyx21PNIw28iR9Dvia7U+Pa/894PW2f6ueysoh6U7bB9ddR9slHKIvkuYAHwN+D3iwaH4FcDHwP2w/V1dtZSl6Qa8GHrb9eN31TJekhcC1wLPAHUXzIuAlwAm2H62rtunqPtADOA84vftx21+stqL2SziUTNJZtv+0mH+97RvrrqlMkuYBryp+XWv76TrrmQlJFwF/ZXuNpPnA7cDzwALgdNufq7XAGZL0q3TCDmCN7a9Jeklx/f9GkXTJJA/b9u9WVswWIuFQsu4ub5u6v20MPUlrbO9fzL8bOMr28ZJeBny1qTs9JX3Ids8RZJK2B66zfVT1VUXT5FDW6Ncbu+b/vLYqytX9Dfr1wN8BNHHYZZwjJJ3Z3VAMNX0d+Fo9Jc2MpPdIOnWC9lOLYI+S5Wil8u0s6T10jngZm3+B7U/UU1ZM4N8l/Qad6+AfDpwKL+xfafJRPb8JfEHSJ2y/R9LewFeB82xfVHNt0/U24LUTtF8OrKKh52+MsoRD+T4NbDfBfNO1MfTeAVwIvAx4d1eP4XXAV2qraoZs/z9JJwCfL45c+mU6n+/amkubiTkTHfRg+1lJbTqfaGRkn0P0RdKHJ3vc9keqqiUm1xXcWwF/AnyDzpAS0Mwgl3QPcIztx8a1LwRusn1APZW1V3oO0Zds/Bulu7d64QRtTfQXwFckvRcYO5H0kKL9vNqqarH0HCKiESQdC7yfzuG5BtYA59j+aq2FtVTCISIiemRYqWTjd9SO18Tx3rbKuorYvIRD+cbGdvcBfgm4rvj9TcA3a6moBC3dkLZyXUWUIcNKQyLp68Cv236q+H074Cu2/3O9lU1P19FKE25Ibf92LYWVoIXrqo1BHhVLz2F4FvLiM3CfLdoaaexopWJDenDXhvTPaPA5AYVWrSta2CNK4FUv4TA8nwW+KWnsxKPjgctqrKcsbduQQsvWVUuDvHWBN+oyrDREkg4Gjix+/brt1XXWUwZJ/x14K51LQkNnQ3qV7bPqq2rmWrquvgv8ou1nit+3Br5te596K5u+tg0BjrL0HIZrG+BJ25dI+llJr7T9QN1FzYTtMyV9lU0b0lPasCGlheuKlvWICm3suY6k9ByGpNiBuwjYx/bPS9oVuNr24TWXNmOSjgD2HtuQAts2eUPa8nXVqh5RW3uuoyjhMCSS7gIOAu4cuy+ApG/b/sV6K5uZNm5I27quoH1BDu0LvFGV+zkMz7PuJK8BJL205nrKcgKdS0L/B4DtH9L86/a0cl0VQX4G8IGiaSvgb+qrqDRjQ4AXAA9JemXdBbVRwmF4rpL0v4EdJP0+cBPw1zXXVIY2bkjbuq5aF+QtDryRkx3SQ2L7PEmvB56kc/jdh9pwa016N6S/S8M3pC1eV8/atqQ2BfkJFEOA0Am84oilKFnCYUgk/bntM4AbJ2hrrDZuSNu6rmhhkNPOwBtJ2SE9JJLutH3wuLbG7+ScaKPZ9A1pW9cVQBHkv0bnDn5/34IgPx3Ym849v8+mE3ifs33hpC+MgSUcSibpvwJ/COwFrO16aDvgNttvq6WwkrRpQ7oFrKvWBTm0L/BGVcKhZJLmAzvS+Vbz/q6HnrK9vp6qZq6NG9K2rqsxbQryMW0NvFGUcBgSSa8F1nSd5r898Au2/7neyqanzRvSFq6r1gX5mDYG3qhKOAyJpNV0Lno2tuNsFrBq/B9207RtQwrtW1dtDPI2B96oytFKwyN3Ja/tn0pqw//vTwHdG82fTNDWNK1aV7afAJ6QdAGwvjvIJR3W0CD/W+CrtCjwRl1Oghue70v6I0lbFdO7gO/XXVQJejakNP9LRlvX1afohPeYsSBvHNtP2F4HjAXeg7YfBDZKOqze6top4TA8fwD8MvAw8BBwGLCs1orK0cYNaVvXVRuDvDWBN+qyzyEGImln4ELgaDqX0LgZeLftx2stLHpI+iKwkk0bzz8EftX28bUVNUOS7rJ94Li27JAegoRDyST9ie1zJf0VxfWHutn+oxrKigm0fV21McjbGHijquldzFF0X/FzVa1VlKylG9JWrqsxRQicVHcdJfsDOoH3QTYFXhuGAEdOeg7RF0lvsv1lSSdP9Ljtpt9hrDVaGuRRsfQcSibpy0zwD3KM7d+ssJzS2P5y8bM1IdDWdUULe0QJvOolHMp3XvHzzcDL2HSt+SXAY7VUVIKWbkhbua7aGOS0MPBGXYaVhkTSKtuLpmprCkm/UsxOuCG1/ce1FFaCFq6rNgZ5VCw9h+F5qaSfs/19gOJWho299rztfwSQ9PFxG80vS2r6t7lWrSscT4k2AAADHUlEQVRa2CNK4FUv4TA8fwyslPR9OpcW3gN4R70llaJtG1Jo2bpqaZC3LvBGXYaVhkjS1sC+xa/3236mznrKIOmNwHI6Z0W/sCG1/fe1FjZDLV1X9wG/Pi7Ib7D9C/VWNn1tGwIcZek5DImkbYD3AHvY/n1Je0vax/b1ddc2E7ZXSNqbFm1I27quaFmPqNDGnutISs9hSCR9HrgDeLvtVxcboNvGn/rfNBNtSIFGb0jbuq6gfT2itvZcR1F6DsOzl+3fkrQEwPYGSaq7qBJcQmdD+p+K3x8GrgYaGw60dF21sUfUxp7rqMpVWYfnWUnzKI6wkLQX0IY/4r1snws8B50NKZ1vcE3W1nV1CfAsLw7yj9VXzswVgfc+4DTbdwOvkPQbNZfVSgmH4fkwsALYXdIVdK4B8yf1llSKNm5I27qu2hjkrQu8UZVhpSEohiTup3PY3Wvp/IN8l+0f1VpYOcZvSA8HltZa0Qy0fF21MchbOQQ4ihIOQ2Dbkm6wfQDwlbrrKUsbN6RtXVeFVgV5oY2BN5ISDsNzp6Rfsv2tugspS4s3pK1bV20M8kIbA28k5VDWIZF0P7A3sA74Dzr/ON30O1ZJugz4ZMs2pG1dV/cUQd4KReDtBmxgU+D9UwsCbyQlHIZE0h4TtRc3RW+sNm5IW7yu2hjkrQq8UZZhpZJJmkvnblWvAu4BLra9sd6qSvWGugsoyxawrg4DflvSOloS5LRwCHBUpedQsuJs2+eAbwDHAg/afle9Vc1cGzekbV1XY9rYI2pjz3VUJRxK1t3tlTQH+Kbtg2sua8bauCFt8bpqXZCPaWPgjaoMK5XvubEZ2xtbdAj2fl0b0ouBb9ZcTxnauq4u48VBvh/Q9CBvbeCNqoRD+V4j6cliXsC84vex7u/29ZU2I23ckLZ1XbUxyFsXeKMu4VAy27PrrmFIWrchbfG6amOQtzHwRlrCIfrS4g1pG7UuyGln4I207JCOiJEn6Xk6RydBEXh0ToZrcuCNtIRDRET0yCW7IyKiR8IhIiJ6JBwiIqJHwiEiInokHCIiokfCISIievx/Za6DIl5EIvsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted FF</th>\n",
       "      <th>Predicted FC</th>\n",
       "      <th>Predicted SL</th>\n",
       "      <th>Predicted KC</th>\n",
       "      <th>Predicted CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual FF</th>\n",
       "      <td>265</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual FC</th>\n",
       "      <td>141</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual SL</th>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual KC</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual CH</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted FF  Predicted FC  Predicted SL  Predicted KC  \\\n",
       "Actual FF           265            10            30            66   \n",
       "Actual FC           141            11            14            35   \n",
       "Actual SL            86             4            61            30   \n",
       "Actual KC            54             0            31           129   \n",
       "Actual CH            38             0             3            16   \n",
       "\n",
       "           Predicted CH  \n",
       "Actual FF             0  \n",
       "Actual FC             0  \n",
       "Actual SL             0  \n",
       "Actual KC             0  \n",
       "Actual CH             0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_rfc_without_bootstrap.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/24/5fe7237b2eca13ee0cfb100bec8c23f4e69ce9df852a64b0493d49dae4e0/xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 142.8MB 352kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.14.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.1.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 22.7min finished\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "num_classes = df[target].nunique()\n",
    "\n",
    "param_grid = {\n",
    "    'booster': ['gbtree', 'dart'],\n",
    "    'eta': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'gamma': [5, 10, 15, 20, 25, 0, 0.5, 1, 3],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 15, 25],\n",
    "    'min_child_weight': [0, 0.5, 1, 2, 4, 8],\n",
    "    'max_delta_step': [0, 1, 2, 3, 6, 10],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0], \n",
    "    'colsample_bylevel': [0.8, 0.9, 1.0],\n",
    "    'colsample_bynode': [0.8, 0.9, 1.0]    \n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(verbosity=0, n_jobs=-1, random_state=42, num_class=num_classes, objective='multi:softmax')\n",
    "\n",
    "\n",
    "xgb_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid, n_iter=200, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, random_state=12, \n",
    "                            error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "xgb_search.fit(X, y)\n",
    "\n",
    "xgb_search_results = pd.DataFrame(xgb_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_delta_step</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_eta</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_colsample_bynode</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_booster</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8.820784</td>\n",
       "      <td>0.197227</td>\n",
       "      <td>0.051132</td>\n",
       "      <td>0.017710</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>{'min_child_weight': 8, 'max_depth': 2, 'max_d...</td>\n",
       "      <td>0.406121</td>\n",
       "      <td>0.471143</td>\n",
       "      <td>0.416274</td>\n",
       "      <td>0.431180</td>\n",
       "      <td>0.028564</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515321</td>\n",
       "      <td>0.489838</td>\n",
       "      <td>0.525169</td>\n",
       "      <td>0.510109</td>\n",
       "      <td>0.014887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>8.677866</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>0.035403</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>{'min_child_weight': 0, 'max_depth': 2, 'max_d...</td>\n",
       "      <td>0.412007</td>\n",
       "      <td>0.464075</td>\n",
       "      <td>0.415684</td>\n",
       "      <td>0.430591</td>\n",
       "      <td>0.023728</td>\n",
       "      <td>2</td>\n",
       "      <td>0.493518</td>\n",
       "      <td>0.472459</td>\n",
       "      <td>0.510156</td>\n",
       "      <td>0.492044</td>\n",
       "      <td>0.015425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>28.368081</td>\n",
       "      <td>0.381132</td>\n",
       "      <td>0.041997</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>dart</td>\n",
       "      <td>{'min_child_weight': 1, 'max_depth': 8, 'max_d...</td>\n",
       "      <td>0.412596</td>\n",
       "      <td>0.461131</td>\n",
       "      <td>0.417453</td>\n",
       "      <td>0.430395</td>\n",
       "      <td>0.021827</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500295</td>\n",
       "      <td>0.473932</td>\n",
       "      <td>0.512511</td>\n",
       "      <td>0.495579</td>\n",
       "      <td>0.016099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>14.808354</td>\n",
       "      <td>0.211108</td>\n",
       "      <td>0.042366</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>dart</td>\n",
       "      <td>{'min_child_weight': 0, 'max_depth': 4, 'max_d...</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>0.458186</td>\n",
       "      <td>0.422170</td>\n",
       "      <td>0.429806</td>\n",
       "      <td>0.020772</td>\n",
       "      <td>4</td>\n",
       "      <td>0.504714</td>\n",
       "      <td>0.481591</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.499311</td>\n",
       "      <td>0.012844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8.220745</td>\n",
       "      <td>0.295464</td>\n",
       "      <td>0.048901</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>{'min_child_weight': 0, 'max_depth': 2, 'max_d...</td>\n",
       "      <td>0.407887</td>\n",
       "      <td>0.461720</td>\n",
       "      <td>0.417453</td>\n",
       "      <td>0.429020</td>\n",
       "      <td>0.023453</td>\n",
       "      <td>5</td>\n",
       "      <td>0.493518</td>\n",
       "      <td>0.473343</td>\n",
       "      <td>0.512511</td>\n",
       "      <td>0.493124</td>\n",
       "      <td>0.015993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>49.377382</td>\n",
       "      <td>0.637373</td>\n",
       "      <td>0.037862</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>{'min_child_weight': 0.5, 'max_depth': 15, 'ma...</td>\n",
       "      <td>0.410830</td>\n",
       "      <td>0.442874</td>\n",
       "      <td>0.422759</td>\n",
       "      <td>0.425486</td>\n",
       "      <td>0.013226</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500295</td>\n",
       "      <td>0.477172</td>\n",
       "      <td>0.515455</td>\n",
       "      <td>0.497641</td>\n",
       "      <td>0.015741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>6.737836</td>\n",
       "      <td>0.148323</td>\n",
       "      <td>0.037322</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>{'min_child_weight': 8, 'max_depth': 2, 'max_d...</td>\n",
       "      <td>0.406121</td>\n",
       "      <td>0.460542</td>\n",
       "      <td>0.408608</td>\n",
       "      <td>0.425093</td>\n",
       "      <td>0.025090</td>\n",
       "      <td>7</td>\n",
       "      <td>0.496170</td>\n",
       "      <td>0.478645</td>\n",
       "      <td>0.509273</td>\n",
       "      <td>0.494696</td>\n",
       "      <td>0.012547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>18.732217</td>\n",
       "      <td>0.128198</td>\n",
       "      <td>0.043481</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>{'min_child_weight': 8, 'max_depth': 6, 'max_d...</td>\n",
       "      <td>0.398470</td>\n",
       "      <td>0.442874</td>\n",
       "      <td>0.431604</td>\n",
       "      <td>0.424308</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>8</td>\n",
       "      <td>0.504714</td>\n",
       "      <td>0.474816</td>\n",
       "      <td>0.514572</td>\n",
       "      <td>0.498034</td>\n",
       "      <td>0.016904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>8.099908</td>\n",
       "      <td>0.271161</td>\n",
       "      <td>0.037012</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>{'min_child_weight': 2, 'max_depth': 2, 'max_d...</td>\n",
       "      <td>0.408476</td>\n",
       "      <td>0.452886</td>\n",
       "      <td>0.410967</td>\n",
       "      <td>0.424112</td>\n",
       "      <td>0.020375</td>\n",
       "      <td>9</td>\n",
       "      <td>0.492634</td>\n",
       "      <td>0.477467</td>\n",
       "      <td>0.512217</td>\n",
       "      <td>0.494106</td>\n",
       "      <td>0.014225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>29.792987</td>\n",
       "      <td>0.620314</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>dart</td>\n",
       "      <td>{'min_child_weight': 0, 'max_depth': 8, 'max_d...</td>\n",
       "      <td>0.414361</td>\n",
       "      <td>0.438163</td>\n",
       "      <td>0.417453</td>\n",
       "      <td>0.423326</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500589</td>\n",
       "      <td>0.475994</td>\n",
       "      <td>0.516044</td>\n",
       "      <td>0.497542</td>\n",
       "      <td>0.016491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "36        8.820784      0.197227         0.051132        0.017710   \n",
       "132       8.677866      0.025958         0.035403        0.000704   \n",
       "66       28.368081      0.381132         0.041997        0.000378   \n",
       "40       14.808354      0.211108         0.042366        0.000615   \n",
       "82        8.220745      0.295464         0.048901        0.019453   \n",
       "34       49.377382      0.637373         0.037862        0.000684   \n",
       "151       6.737836      0.148323         0.037322        0.001084   \n",
       "77       18.732217      0.128198         0.043481        0.009791   \n",
       "165       8.099908      0.271161         0.037012        0.001217   \n",
       "81       29.792987      0.620314         0.048161        0.004316   \n",
       "\n",
       "    param_min_child_weight param_max_depth param_max_delta_step param_gamma  \\\n",
       "36                       8               2                    6          10   \n",
       "132                      0               2                   10          25   \n",
       "66                       1               8                    1          25   \n",
       "40                       0               4                    1          20   \n",
       "82                       0               2                    0          20   \n",
       "34                     0.5              15                    0          25   \n",
       "151                      8               2                    2          20   \n",
       "77                       8               6                    2          25   \n",
       "165                      2               2                    3          20   \n",
       "81                       0               8                   10          25   \n",
       "\n",
       "    param_eta param_colsample_bytree param_colsample_bynode  \\\n",
       "36        0.4                    0.9                    0.9   \n",
       "132       0.1                    0.9                    0.9   \n",
       "66        0.4                    0.9                    0.8   \n",
       "40        0.3                    0.9                    0.8   \n",
       "82        0.4                    0.8                      1   \n",
       "34        0.1                    0.8                    0.8   \n",
       "151       0.3                    0.8                    0.8   \n",
       "77        0.4                    0.9                    0.8   \n",
       "165       0.1                    0.9                    0.9   \n",
       "81        0.5                    0.9                    0.8   \n",
       "\n",
       "    param_colsample_bylevel param_booster  \\\n",
       "36                      0.9        gbtree   \n",
       "132                     0.9        gbtree   \n",
       "66                      0.8          dart   \n",
       "40                      0.8          dart   \n",
       "82                      0.8        gbtree   \n",
       "34                      0.9        gbtree   \n",
       "151                     0.8        gbtree   \n",
       "77                      0.8        gbtree   \n",
       "165                     0.8        gbtree   \n",
       "81                      0.8          dart   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "36   {'min_child_weight': 8, 'max_depth': 2, 'max_d...           0.406121   \n",
       "132  {'min_child_weight': 0, 'max_depth': 2, 'max_d...           0.412007   \n",
       "66   {'min_child_weight': 1, 'max_depth': 8, 'max_d...           0.412596   \n",
       "40   {'min_child_weight': 0, 'max_depth': 4, 'max_d...           0.409064   \n",
       "82   {'min_child_weight': 0, 'max_depth': 2, 'max_d...           0.407887   \n",
       "34   {'min_child_weight': 0.5, 'max_depth': 15, 'ma...           0.410830   \n",
       "151  {'min_child_weight': 8, 'max_depth': 2, 'max_d...           0.406121   \n",
       "77   {'min_child_weight': 8, 'max_depth': 6, 'max_d...           0.398470   \n",
       "165  {'min_child_weight': 2, 'max_depth': 2, 'max_d...           0.408476   \n",
       "81   {'min_child_weight': 0, 'max_depth': 8, 'max_d...           0.414361   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "36            0.471143           0.416274         0.431180        0.028564   \n",
       "132           0.464075           0.415684         0.430591        0.023728   \n",
       "66            0.461131           0.417453         0.430395        0.021827   \n",
       "40            0.458186           0.422170         0.429806        0.020772   \n",
       "82            0.461720           0.417453         0.429020        0.023453   \n",
       "34            0.442874           0.422759         0.425486        0.013226   \n",
       "151           0.460542           0.408608         0.425093        0.025090   \n",
       "77            0.442874           0.431604         0.424308        0.018851   \n",
       "165           0.452886           0.410967         0.424112        0.020375   \n",
       "81            0.438163           0.417453         0.423326        0.010568   \n",
       "\n",
       "     rank_test_score  split0_train_score  split1_train_score  \\\n",
       "36                 1            0.515321            0.489838   \n",
       "132                2            0.493518            0.472459   \n",
       "66                 3            0.500295            0.473932   \n",
       "40                 4            0.504714            0.481591   \n",
       "82                 5            0.493518            0.473343   \n",
       "34                 6            0.500295            0.477172   \n",
       "151                7            0.496170            0.478645   \n",
       "77                 8            0.504714            0.474816   \n",
       "165                9            0.492634            0.477467   \n",
       "81                10            0.500589            0.475994   \n",
       "\n",
       "     split2_train_score  mean_train_score  std_train_score  \n",
       "36             0.525169          0.510109         0.014887  \n",
       "132            0.510156          0.492044         0.015425  \n",
       "66             0.512511          0.495579         0.016099  \n",
       "40             0.511628          0.499311         0.012844  \n",
       "82             0.512511          0.493124         0.015993  \n",
       "34             0.515455          0.497641         0.015741  \n",
       "151            0.509273          0.494696         0.012547  \n",
       "77             0.514572          0.498034         0.016904  \n",
       "165            0.512217          0.494106         0.014225  \n",
       "81             0.516044          0.497542         0.016491  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_search_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 23s, sys: 11.9 s, total: 23min 35s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_xgb = get_top_n_models(xgb_search_results, 'xgb', k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FF       0.45      0.81      0.57       371\n",
      "          FC       0.00      0.00      0.00       201\n",
      "          SL       0.45      0.40      0.42       181\n",
      "          KC       0.55      0.50      0.52       214\n",
      "          CH       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      1024\n",
      "   macro avg       0.29      0.34      0.30      1024\n",
      "weighted avg       0.36      0.47      0.39      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted FF</th>\n",
       "      <th>Predicted FC</th>\n",
       "      <th>Predicted SL</th>\n",
       "      <th>Predicted KC</th>\n",
       "      <th>Predicted CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual FF</th>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual FC</th>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual SL</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual KC</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual CH</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted FF  Predicted FC  Predicted SL  Predicted KC  \\\n",
       "Actual FF           299             0            33            39   \n",
       "Actual FC           157             0            17            27   \n",
       "Actual SL            97             0            72            12   \n",
       "Actual KC            73             0            34           107   \n",
       "Actual CH            43             0             3            11   \n",
       "\n",
       "           Predicted CH  \n",
       "Actual FF             0  \n",
       "Actual FC             0  \n",
       "Actual SL             0  \n",
       "Actual KC             0  \n",
       "Actual CH             0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_xgb.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   15.8s\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 12.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]CPU times: user 21.4 s, sys: 691 ms, total: 22.1 s\n",
      "Wall time: 12min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {\n",
    "    'degree': [2,3,4],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'tol': [0.0001, 0.00001],\n",
    "    'C': [0.2, 0.5, 1.0, 2.0, 3.5, 5.0],\n",
    "    'shrinking': [True, False],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'max_iter': [100, 250, 400, 700, 1200, 2000, 3500],\n",
    "    'decision_function_shape': ['ovo', 'ovr'],\n",
    "    'gamma': ['auto', 'scale']\n",
    "}\n",
    "\n",
    "svm = SVC(random_state=42, verbose=50)\n",
    "\n",
    "# svm_search = GridSearchCV(\n",
    "#     estimator = svm, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=3,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "svm_search = RandomizedSearchCV(estimator=svm, param_distributions=param_grid, n_iter=400, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "svm_search.fit(X, y)\n",
    "\n",
    "svm_search_results = pd.DataFrame(svm_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_shrinking</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_decision_function_shape</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>8.383509</td>\n",
       "      <td>0.119384</td>\n",
       "      <td>3.081462</td>\n",
       "      <td>0.062146</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>2000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>2</td>\n",
       "      <td>ovo</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>{'tol': 1e-05, 'shrinking': False, 'max_iter':...</td>\n",
       "      <td>0.454385</td>\n",
       "      <td>0.471143</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.454349</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501473</td>\n",
       "      <td>0.469514</td>\n",
       "      <td>0.515455</td>\n",
       "      <td>0.495481</td>\n",
       "      <td>0.019228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>7.405394</td>\n",
       "      <td>0.174031</td>\n",
       "      <td>1.873928</td>\n",
       "      <td>0.118834</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>3500</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>2</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>3.5</td>\n",
       "      <td>{'tol': 1e-05, 'shrinking': True, 'max_iter': ...</td>\n",
       "      <td>0.443202</td>\n",
       "      <td>0.461720</td>\n",
       "      <td>0.436910</td>\n",
       "      <td>0.447281</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>2</td>\n",
       "      <td>0.473777</td>\n",
       "      <td>0.450368</td>\n",
       "      <td>0.495437</td>\n",
       "      <td>0.473194</td>\n",
       "      <td>0.018404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>8.587831</td>\n",
       "      <td>0.062834</td>\n",
       "      <td>2.778763</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>1200</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>3</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>3.5</td>\n",
       "      <td>{'tol': 0.0001, 'shrinking': True, 'max_iter':...</td>\n",
       "      <td>0.443202</td>\n",
       "      <td>0.461131</td>\n",
       "      <td>0.436910</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>3</td>\n",
       "      <td>0.473777</td>\n",
       "      <td>0.450074</td>\n",
       "      <td>0.495437</td>\n",
       "      <td>0.473096</td>\n",
       "      <td>0.018526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>8.143470</td>\n",
       "      <td>0.143888</td>\n",
       "      <td>3.012065</td>\n",
       "      <td>0.045390</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>2000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>{'tol': 1e-05, 'shrinking': False, 'max_iter':...</td>\n",
       "      <td>0.432019</td>\n",
       "      <td>0.469376</td>\n",
       "      <td>0.420991</td>\n",
       "      <td>0.440801</td>\n",
       "      <td>0.020704</td>\n",
       "      <td>4</td>\n",
       "      <td>0.614319</td>\n",
       "      <td>0.592047</td>\n",
       "      <td>0.608184</td>\n",
       "      <td>0.604850</td>\n",
       "      <td>0.009393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>8.826118</td>\n",
       "      <td>0.236243</td>\n",
       "      <td>2.871889</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>2000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>ovo</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>{'tol': 1e-05, 'shrinking': False, 'max_iter':...</td>\n",
       "      <td>0.432019</td>\n",
       "      <td>0.469376</td>\n",
       "      <td>0.420991</td>\n",
       "      <td>0.440801</td>\n",
       "      <td>0.020704</td>\n",
       "      <td>4</td>\n",
       "      <td>0.614319</td>\n",
       "      <td>0.592047</td>\n",
       "      <td>0.608184</td>\n",
       "      <td>0.604850</td>\n",
       "      <td>0.009393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_tol  \\\n",
       "132       8.383509      0.119384         3.081462        0.062146     1e-05   \n",
       "399       7.405394      0.174031         1.873928        0.118834     1e-05   \n",
       "394       8.587831      0.062834         2.778763        0.017007    0.0001   \n",
       "217       8.143470      0.143888         3.012065        0.045390     1e-05   \n",
       "246       8.826118      0.236243         2.871889        0.023012     1e-05   \n",
       "\n",
       "    param_shrinking param_max_iter param_kernel param_gamma param_degree  \\\n",
       "132           False           2000          rbf       scale            2   \n",
       "399            True           3500          rbf       scale            2   \n",
       "394            True           1200          rbf       scale            3   \n",
       "217           False           2000          rbf        auto            3   \n",
       "246           False           2000          rbf        auto            2   \n",
       "\n",
       "    param_decision_function_shape param_class_weight param_C  \\\n",
       "132                           ovo               None       5   \n",
       "399                           ovr               None     3.5   \n",
       "394                           ovr               None     3.5   \n",
       "217                           ovr               None       2   \n",
       "246                           ovo               None       2   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "132  {'tol': 1e-05, 'shrinking': False, 'max_iter':...           0.454385   \n",
       "399  {'tol': 1e-05, 'shrinking': True, 'max_iter': ...           0.443202   \n",
       "394  {'tol': 0.0001, 'shrinking': True, 'max_iter':...           0.443202   \n",
       "217  {'tol': 1e-05, 'shrinking': False, 'max_iter':...           0.432019   \n",
       "246  {'tol': 1e-05, 'shrinking': False, 'max_iter':...           0.432019   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "132           0.471143           0.437500         0.454349        0.013732   \n",
       "399           0.461720           0.436910         0.447281        0.010530   \n",
       "394           0.461131           0.436910         0.447084        0.010260   \n",
       "217           0.469376           0.420991         0.440801        0.020704   \n",
       "246           0.469376           0.420991         0.440801        0.020704   \n",
       "\n",
       "     rank_test_score  split0_train_score  split1_train_score  \\\n",
       "132                1            0.501473            0.469514   \n",
       "399                2            0.473777            0.450368   \n",
       "394                3            0.473777            0.450074   \n",
       "217                4            0.614319            0.592047   \n",
       "246                4            0.614319            0.592047   \n",
       "\n",
       "     split2_train_score  mean_train_score  std_train_score  \n",
       "132            0.515455          0.495481         0.019228  \n",
       "399            0.495437          0.473194         0.018404  \n",
       "394            0.495437          0.473096         0.018526  \n",
       "217            0.608184          0.604850         0.009393  \n",
       "246            0.608184          0.604850         0.009393  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 43s, sys: 129 ms, total: 5min 43s\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_svm = get_top_n_models(svm_search_results, 'svm', k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FF       0.44      0.74      0.55       371\n",
      "          FC       0.50      0.00      0.01       201\n",
      "          SL       0.46      0.30      0.36       181\n",
      "          KC       0.46      0.60      0.52       214\n",
      "          CH       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1024\n",
      "   macro avg       0.37      0.33      0.29      1024\n",
      "weighted avg       0.44      0.45      0.38      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted FF</th>\n",
       "      <th>Predicted FC</th>\n",
       "      <th>Predicted SL</th>\n",
       "      <th>Predicted KC</th>\n",
       "      <th>Predicted CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual FF</th>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual FC</th>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual SL</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual KC</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual CH</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted FF  Predicted FC  Predicted SL  Predicted KC  \\\n",
       "Actual FF           276             0            23            72   \n",
       "Actual FC           156             1            15            29   \n",
       "Actual SL            91             1            54            35   \n",
       "Actual KC            62             0            23           129   \n",
       "Actual CH            41             0             3            13   \n",
       "\n",
       "           Predicted CH  \n",
       "Actual FF             0  \n",
       "Actual FC             0  \n",
       "Actual SL             0  \n",
       "Actual KC             0  \n",
       "Actual CH             0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_svm.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 504 candidates, totalling 1512 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1481 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1512 out of 1512 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]CPU times: user 21 s, sys: 966 ms, total: 21.9 s\n",
      "Wall time: 10min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#L1 Regularization\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1'],\n",
    "    'loss': ['squared_hinge'],\n",
    "    'dual': [False],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    'C': [0.2, 0.5, 1.0, 2.0, 3.5, 5.0],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'max_iter': [50, 100, 250, 400, 700, 1200, 2000],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "l1_LinSVC = LinearSVC(random_state=42, verbose=50)\n",
    "\n",
    "l1_LinSVC_search = GridSearchCV(\n",
    "    estimator = l1_LinSVC, \n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    verbose=10,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# l1_LinSVC_search = RandomizedSearchCV(estimator=svm, param_distributions=param_grid, n_iter=500, \n",
    "#                             scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=4, verbose=10, \n",
    "#                             random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "\n",
    "l1_LinSVC_search.fit(X, y)\n",
    "l1_LinSVC_search_results = pd.DataFrame(l1_LinSVC_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9.079489</td>\n",
       "      <td>0.029625</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1200</td>\n",
       "      <td>l1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.380812</td>\n",
       "      <td>0.462309</td>\n",
       "      <td>0.419222</td>\n",
       "      <td>0.420774</td>\n",
       "      <td>0.033297</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573365</td>\n",
       "      <td>0.555228</td>\n",
       "      <td>0.574625</td>\n",
       "      <td>0.567739</td>\n",
       "      <td>0.008862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9.140771</td>\n",
       "      <td>0.075443</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1200</td>\n",
       "      <td>l1</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.380812</td>\n",
       "      <td>0.462309</td>\n",
       "      <td>0.419222</td>\n",
       "      <td>0.420774</td>\n",
       "      <td>0.033297</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573365</td>\n",
       "      <td>0.555228</td>\n",
       "      <td>0.574625</td>\n",
       "      <td>0.567739</td>\n",
       "      <td>0.008862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.532129</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>l1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.377281</td>\n",
       "      <td>0.464075</td>\n",
       "      <td>0.419222</td>\n",
       "      <td>0.420185</td>\n",
       "      <td>0.035449</td>\n",
       "      <td>3</td>\n",
       "      <td>0.573070</td>\n",
       "      <td>0.551988</td>\n",
       "      <td>0.572564</td>\n",
       "      <td>0.565874</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.537577</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>l1</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.377281</td>\n",
       "      <td>0.464075</td>\n",
       "      <td>0.419222</td>\n",
       "      <td>0.420185</td>\n",
       "      <td>0.035449</td>\n",
       "      <td>3</td>\n",
       "      <td>0.573070</td>\n",
       "      <td>0.551988</td>\n",
       "      <td>0.572564</td>\n",
       "      <td>0.565874</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.537219</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 0.2, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.377281</td>\n",
       "      <td>0.464075</td>\n",
       "      <td>0.419222</td>\n",
       "      <td>0.420185</td>\n",
       "      <td>0.035449</td>\n",
       "      <td>3</td>\n",
       "      <td>0.573070</td>\n",
       "      <td>0.551988</td>\n",
       "      <td>0.572564</td>\n",
       "      <td>0.565874</td>\n",
       "      <td>0.009821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "38       9.079489      0.029625         0.004162        0.000080     0.2   \n",
       "37       9.140771      0.075443         0.004114        0.000099     0.2   \n",
       "23       0.532129      0.002201         0.004059        0.000039     0.2   \n",
       "22       0.537577      0.002728         0.004065        0.000028     0.2   \n",
       "21       0.537219      0.005079         0.004081        0.000022     0.2   \n",
       "\n",
       "   param_class_weight param_dual param_fit_intercept     param_loss  \\\n",
       "38               None      False               False  squared_hinge   \n",
       "37               None      False               False  squared_hinge   \n",
       "23               None      False               False  squared_hinge   \n",
       "22               None      False               False  squared_hinge   \n",
       "21               None      False               False  squared_hinge   \n",
       "\n",
       "   param_max_iter param_penalty param_tol  \\\n",
       "38           1200            l1     1e-05   \n",
       "37           1200            l1     5e-05   \n",
       "23             50            l1     1e-05   \n",
       "22             50            l1     5e-05   \n",
       "21             50            l1    0.0001   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "38  {'C': 0.2, 'class_weight': None, 'dual': False...           0.380812   \n",
       "37  {'C': 0.2, 'class_weight': None, 'dual': False...           0.380812   \n",
       "23  {'C': 0.2, 'class_weight': None, 'dual': False...           0.377281   \n",
       "22  {'C': 0.2, 'class_weight': None, 'dual': False...           0.377281   \n",
       "21  {'C': 0.2, 'class_weight': None, 'dual': False...           0.377281   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "38           0.462309           0.419222         0.420774        0.033297   \n",
       "37           0.462309           0.419222         0.420774        0.033297   \n",
       "23           0.464075           0.419222         0.420185        0.035449   \n",
       "22           0.464075           0.419222         0.420185        0.035449   \n",
       "21           0.464075           0.419222         0.420185        0.035449   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "38                1            0.573365            0.555228   \n",
       "37                1            0.573365            0.555228   \n",
       "23                3            0.573070            0.551988   \n",
       "22                3            0.573070            0.551988   \n",
       "21                3            0.573070            0.551988   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "38            0.574625          0.567739         0.008862  \n",
       "37            0.574625          0.567739         0.008862  \n",
       "23            0.572564          0.565874         0.009821  \n",
       "22            0.572564          0.565874         0.009821  \n",
       "21            0.572564          0.565874         0.009821  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_LinSVC_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 27s, sys: 2.32 s, total: 3min 30s\n",
      "Wall time: 2min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_l1_LinSVC = get_top_n_models(l1_LinSVC_search_results, 'lin_SVC', k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FF       0.46      0.69      0.55       371\n",
      "          FC       0.25      0.10      0.14       201\n",
      "          SL       0.40      0.31      0.35       181\n",
      "          KC       0.49      0.49      0.49       214\n",
      "          CH       0.19      0.14      0.16        57\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      1024\n",
      "   macro avg       0.36      0.34      0.34      1024\n",
      "weighted avg       0.40      0.43      0.40      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted FF</th>\n",
       "      <th>Predicted FC</th>\n",
       "      <th>Predicted SL</th>\n",
       "      <th>Predicted KC</th>\n",
       "      <th>Predicted CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual FF</th>\n",
       "      <td>255</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>51</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual FC</th>\n",
       "      <td>134</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual SL</th>\n",
       "      <td>71</td>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual KC</th>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>104</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual CH</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted FF  Predicted FC  Predicted SL  Predicted KC  \\\n",
       "Actual FF           255            26            27            51   \n",
       "Actual FC           134            20            15            21   \n",
       "Actual SL            71            24            56            28   \n",
       "Actual KC            56             8            36           104   \n",
       "Actual CH            35             1             5             8   \n",
       "\n",
       "           Predicted CH  \n",
       "Actual FF            12  \n",
       "Actual FC            11  \n",
       "Actual SL             2  \n",
       "Actual KC            10  \n",
       "Actual CH             8  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_l1_LinSVC.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 216 is smaller than n_iter=250. Running 216 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 216 is smaller than n_iter=250. Running 216 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]CPU times: user 20.4 s, sys: 549 ms, total: 21 s\n",
      "Wall time: 6min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#L2 Regularization\n",
    "\n",
    "#The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l2'],#, 'l1'],\n",
    "    'loss': ['squared_hinge'],# 'hinge'],\n",
    "    'dual': [True],# False],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    'C': [0.2, 0.5, 1.0, 2.0, 3.5, 5.0],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'max_iter': [50, 100, 250, 400, 700, 1200],\n",
    "    'fit_intercept': [True]#, False]\n",
    "}\n",
    "\n",
    "l2_LinSVC = LinearSVC(random_state=42, verbose=50)\n",
    "\n",
    "# l2_LinSVC_search_A = GridSearchCV(\n",
    "#     estimator = l2_LinSVC, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=4,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "l2_LinSVC_search_A = RandomizedSearchCV(estimator=l2_LinSVC, param_distributions=param_grid, n_iter=250, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "l2_LinSVC_search_A.fit(X, y)\n",
    "l2_LinSVC_search_results_A = pd.DataFrame(l2_LinSVC_search_A.cv_results_).sort_values(by='rank_test_score')\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l2'],\n",
    "    'loss': ['hinge'],\n",
    "    'dual': [True],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    'C': [0.2, 0.5, 1.0, 2.0, 3.5, 5.0],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'max_iter': [50, 100, 250, 400, 700, 1200],\n",
    "    'fit_intercept': [True]#, False]\n",
    "}\n",
    "\n",
    "# l2_LinSVC_search_B = GridSearchCV(\n",
    "#     estimator = l2_LinSVC, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=4,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "l2_LinSVC_search_B = RandomizedSearchCV(estimator=l2_LinSVC, param_distributions=param_grid, n_iter=250, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "l2_LinSVC_search_B.fit(X, y)\n",
    "l2_LinSVC_search_results_B = pd.DataFrame(l2_LinSVC_search_B.cv_results_).sort_values(by='rank_test_score')\n",
    "\n",
    "\n",
    "l2_LinSVC_search_results = pd.concat([l2_LinSVC_search_results_A, l2_LinSVC_search_results_B]).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.022266</td>\n",
       "      <td>0.049634</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>400</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'tol': 0.0001, 'penalty': 'l2', 'max_iter': 4...</td>\n",
       "      <td>0.406121</td>\n",
       "      <td>0.432862</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.418025</td>\n",
       "      <td>0.011114</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561874</td>\n",
       "      <td>0.549632</td>\n",
       "      <td>0.529585</td>\n",
       "      <td>0.547030</td>\n",
       "      <td>0.013310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.975286</td>\n",
       "      <td>0.110265</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>l2</td>\n",
       "      <td>400</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'tol': 1e-05, 'penalty': 'l2', 'max_iter': 40...</td>\n",
       "      <td>0.406121</td>\n",
       "      <td>0.432862</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.418025</td>\n",
       "      <td>0.011114</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561874</td>\n",
       "      <td>0.549632</td>\n",
       "      <td>0.529585</td>\n",
       "      <td>0.547030</td>\n",
       "      <td>0.013310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.986700</td>\n",
       "      <td>0.073819</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>l2</td>\n",
       "      <td>400</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'tol': 5e-05, 'penalty': 'l2', 'max_iter': 40...</td>\n",
       "      <td>0.406121</td>\n",
       "      <td>0.432862</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.418025</td>\n",
       "      <td>0.011114</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561874</td>\n",
       "      <td>0.549632</td>\n",
       "      <td>0.529585</td>\n",
       "      <td>0.547030</td>\n",
       "      <td>0.013310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9.892938</td>\n",
       "      <td>0.239682</td>\n",
       "      <td>0.004656</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>l2</td>\n",
       "      <td>1200</td>\n",
       "      <td>hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'tol': 1e-05, 'penalty': 'l2', 'max_iter': 12...</td>\n",
       "      <td>0.371395</td>\n",
       "      <td>0.451119</td>\n",
       "      <td>0.425708</td>\n",
       "      <td>0.416061</td>\n",
       "      <td>0.033261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554803</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.548425</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.017788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9.882869</td>\n",
       "      <td>0.074493</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>l2</td>\n",
       "      <td>1200</td>\n",
       "      <td>hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'tol': 5e-05, 'penalty': 'l2', 'max_iter': 12...</td>\n",
       "      <td>0.371395</td>\n",
       "      <td>0.451119</td>\n",
       "      <td>0.425708</td>\n",
       "      <td>0.416061</td>\n",
       "      <td>0.033261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554803</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.548425</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.017788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_tol  \\\n",
       "27       4.022266      0.049634         0.004662        0.000077    0.0001   \n",
       "29       3.975286      0.110265         0.004726        0.000222     1e-05   \n",
       "28       3.986700      0.073819         0.004628        0.000071     5e-05   \n",
       "35       9.892938      0.239682         0.004656        0.000049     1e-05   \n",
       "34       9.882869      0.074493         0.004704        0.000038     5e-05   \n",
       "\n",
       "   param_penalty param_max_iter     param_loss param_fit_intercept param_dual  \\\n",
       "27            l2            400  squared_hinge                True       True   \n",
       "29            l2            400  squared_hinge                True       True   \n",
       "28            l2            400  squared_hinge                True       True   \n",
       "35            l2           1200          hinge                True       True   \n",
       "34            l2           1200          hinge                True       True   \n",
       "\n",
       "   param_class_weight param_C  \\\n",
       "27               None     0.2   \n",
       "29               None     0.2   \n",
       "28               None     0.2   \n",
       "35               None     0.2   \n",
       "34               None     0.2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "27  {'tol': 0.0001, 'penalty': 'l2', 'max_iter': 4...           0.406121   \n",
       "29  {'tol': 1e-05, 'penalty': 'l2', 'max_iter': 40...           0.406121   \n",
       "28  {'tol': 5e-05, 'penalty': 'l2', 'max_iter': 40...           0.406121   \n",
       "35  {'tol': 1e-05, 'penalty': 'l2', 'max_iter': 12...           0.371395   \n",
       "34  {'tol': 5e-05, 'penalty': 'l2', 'max_iter': 12...           0.371395   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "27           0.432862           0.415094         0.418025        0.011114   \n",
       "29           0.432862           0.415094         0.418025        0.011114   \n",
       "28           0.432862           0.415094         0.418025        0.011114   \n",
       "35           0.451119           0.425708         0.416061        0.033261   \n",
       "34           0.451119           0.425708         0.416061        0.033261   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "27                1            0.561874            0.549632   \n",
       "29                1            0.561874            0.549632   \n",
       "28                1            0.561874            0.549632   \n",
       "35                1            0.554803            0.514286   \n",
       "34                1            0.554803            0.514286   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "27            0.529585          0.547030         0.013310  \n",
       "29            0.529585          0.547030         0.013310  \n",
       "28            0.529585          0.547030         0.013310  \n",
       "35            0.548425          0.539171         0.017788  \n",
       "34            0.548425          0.539171         0.017788  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_LinSVC_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 17s, sys: 2.38 s, total: 3min 19s\n",
      "Wall time: 2min 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_l2_LinSVC = get_top_n_models(l2_LinSVC_search_results, 'lin_SVC', k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FF       0.45      0.68      0.54       371\n",
      "          FC       0.24      0.16      0.19       201\n",
      "          SL       0.38      0.27      0.31       181\n",
      "          KC       0.48      0.31      0.38       214\n",
      "          CH       0.09      0.09      0.09        57\n",
      "\n",
      "   micro avg       0.39      0.39      0.39      1024\n",
      "   macro avg       0.33      0.30      0.30      1024\n",
      "weighted avg       0.38      0.39      0.37      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted FF</th>\n",
       "      <th>Predicted FC</th>\n",
       "      <th>Predicted SL</th>\n",
       "      <th>Predicted KC</th>\n",
       "      <th>Predicted CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual FF</th>\n",
       "      <td>251</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual FC</th>\n",
       "      <td>130</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual SL</th>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual KC</th>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>67</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual CH</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted FF  Predicted FC  Predicted SL  Predicted KC  \\\n",
       "Actual FF           251            48            23            27   \n",
       "Actual FC           130            33            13            15   \n",
       "Actual SL            58            45            48            25   \n",
       "Actual KC            82            11            41            67   \n",
       "Actual CH            42             2             2             6   \n",
       "\n",
       "           Predicted CH  \n",
       "Actual FF            22  \n",
       "Actual FC            10  \n",
       "Actual SL             5  \n",
       "Actual KC            13  \n",
       "Actual CH             5  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_l2_LinSVC.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_accuracy_metrics(model, X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 48.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "-- Epoch 1\n",
      "Norm: 2.58, NNZs: 253, Bias: 1.121090, T: 5093, Avg. loss: 26.897463\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.81, NNZs: 253, Bias: 1.124985, T: 10186, Avg. loss: 2.478462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.47, NNZs: 253, Bias: 1.081564, T: 15279, Avg. loss: 1.444790\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.31, NNZs: 253, Bias: 1.065300, T: 20372, Avg. loss: 1.109424\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.22, NNZs: 253, Bias: 1.041011, T: 25465, Avg. loss: 0.941720\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.15, NNZs: 253, Bias: 1.035088, T: 30558, Avg. loss: 0.829169\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.09, NNZs: 253, Bias: 1.027378, T: 35651, Avg. loss: 0.774251\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.05, NNZs: 253, Bias: 1.019003, T: 40744, Avg. loss: 0.750951\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.02, NNZs: 253, Bias: 1.006399, T: 45837, Avg. loss: 0.723003\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.00, NNZs: 253, Bias: 1.001483, T: 50930, Avg. loss: 0.681376\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.99, NNZs: 253, Bias: 0.996407, T: 56023, Avg. loss: 0.677310\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.97, NNZs: 253, Bias: 0.991169, T: 61116, Avg. loss: 0.665426\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.96, NNZs: 253, Bias: 0.985558, T: 66209, Avg. loss: 0.655216\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.96, NNZs: 253, Bias: 0.979678, T: 71302, Avg. loss: 0.641508\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.95, NNZs: 253, Bias: 0.976029, T: 76395, Avg. loss: 0.639399\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.94, NNZs: 253, Bias: 0.970637, T: 81488, Avg. loss: 0.630520\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.93, NNZs: 253, Bias: 0.968737, T: 86581, Avg. loss: 0.627501\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.93, NNZs: 253, Bias: 0.964699, T: 91674, Avg. loss: 0.613125\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.92, NNZs: 253, Bias: 0.962685, T: 96767, Avg. loss: 0.613280\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.92, NNZs: 253, Bias: 0.958398, T: 101860, Avg. loss: 0.612004\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.91, NNZs: 253, Bias: 0.957427, T: 106953, Avg. loss: 0.611081\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.91, NNZs: 253, Bias: 0.953982, T: 112046, Avg. loss: 0.602655\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.91, NNZs: 253, Bias: 0.950854, T: 117139, Avg. loss: 0.598703\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.90, NNZs: 253, Bias: 0.950014, T: 122232, Avg. loss: 0.599025\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.90, NNZs: 253, Bias: 0.947038, T: 127325, Avg. loss: 0.600748\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.90, NNZs: 253, Bias: 0.943433, T: 132418, Avg. loss: 0.598747\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.90, NNZs: 253, Bias: 0.941066, T: 137511, Avg. loss: 0.600427\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.89, NNZs: 253, Bias: 0.939608, T: 142604, Avg. loss: 0.592518\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.89, NNZs: 253, Bias: 0.936077, T: 147697, Avg. loss: 0.592828\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.89, NNZs: 253, Bias: 0.933787, T: 152790, Avg. loss: 0.591616\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.89, NNZs: 253, Bias: 0.932071, T: 157883, Avg. loss: 0.594729\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.89, NNZs: 253, Bias: 0.930970, T: 162976, Avg. loss: 0.588948\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.89, NNZs: 253, Bias: 0.928358, T: 168069, Avg. loss: 0.589786\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.927242, T: 173162, Avg. loss: 0.588540\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.925758, T: 178255, Avg. loss: 0.587042\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.924198, T: 183348, Avg. loss: 0.584256\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.922574, T: 188441, Avg. loss: 0.586880\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.920557, T: 193534, Avg. loss: 0.587692\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.918598, T: 198627, Avg. loss: 0.584904\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.917092, T: 203720, Avg. loss: 0.581454\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.915597, T: 208813, Avg. loss: 0.586470\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.913880, T: 213906, Avg. loss: 0.583274\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.912736, T: 218999, Avg. loss: 0.583809\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.911296, T: 224092, Avg. loss: 0.581783\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.910209, T: 229185, Avg. loss: 0.580386\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.88, NNZs: 253, Bias: 0.908328, T: 234278, Avg. loss: 0.579131\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 253, Bias: 0.907328, T: 239371, Avg. loss: 0.580216\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.87, NNZs: 253, Bias: 0.906339, T: 244464, Avg. loss: 0.579676\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.87, NNZs: 253, Bias: 0.904526, T: 249557, Avg. loss: 0.580929\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.87, NNZs: 253, Bias: 0.903387, T: 254650, Avg. loss: 0.578816\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.87, NNZs: 253, Bias: 0.902129, T: 259743, Avg. loss: 0.576973\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.87, NNZs: 253, Bias: 0.901369, T: 264836, Avg. loss: 0.579067\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.87, NNZs: 253, Bias: 0.900518, T: 269929, Avg. loss: 0.578096\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.87, NNZs: 253, Bias: 0.899030, T: 275022, Avg. loss: 0.577728\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.87, NNZs: 253, Bias: 0.897876, T: 280115, Avg. loss: 0.577391\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.87, NNZs: 253, Bias: 0.896706, T: 285208, Avg. loss: 0.577673\n",
      "Total training time: 0.26 seconds.\n",
      "Convergence after 56 epochs took 0.26 seconds\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "-- Epoch 1\n",
      "Norm: 1.41, NNZs: 253, Bias: -0.217814, T: 5093, Avg. loss: 16.116201\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.10, NNZs: 253, Bias: -0.270793, T: 10186, Avg. loss: 1.701408\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.99, NNZs: 253, Bias: -0.278482, T: 15279, Avg. loss: 1.027432\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.91, NNZs: 253, Bias: -0.295028, T: 20372, Avg. loss: 0.810248\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.84, NNZs: 253, Bias: -0.289525, T: 25465, Avg. loss: 0.698880\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.81, NNZs: 253, Bias: -0.303254, T: 30558, Avg. loss: 0.622054\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.78, NNZs: 253, Bias: -0.307901, T: 35651, Avg. loss: 0.575523\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.75, NNZs: 253, Bias: -0.311173, T: 40744, Avg. loss: 0.558750\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.74, NNZs: 253, Bias: -0.316136, T: 45837, Avg. loss: 0.532007\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.72, NNZs: 253, Bias: -0.321139, T: 50930, Avg. loss: 0.522082\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.72, NNZs: 253, Bias: -0.324960, T: 56023, Avg. loss: 0.503492\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.71, NNZs: 253, Bias: -0.327223, T: 61116, Avg. loss: 0.499617\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.70, NNZs: 253, Bias: -0.331184, T: 66209, Avg. loss: 0.490041\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.69, NNZs: 253, Bias: -0.334278, T: 71302, Avg. loss: 0.486503\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.69, NNZs: 253, Bias: -0.336552, T: 76395, Avg. loss: 0.482545\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.68, NNZs: 253, Bias: -0.340762, T: 81488, Avg. loss: 0.476423\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.68, NNZs: 253, Bias: -0.342535, T: 86581, Avg. loss: 0.477476\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.68, NNZs: 253, Bias: -0.344230, T: 91674, Avg. loss: 0.469665\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.68, NNZs: 253, Bias: -0.346824, T: 96767, Avg. loss: 0.466185\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.68, NNZs: 253, Bias: -0.349445, T: 101860, Avg. loss: 0.465492\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.67, NNZs: 253, Bias: -0.351502, T: 106953, Avg. loss: 0.468655\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.67, NNZs: 253, Bias: -0.353199, T: 112046, Avg. loss: 0.460816\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.67, NNZs: 253, Bias: -0.354737, T: 117139, Avg. loss: 0.464467\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.67, NNZs: 253, Bias: -0.357222, T: 122232, Avg. loss: 0.462553\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.67, NNZs: 253, Bias: -0.358765, T: 127325, Avg. loss: 0.459130\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.66, NNZs: 253, Bias: -0.359796, T: 132418, Avg. loss: 0.456891\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.66, NNZs: 253, Bias: -0.362011, T: 137511, Avg. loss: 0.455850\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.66, NNZs: 253, Bias: -0.363663, T: 142604, Avg. loss: 0.453670\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.66, NNZs: 253, Bias: -0.364224, T: 147697, Avg. loss: 0.453895\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.66, NNZs: 253, Bias: -0.366161, T: 152790, Avg. loss: 0.453637\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.66, NNZs: 253, Bias: -0.367662, T: 157883, Avg. loss: 0.453833\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.66, NNZs: 253, Bias: -0.369139, T: 162976, Avg. loss: 0.451811\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.66, NNZs: 253, Bias: -0.369971, T: 168069, Avg. loss: 0.450965\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.66, NNZs: 253, Bias: -0.371355, T: 173162, Avg. loss: 0.451565\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 253, Bias: -0.371823, T: 178255, Avg. loss: 0.450535\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 253, Bias: -0.373381, T: 183348, Avg. loss: 0.450924\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 253, Bias: -0.374185, T: 188441, Avg. loss: 0.445985\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.65, NNZs: 253, Bias: -0.375152, T: 193534, Avg. loss: 0.446943\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.65, NNZs: 253, Bias: -0.376104, T: 198627, Avg. loss: 0.449049\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.65, NNZs: 253, Bias: -0.376881, T: 203720, Avg. loss: 0.447273\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.65, NNZs: 253, Bias: -0.378174, T: 208813, Avg. loss: 0.448636\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.65, NNZs: 253, Bias: -0.379337, T: 213906, Avg. loss: 0.447891\n",
      "Total training time: 0.19 seconds.\n",
      "Convergence after 42 epochs took 0.19 seconds\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "-- Epoch 1\n",
      "Norm: 2.49, NNZs: 253, Bias: -2.577933, T: 5093, Avg. loss: 16.734485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.82, NNZs: 253, Bias: -2.563409, T: 10186, Avg. loss: 1.257896\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.54, NNZs: 253, Bias: -2.550626, T: 15279, Avg. loss: 0.727824\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.38, NNZs: 253, Bias: -2.538501, T: 20372, Avg. loss: 0.577977\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.26, NNZs: 253, Bias: -2.541100, T: 25465, Avg. loss: 0.485556\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.19, NNZs: 253, Bias: -2.535824, T: 30558, Avg. loss: 0.440405\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.14, NNZs: 253, Bias: -2.534085, T: 35651, Avg. loss: 0.405282\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.10, NNZs: 253, Bias: -2.530853, T: 40744, Avg. loss: 0.394240\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 253, Bias: -2.527958, T: 45837, Avg. loss: 0.376899\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.05, NNZs: 253, Bias: -2.526026, T: 50930, Avg. loss: 0.361271\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.03, NNZs: 253, Bias: -2.525450, T: 56023, Avg. loss: 0.356080\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.01, NNZs: 253, Bias: -2.522857, T: 61116, Avg. loss: 0.351893\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.00, NNZs: 253, Bias: -2.523222, T: 66209, Avg. loss: 0.344522\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.99, NNZs: 253, Bias: -2.521805, T: 71302, Avg. loss: 0.340604\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.98, NNZs: 253, Bias: -2.519676, T: 76395, Avg. loss: 0.337279\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.98, NNZs: 253, Bias: -2.517477, T: 81488, Avg. loss: 0.336576\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.97, NNZs: 253, Bias: -2.518411, T: 86581, Avg. loss: 0.338841\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.96, NNZs: 253, Bias: -2.517098, T: 91674, Avg. loss: 0.330901\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 253, Bias: -2.516907, T: 96767, Avg. loss: 0.333148\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.95, NNZs: 253, Bias: -2.516196, T: 101860, Avg. loss: 0.328969\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.95, NNZs: 253, Bias: -2.515781, T: 106953, Avg. loss: 0.330079\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.94, NNZs: 253, Bias: -2.513979, T: 112046, Avg. loss: 0.325808\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.94, NNZs: 253, Bias: -2.513819, T: 117139, Avg. loss: 0.325608\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.93, NNZs: 253, Bias: -2.514149, T: 122232, Avg. loss: 0.328626\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.93, NNZs: 253, Bias: -2.513814, T: 127325, Avg. loss: 0.322783\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.93, NNZs: 253, Bias: -2.512843, T: 132418, Avg. loss: 0.322911\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.93, NNZs: 253, Bias: -2.512163, T: 137511, Avg. loss: 0.323672\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.93, NNZs: 253, Bias: -2.511490, T: 142604, Avg. loss: 0.322268\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.92, NNZs: 253, Bias: -2.511159, T: 147697, Avg. loss: 0.323632\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.92, NNZs: 253, Bias: -2.510749, T: 152790, Avg. loss: 0.321527\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.92, NNZs: 253, Bias: -2.510491, T: 157883, Avg. loss: 0.323199\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.92, NNZs: 253, Bias: -2.510491, T: 162976, Avg. loss: 0.319529\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.92, NNZs: 253, Bias: -2.510247, T: 168069, Avg. loss: 0.318992\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.92, NNZs: 253, Bias: -2.509713, T: 173162, Avg. loss: 0.320228\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.92, NNZs: 253, Bias: -2.509321, T: 178255, Avg. loss: 0.318963\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.92, NNZs: 253, Bias: -2.509017, T: 183348, Avg. loss: 0.317547\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.91, NNZs: 253, Bias: -2.508954, T: 188441, Avg. loss: 0.319425\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.91, NNZs: 253, Bias: -2.508746, T: 193534, Avg. loss: 0.317280\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 253, Bias: -2.508141, T: 198627, Avg. loss: 0.314832\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.91, NNZs: 253, Bias: -2.507744, T: 203720, Avg. loss: 0.316376\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.91, NNZs: 253, Bias: -2.507237, T: 208813, Avg. loss: 0.318063\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.91, NNZs: 253, Bias: -2.507008, T: 213906, Avg. loss: 0.316722\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.91, NNZs: 253, Bias: -2.506728, T: 218999, Avg. loss: 0.317541\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.91, NNZs: 253, Bias: -2.506394, T: 224092, Avg. loss: 0.316545\n",
      "Total training time: 0.20 seconds.\n",
      "Convergence after 44 epochs took 0.20 seconds\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n",
      "-- Epoch 1\n",
      "Norm: 2.55, NNZs: 253, Bias: -0.641377, T: 5093, Avg. loss: 19.990596\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.92, NNZs: 253, Bias: -0.664556, T: 10186, Avg. loss: 1.927503\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.61, NNZs: 253, Bias: -0.683277, T: 15279, Avg. loss: 1.192555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.46, NNZs: 253, Bias: -0.699362, T: 20372, Avg. loss: 0.908693\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.35, NNZs: 253, Bias: -0.701562, T: 25465, Avg. loss: 0.737410\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.26, NNZs: 253, Bias: -0.710906, T: 30558, Avg. loss: 0.660576\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.21, NNZs: 253, Bias: -0.718386, T: 35651, Avg. loss: 0.617995\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.16, NNZs: 253, Bias: -0.727468, T: 40744, Avg. loss: 0.582323\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.11, NNZs: 253, Bias: -0.730669, T: 45837, Avg. loss: 0.562086\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.09, NNZs: 253, Bias: -0.732248, T: 50930, Avg. loss: 0.545918\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.06, NNZs: 253, Bias: -0.737951, T: 56023, Avg. loss: 0.539474\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.05, NNZs: 253, Bias: -0.742790, T: 61116, Avg. loss: 0.528175\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.03, NNZs: 253, Bias: -0.744825, T: 66209, Avg. loss: 0.514282\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.02, NNZs: 253, Bias: -0.747842, T: 71302, Avg. loss: 0.509564\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.01, NNZs: 253, Bias: -0.750337, T: 76395, Avg. loss: 0.505951\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.00, NNZs: 253, Bias: -0.752105, T: 81488, Avg. loss: 0.498587\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.99, NNZs: 253, Bias: -0.755329, T: 86581, Avg. loss: 0.503826\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.99, NNZs: 253, Bias: -0.757143, T: 91674, Avg. loss: 0.494783\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.98, NNZs: 253, Bias: -0.758970, T: 96767, Avg. loss: 0.490651\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.98, NNZs: 253, Bias: -0.760964, T: 101860, Avg. loss: 0.490162\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.97, NNZs: 253, Bias: -0.763247, T: 106953, Avg. loss: 0.488043\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.97, NNZs: 253, Bias: -0.765032, T: 112046, Avg. loss: 0.487346\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.96, NNZs: 253, Bias: -0.766546, T: 117139, Avg. loss: 0.481795\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.96, NNZs: 253, Bias: -0.767929, T: 122232, Avg. loss: 0.479686\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.96, NNZs: 253, Bias: -0.769321, T: 127325, Avg. loss: 0.480724\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.95, NNZs: 253, Bias: -0.771220, T: 132418, Avg. loss: 0.481109\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.95, NNZs: 253, Bias: -0.772231, T: 137511, Avg. loss: 0.480732\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.95, NNZs: 253, Bias: -0.773842, T: 142604, Avg. loss: 0.472541\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.94, NNZs: 253, Bias: -0.775135, T: 147697, Avg. loss: 0.473827\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.94, NNZs: 253, Bias: -0.775829, T: 152790, Avg. loss: 0.472001\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.94, NNZs: 253, Bias: -0.776887, T: 157883, Avg. loss: 0.474272\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.94, NNZs: 253, Bias: -0.778254, T: 162976, Avg. loss: 0.471729\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.94, NNZs: 253, Bias: -0.779086, T: 168069, Avg. loss: 0.470402\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 253, Bias: -0.780759, T: 173162, Avg. loss: 0.472180\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 253, Bias: -0.782155, T: 178255, Avg. loss: 0.468810\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 253, Bias: -0.782919, T: 183348, Avg. loss: 0.467258\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.93, NNZs: 253, Bias: -0.783935, T: 188441, Avg. loss: 0.467081\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.93, NNZs: 253, Bias: -0.784490, T: 193534, Avg. loss: 0.466938\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.93, NNZs: 253, Bias: -0.785564, T: 198627, Avg. loss: 0.468409\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.93, NNZs: 253, Bias: -0.787058, T: 203720, Avg. loss: 0.466849\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.93, NNZs: 253, Bias: -0.787682, T: 208813, Avg. loss: 0.468331\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.92, NNZs: 253, Bias: -0.788349, T: 213906, Avg. loss: 0.465661\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.92, NNZs: 253, Bias: -0.789616, T: 218999, Avg. loss: 0.467637\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.92, NNZs: 253, Bias: -0.789758, T: 224092, Avg. loss: 0.464377\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.92, NNZs: 253, Bias: -0.790821, T: 229185, Avg. loss: 0.467376\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.92, NNZs: 253, Bias: -0.791505, T: 234278, Avg. loss: 0.464856\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.92, NNZs: 253, Bias: -0.792372, T: 239371, Avg. loss: 0.464342\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.92, NNZs: 253, Bias: -0.792649, T: 244464, Avg. loss: 0.464786\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.92, NNZs: 253, Bias: -0.793596, T: 249557, Avg. loss: 0.465472\n",
      "Total training time: 0.23 seconds.\n",
      "Convergence after 49 epochs took 0.23 seconds\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.9s remaining:    0.0s\n",
      "-- Epoch 1\n",
      "Norm: 1.55, NNZs: 253, Bias: -2.559818, T: 5093, Avg. loss: 7.393200\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.25, NNZs: 253, Bias: -2.590138, T: 10186, Avg. loss: 0.780056\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.06, NNZs: 253, Bias: -2.592046, T: 15279, Avg. loss: 0.468610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.97, NNZs: 253, Bias: -2.591917, T: 20372, Avg. loss: 0.379017\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.90, NNZs: 253, Bias: -2.595201, T: 25465, Avg. loss: 0.321818\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.86, NNZs: 253, Bias: -2.593138, T: 30558, Avg. loss: 0.291486\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.82, NNZs: 253, Bias: -2.597849, T: 35651, Avg. loss: 0.283465\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.79, NNZs: 253, Bias: -2.598673, T: 40744, Avg. loss: 0.273662\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.78, NNZs: 253, Bias: -2.596796, T: 45837, Avg. loss: 0.270437\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.76, NNZs: 253, Bias: -2.598512, T: 50930, Avg. loss: 0.261878\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.75, NNZs: 253, Bias: -2.598596, T: 56023, Avg. loss: 0.259511\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.74, NNZs: 253, Bias: -2.599859, T: 61116, Avg. loss: 0.257924\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.73, NNZs: 253, Bias: -2.599615, T: 66209, Avg. loss: 0.254508\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.73, NNZs: 253, Bias: -2.599917, T: 71302, Avg. loss: 0.251172\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.72, NNZs: 253, Bias: -2.600916, T: 76395, Avg. loss: 0.250060\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.71, NNZs: 253, Bias: -2.601389, T: 81488, Avg. loss: 0.247529\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.71, NNZs: 253, Bias: -2.601056, T: 86581, Avg. loss: 0.246080\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.71, NNZs: 253, Bias: -2.601867, T: 91674, Avg. loss: 0.246251\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.70, NNZs: 253, Bias: -2.602305, T: 96767, Avg. loss: 0.244917\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.70, NNZs: 253, Bias: -2.602070, T: 101860, Avg. loss: 0.244277\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.70, NNZs: 253, Bias: -2.603192, T: 106953, Avg. loss: 0.241314\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.70, NNZs: 253, Bias: -2.604301, T: 112046, Avg. loss: 0.241327\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.604727, T: 117139, Avg. loss: 0.242542\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.604818, T: 122232, Avg. loss: 0.239965\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.605166, T: 127325, Avg. loss: 0.240352\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.605362, T: 132418, Avg. loss: 0.239276\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.605706, T: 137511, Avg. loss: 0.239237\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.606061, T: 142604, Avg. loss: 0.237966\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.605959, T: 147697, Avg. loss: 0.239396\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.606342, T: 152790, Avg. loss: 0.238278\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.606428, T: 157883, Avg. loss: 0.238180\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.606782, T: 162976, Avg. loss: 0.235669\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.69, NNZs: 253, Bias: -2.606881, T: 168069, Avg. loss: 0.236572\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.68, NNZs: 253, Bias: -2.607373, T: 173162, Avg. loss: 0.237313\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.68, NNZs: 253, Bias: -2.607715, T: 178255, Avg. loss: 0.235355\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.68, NNZs: 253, Bias: -2.608072, T: 183348, Avg. loss: 0.233901\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.68, NNZs: 253, Bias: -2.608193, T: 188441, Avg. loss: 0.235212\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.68, NNZs: 253, Bias: -2.608338, T: 193534, Avg. loss: 0.235432\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.68, NNZs: 253, Bias: -2.608837, T: 198627, Avg. loss: 0.237424\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.68, NNZs: 253, Bias: -2.608812, T: 203720, Avg. loss: 0.236193\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.68, NNZs: 253, Bias: -2.609517, T: 208813, Avg. loss: 0.236905\n",
      "Total training time: 0.19 seconds.\n",
      "Convergence after 41 epochs took 0.19 seconds\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "CPU times: user 5.84 s, sys: 289 ms, total: 6.13 s\n",
      "Wall time: 48min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.02, .05, 0.1],\n",
    "    'loss': ['log', 'hinge', 'squared_hinge'],# 'modified_huber', 'perceptron'],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'max_iter': [1000, 3000, 5000, 10000, 20000, 40000, 100000, 200000],\n",
    "    'fit_intercept': [True, False],\n",
    "    'warm_start': [True, False],\n",
    "    'learning_rate': ['optimal'],\n",
    "    'shuffle':[True, False]\n",
    "}\n",
    "\n",
    "sgd = SGDClassifier(random_state=42, verbose=50)\n",
    "\n",
    "# search = GridSearchCV(\n",
    "#     estimator = sgd, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=4,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "\n",
    "sgd_search = RandomizedSearchCV(estimator=sgd, param_distributions=param_grid, n_iter=200, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "sgd_search.fit(X, y)\n",
    "\n",
    "sgd_search_results = pd.DataFrame(sgd_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_warm_start</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_shuffle</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.488549</td>\n",
       "      <td>0.048060</td>\n",
       "      <td>0.005648</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>20000</td>\n",
       "      <td>log</td>\n",
       "      <td>optimal</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'warm_start': True, 'tol': 0.0001, 'shuffle':...</td>\n",
       "      <td>0.443202</td>\n",
       "      <td>0.475265</td>\n",
       "      <td>0.443396</td>\n",
       "      <td>0.453956</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517089</td>\n",
       "      <td>0.492784</td>\n",
       "      <td>0.520754</td>\n",
       "      <td>0.510209</td>\n",
       "      <td>0.012412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.563821</td>\n",
       "      <td>0.045572</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>40000</td>\n",
       "      <td>log</td>\n",
       "      <td>optimal</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'warm_start': False, 'tol': 0.0001, 'shuffle'...</td>\n",
       "      <td>0.443202</td>\n",
       "      <td>0.475265</td>\n",
       "      <td>0.443396</td>\n",
       "      <td>0.453956</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517089</td>\n",
       "      <td>0.492784</td>\n",
       "      <td>0.520754</td>\n",
       "      <td>0.510209</td>\n",
       "      <td>0.012412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.060052</td>\n",
       "      <td>0.045013</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>100000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>optimal</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'warm_start': False, 'tol': 1e-05, 'shuffle':...</td>\n",
       "      <td>0.442613</td>\n",
       "      <td>0.476443</td>\n",
       "      <td>0.410377</td>\n",
       "      <td>0.443157</td>\n",
       "      <td>0.026969</td>\n",
       "      <td>3</td>\n",
       "      <td>0.516794</td>\n",
       "      <td>0.499853</td>\n",
       "      <td>0.491021</td>\n",
       "      <td>0.502556</td>\n",
       "      <td>0.010694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2.065994</td>\n",
       "      <td>0.375096</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>40000</td>\n",
       "      <td>log</td>\n",
       "      <td>optimal</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'warm_start': False, 'tol': 0.0001, 'shuffle'...</td>\n",
       "      <td>0.424956</td>\n",
       "      <td>0.466431</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.441783</td>\n",
       "      <td>0.017815</td>\n",
       "      <td>4</td>\n",
       "      <td>0.464643</td>\n",
       "      <td>0.449190</td>\n",
       "      <td>0.511334</td>\n",
       "      <td>0.475056</td>\n",
       "      <td>0.026417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.093490</td>\n",
       "      <td>0.384122</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>40000</td>\n",
       "      <td>log</td>\n",
       "      <td>optimal</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'warm_start': True, 'tol': 0.0001, 'shuffle':...</td>\n",
       "      <td>0.452031</td>\n",
       "      <td>0.458775</td>\n",
       "      <td>0.402123</td>\n",
       "      <td>0.437660</td>\n",
       "      <td>0.025260</td>\n",
       "      <td>5</td>\n",
       "      <td>0.499705</td>\n",
       "      <td>0.482180</td>\n",
       "      <td>0.463056</td>\n",
       "      <td>0.481647</td>\n",
       "      <td>0.014967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "32        1.488549      0.048060         0.005648        0.000081   \n",
       "71        1.563821      0.045572         0.005891        0.000140   \n",
       "189       1.060052      0.045013         0.005548        0.000056   \n",
       "151       2.065994      0.375096         0.005789        0.000080   \n",
       "1         2.093490      0.384122         0.005795        0.000181   \n",
       "\n",
       "    param_warm_start param_tol param_shuffle param_penalty param_max_iter  \\\n",
       "32              True    0.0001          True            l2          20000   \n",
       "71             False    0.0001          True            l2          40000   \n",
       "189            False     1e-05          True            l2         100000   \n",
       "151            False    0.0001          True    elasticnet          40000   \n",
       "1               True    0.0001          True    elasticnet          40000   \n",
       "\n",
       "    param_loss param_learning_rate param_fit_intercept param_class_weight  \\\n",
       "32         log             optimal                True               None   \n",
       "71         log             optimal                True               None   \n",
       "189      hinge             optimal               False               None   \n",
       "151        log             optimal                True               None   \n",
       "1          log             optimal                True               None   \n",
       "\n",
       "    param_alpha                                             params  \\\n",
       "32         0.05  {'warm_start': True, 'tol': 0.0001, 'shuffle':...   \n",
       "71         0.05  {'warm_start': False, 'tol': 0.0001, 'shuffle'...   \n",
       "189         0.1  {'warm_start': False, 'tol': 1e-05, 'shuffle':...   \n",
       "151        0.05  {'warm_start': False, 'tol': 0.0001, 'shuffle'...   \n",
       "1          0.02  {'warm_start': True, 'tol': 0.0001, 'shuffle':...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "32            0.443202           0.475265           0.443396         0.453956   \n",
       "71            0.443202           0.475265           0.443396         0.453956   \n",
       "189           0.442613           0.476443           0.410377         0.443157   \n",
       "151           0.424956           0.466431           0.433962         0.441783   \n",
       "1             0.452031           0.458775           0.402123         0.437660   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "32         0.015070                1            0.517089            0.492784   \n",
       "71         0.015070                1            0.517089            0.492784   \n",
       "189        0.026969                3            0.516794            0.499853   \n",
       "151        0.017815                4            0.464643            0.449190   \n",
       "1          0.025260                5            0.499705            0.482180   \n",
       "\n",
       "     split2_train_score  mean_train_score  std_train_score  \n",
       "32             0.520754          0.510209         0.012412  \n",
       "71             0.520754          0.510209         0.012412  \n",
       "189            0.491021          0.502556         0.010694  \n",
       "151            0.511334          0.475056         0.026417  \n",
       "1              0.463056          0.481647         0.014967  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 2.6 s, total: 1min 24s\n",
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_sgd = get_top_n_models(sgd_search_results, 'sgd', k=30, accuracy_metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.05, average=False, class...</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.321193</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.497735</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.05, average=False, class...</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.321193</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.497735</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.02, average=False, class...</td>\n",
       "      <td>0.442383</td>\n",
       "      <td>0.350308</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.388153</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.02, average=False, class...</td>\n",
       "      <td>0.439453</td>\n",
       "      <td>0.340264</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.427970</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.02, average=False, class...</td>\n",
       "      <td>0.439453</td>\n",
       "      <td>0.340264</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.427970</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.02, average=False, class...</td>\n",
       "      <td>0.438477</td>\n",
       "      <td>0.344896</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.389514</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.1, average=False, class_...</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>0.308018</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.581112</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.05, average=False, class...</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>0.350818</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.622971</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.1, average=False, class_...</td>\n",
       "      <td>0.424805</td>\n",
       "      <td>0.306374</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.376582</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.345999</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-0.727449</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy  \\\n",
       "0  SGDClassifier(alpha=0.05, average=False, class...  0.445312   \n",
       "0  SGDClassifier(alpha=0.05, average=False, class...  0.445312   \n",
       "0  SGDClassifier(alpha=0.02, average=False, class...  0.442383   \n",
       "0  SGDClassifier(alpha=0.02, average=False, class...  0.439453   \n",
       "0  SGDClassifier(alpha=0.02, average=False, class...  0.439453   \n",
       "0  SGDClassifier(alpha=0.02, average=False, class...  0.438477   \n",
       "0  SGDClassifier(alpha=0.1, average=False, class_...  0.433594   \n",
       "0  SGDClassifier(alpha=0.05, average=False, class...  0.427734   \n",
       "0  SGDClassifier(alpha=0.1, average=False, class_...  0.424805   \n",
       "0  SGDClassifier(alpha=0.001, average=False, clas...  0.421875   \n",
       "\n",
       "   balanced_accuracy f1_score  r2_score roc_auc_score     model_type  \n",
       "0           0.321193      N/A -0.497735           N/A  SGDClassifier  \n",
       "0           0.321193      N/A -0.497735           N/A  SGDClassifier  \n",
       "0           0.350308      N/A -0.388153           N/A  SGDClassifier  \n",
       "0           0.340264      N/A -0.427970           N/A  SGDClassifier  \n",
       "0           0.340264      N/A -0.427970           N/A  SGDClassifier  \n",
       "0           0.344896      N/A -0.389514           N/A  SGDClassifier  \n",
       "0           0.308018      N/A -0.581112           N/A  SGDClassifier  \n",
       "0           0.350818      N/A -0.622971           N/A  SGDClassifier  \n",
       "0           0.306374      N/A -0.376582           N/A  SGDClassifier  \n",
       "0           0.345999      N/A -0.727449           N/A  SGDClassifier  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FF       0.42      0.78      0.55       371\n",
      "          FC       0.00      0.00      0.00       201\n",
      "          SL       0.45      0.29      0.36       181\n",
      "          KC       0.51      0.50      0.51       214\n",
      "          CH       0.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      1024\n",
      "   macro avg       0.28      0.32      0.28      1024\n",
      "weighted avg       0.34      0.44      0.37      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted FF</th>\n",
       "      <th>Predicted FC</th>\n",
       "      <th>Predicted SL</th>\n",
       "      <th>Predicted KC</th>\n",
       "      <th>Predicted CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual FF</th>\n",
       "      <td>289</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual FC</th>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual SL</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual KC</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual CH</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted FF  Predicted FC  Predicted SL  Predicted KC  \\\n",
       "Actual FF           289             5            26            50   \n",
       "Actual FC           166             0            11            21   \n",
       "Actual SL           100             2            53            26   \n",
       "Actual KC            80             1            24           108   \n",
       "Actual CH            46             0             3             8   \n",
       "\n",
       "           Predicted CH  \n",
       "Actual FF             1  \n",
       "Actual FC             3  \n",
       "Actual SL             0  \n",
       "Actual KC             1  \n",
       "Actual CH             0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = search.best_estimator_\n",
    "model = top10_sgd.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 60 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:   11.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "param_grid = {\n",
    "    'solver': ['lsqr'],#, 'eigen'],\n",
    "    'shrinkage': [None, 'auto', 0.1, 0.5],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    'n_components':[None, 25, 50, 75, 100],\n",
    "    #'store_covariance': [True, False]\n",
    "}\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda_search = GridSearchCV(\n",
    "    estimator = lda, \n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=8,\n",
    "    verbose=10,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "lda_search.fit(X, y)\n",
    "\n",
    "lda_search_results = pd.DataFrame(lda_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_components</th>\n",
       "      <th>param_shrinkage</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.277161</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'n_components': 75, 'shrinkage': 0.1, 'solver...</td>\n",
       "      <td>0.425665</td>\n",
       "      <td>0.488263</td>\n",
       "      <td>0.492138</td>\n",
       "      <td>0.498428</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0.446541</td>\n",
       "      <td>0.413522</td>\n",
       "      <td>0.464567</td>\n",
       "      <td>0.46181</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516614</td>\n",
       "      <td>0.504266</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.505721</td>\n",
       "      <td>0.508414</td>\n",
       "      <td>0.514023</td>\n",
       "      <td>0.508973</td>\n",
       "      <td>0.508626</td>\n",
       "      <td>0.004209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.273771</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'n_components': 25, 'shrinkage': 0.1, 'solver...</td>\n",
       "      <td>0.425665</td>\n",
       "      <td>0.488263</td>\n",
       "      <td>0.492138</td>\n",
       "      <td>0.498428</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0.446541</td>\n",
       "      <td>0.413522</td>\n",
       "      <td>0.464567</td>\n",
       "      <td>0.46181</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516614</td>\n",
       "      <td>0.504266</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.505721</td>\n",
       "      <td>0.508414</td>\n",
       "      <td>0.514023</td>\n",
       "      <td>0.508973</td>\n",
       "      <td>0.508626</td>\n",
       "      <td>0.004209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.269106</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>{'n_components': 75, 'shrinkage': 0.1, 'solver...</td>\n",
       "      <td>0.425665</td>\n",
       "      <td>0.488263</td>\n",
       "      <td>0.492138</td>\n",
       "      <td>0.498428</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0.446541</td>\n",
       "      <td>0.413522</td>\n",
       "      <td>0.464567</td>\n",
       "      <td>0.46181</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516614</td>\n",
       "      <td>0.504266</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.505721</td>\n",
       "      <td>0.508414</td>\n",
       "      <td>0.514023</td>\n",
       "      <td>0.508973</td>\n",
       "      <td>0.508626</td>\n",
       "      <td>0.004209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.278989</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'n_components': 75, 'shrinkage': 0.1, 'solver...</td>\n",
       "      <td>0.425665</td>\n",
       "      <td>0.488263</td>\n",
       "      <td>0.492138</td>\n",
       "      <td>0.498428</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0.446541</td>\n",
       "      <td>0.413522</td>\n",
       "      <td>0.464567</td>\n",
       "      <td>0.46181</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516614</td>\n",
       "      <td>0.504266</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.505721</td>\n",
       "      <td>0.508414</td>\n",
       "      <td>0.514023</td>\n",
       "      <td>0.508973</td>\n",
       "      <td>0.508626</td>\n",
       "      <td>0.004209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.278465</td>\n",
       "      <td>0.011242</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'n_components': 50, 'shrinkage': 0.1, 'solver...</td>\n",
       "      <td>0.425665</td>\n",
       "      <td>0.488263</td>\n",
       "      <td>0.492138</td>\n",
       "      <td>0.498428</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0.446541</td>\n",
       "      <td>0.413522</td>\n",
       "      <td>0.464567</td>\n",
       "      <td>0.46181</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516614</td>\n",
       "      <td>0.504266</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.505721</td>\n",
       "      <td>0.508414</td>\n",
       "      <td>0.514023</td>\n",
       "      <td>0.508973</td>\n",
       "      <td>0.508626</td>\n",
       "      <td>0.004209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "44       0.277161      0.002804         0.003063        0.000266   \n",
       "20       0.273771      0.006070         0.002852        0.000417   \n",
       "43       0.269106      0.004511         0.002886        0.000248   \n",
       "42       0.278989      0.004383         0.003017        0.000306   \n",
       "30       0.278465      0.011242         0.002969        0.000173   \n",
       "\n",
       "   param_n_components param_shrinkage param_solver param_tol  \\\n",
       "44                 75             0.1         lsqr     1e-05   \n",
       "20                 25             0.1         lsqr     1e-05   \n",
       "43                 75             0.1         lsqr     5e-05   \n",
       "42                 75             0.1         lsqr    0.0001   \n",
       "30                 50             0.1         lsqr    0.0001   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "44  {'n_components': 75, 'shrinkage': 0.1, 'solver...           0.425665   \n",
       "20  {'n_components': 25, 'shrinkage': 0.1, 'solver...           0.425665   \n",
       "43  {'n_components': 75, 'shrinkage': 0.1, 'solver...           0.425665   \n",
       "42  {'n_components': 75, 'shrinkage': 0.1, 'solver...           0.425665   \n",
       "30  {'n_components': 50, 'shrinkage': 0.1, 'solver...           0.425665   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "44           0.488263           0.492138           0.498428   \n",
       "20           0.488263           0.492138           0.498428   \n",
       "43           0.488263           0.492138           0.498428   \n",
       "42           0.488263           0.492138           0.498428   \n",
       "30           0.488263           0.492138           0.498428   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "44           0.465409           0.446541           0.413522   \n",
       "20           0.465409           0.446541           0.413522   \n",
       "43           0.465409           0.446541           0.413522   \n",
       "42           0.465409           0.446541           0.413522   \n",
       "30           0.465409           0.446541           0.413522   \n",
       "\n",
       "    split7_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "44           0.464567          0.46181        0.029272                1   \n",
       "20           0.464567          0.46181        0.029272                1   \n",
       "43           0.464567          0.46181        0.029272                1   \n",
       "42           0.464567          0.46181        0.029272                1   \n",
       "30           0.464567          0.46181        0.029272                1   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "44            0.516614            0.504266            0.506394   \n",
       "20            0.516614            0.504266            0.506394   \n",
       "43            0.516614            0.504266            0.506394   \n",
       "42            0.516614            0.504266            0.506394   \n",
       "30            0.516614            0.504266            0.506394   \n",
       "\n",
       "    split3_train_score  split4_train_score  split5_train_score  \\\n",
       "44              0.5046            0.505721            0.508414   \n",
       "20              0.5046            0.505721            0.508414   \n",
       "43              0.5046            0.505721            0.508414   \n",
       "42              0.5046            0.505721            0.508414   \n",
       "30              0.5046            0.505721            0.508414   \n",
       "\n",
       "    split6_train_score  split7_train_score  mean_train_score  std_train_score  \n",
       "44            0.514023            0.508973          0.508626         0.004209  \n",
       "20            0.514023            0.508973          0.508626         0.004209  \n",
       "43            0.514023            0.508973          0.508626         0.004209  \n",
       "42            0.514023            0.508973          0.508626         0.004209  \n",
       "30            0.514023            0.508973          0.508626         0.004209  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 3.02 s, total: 1min 7s\n",
      "Wall time: 8.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_lda = get_top_n_models(lda_search_results, 'lda', k=60)\n",
    "top10_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FF       0.45      0.73      0.55       371\n",
      "          FC       0.27      0.04      0.07       201\n",
      "          SL       0.47      0.31      0.37       181\n",
      "          KC       0.47      0.52      0.50       214\n",
      "          CH       0.11      0.07      0.09        57\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      1024\n",
      "   macro avg       0.35      0.33      0.32      1024\n",
      "weighted avg       0.40      0.44      0.39      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted FF</th>\n",
       "      <th>Predicted FC</th>\n",
       "      <th>Predicted SL</th>\n",
       "      <th>Predicted KC</th>\n",
       "      <th>Predicted CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual FF</th>\n",
       "      <td>270</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual FC</th>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual SL</th>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual KC</th>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>112</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual CH</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted FF  Predicted FC  Predicted SL  Predicted KC  \\\n",
       "Actual FF           270            12            23            54   \n",
       "Actual FC           150             8            11            25   \n",
       "Actual SL            83             8            56            33   \n",
       "Actual KC            62             2            27           112   \n",
       "Actual CH            38             0             3            12   \n",
       "\n",
       "           Predicted CH  \n",
       "Actual FF            12  \n",
       "Actual FC             7  \n",
       "Actual SL             1  \n",
       "Actual KC            11  \n",
       "Actual CH             4  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = top10_lda.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed: 20.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 s, sys: 155 ms, total: 3.4 s\n",
      "Wall time: 24min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed: 24.7min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 4, 5, 6, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [10, 20, 30, 40, 50],\n",
    "    'p': [1,2,3]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# search = GridSearchCV(\n",
    "#     estimator = knn, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=4,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "\n",
    "knn_search = RandomizedSearchCV(estimator=knn, param_distributions=param_grid, n_iter=150, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "knn_search.fit(X, y)\n",
    "\n",
    "knn_search_results = pd.DataFrame(knn_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>param_p</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_leaf_size</th>\n",
       "      <th>param_algorithm</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.065308</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>2.762503</td>\n",
       "      <td>0.075232</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.400235</td>\n",
       "      <td>0.388104</td>\n",
       "      <td>0.362028</td>\n",
       "      <td>0.383468</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601945</td>\n",
       "      <td>0.580265</td>\n",
       "      <td>0.557845</td>\n",
       "      <td>0.580018</td>\n",
       "      <td>0.018004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.052698</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>1.984219</td>\n",
       "      <td>0.108632</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.400235</td>\n",
       "      <td>0.388104</td>\n",
       "      <td>0.362028</td>\n",
       "      <td>0.383468</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601945</td>\n",
       "      <td>0.580265</td>\n",
       "      <td>0.557845</td>\n",
       "      <td>0.580018</td>\n",
       "      <td>0.018004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.013361</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>1.034954</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.400235</td>\n",
       "      <td>0.388104</td>\n",
       "      <td>0.362028</td>\n",
       "      <td>0.383468</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601945</td>\n",
       "      <td>0.580265</td>\n",
       "      <td>0.557845</td>\n",
       "      <td>0.580018</td>\n",
       "      <td>0.018004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.048941</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>2.624460</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.400235</td>\n",
       "      <td>0.391637</td>\n",
       "      <td>0.355542</td>\n",
       "      <td>0.382486</td>\n",
       "      <td>0.019359</td>\n",
       "      <td>4</td>\n",
       "      <td>0.591927</td>\n",
       "      <td>0.574669</td>\n",
       "      <td>0.559611</td>\n",
       "      <td>0.575402</td>\n",
       "      <td>0.013203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.053774</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>2.630787</td>\n",
       "      <td>0.009865</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.400235</td>\n",
       "      <td>0.391637</td>\n",
       "      <td>0.355542</td>\n",
       "      <td>0.382486</td>\n",
       "      <td>0.019359</td>\n",
       "      <td>4</td>\n",
       "      <td>0.591927</td>\n",
       "      <td>0.574669</td>\n",
       "      <td>0.559611</td>\n",
       "      <td>0.575402</td>\n",
       "      <td>0.013203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8         0.065308      0.001426         2.762503        0.075232   \n",
       "96        0.052698      0.003660         1.984219        0.108632   \n",
       "13        0.013361      0.001586         1.034954        0.027797   \n",
       "130       0.048941      0.003506         2.624460        0.008167   \n",
       "109       0.053774      0.000873         2.630787        0.009865   \n",
       "\n",
       "    param_weights param_p param_n_neighbors param_leaf_size param_algorithm  \\\n",
       "8         uniform       1                 6              30            auto   \n",
       "96        uniform       1                 6              30       ball_tree   \n",
       "13        uniform       1                 6              50           brute   \n",
       "130       uniform       1                 7              30            auto   \n",
       "109       uniform       1                 7              40         kd_tree   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "8    {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.400235   \n",
       "96   {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.400235   \n",
       "13   {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.400235   \n",
       "130  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.400235   \n",
       "109  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.400235   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "8             0.388104           0.362028         0.383468        0.015938   \n",
       "96            0.388104           0.362028         0.383468        0.015938   \n",
       "13            0.388104           0.362028         0.383468        0.015938   \n",
       "130           0.391637           0.355542         0.382486        0.019359   \n",
       "109           0.391637           0.355542         0.382486        0.019359   \n",
       "\n",
       "     rank_test_score  split0_train_score  split1_train_score  \\\n",
       "8                  1            0.601945            0.580265   \n",
       "96                 1            0.601945            0.580265   \n",
       "13                 1            0.601945            0.580265   \n",
       "130                4            0.591927            0.574669   \n",
       "109                4            0.591927            0.574669   \n",
       "\n",
       "     split2_train_score  mean_train_score  std_train_score  \n",
       "8              0.557845          0.580018         0.018004  \n",
       "96             0.557845          0.580018         0.018004  \n",
       "13             0.557845          0.580018         0.018004  \n",
       "130            0.559611          0.575402         0.013203  \n",
       "109            0.559611          0.575402         0.013203  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 s, sys: 412 ms, total: 53.7 s\n",
      "Wall time: 53.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top10_knn = get_top_n_models(knn_search_results, 'knn', k=20)\n",
    "top10_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FF       0.45      0.71      0.55       371\n",
      "          FC       0.25      0.16      0.20       201\n",
      "          SL       0.35      0.15      0.21       181\n",
      "          KC       0.46      0.43      0.45       214\n",
      "          CH       0.18      0.09      0.12        57\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      1024\n",
      "   macro avg       0.34      0.31      0.31      1024\n",
      "weighted avg       0.38      0.41      0.38      1024\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted FF</th>\n",
       "      <th>Predicted FC</th>\n",
       "      <th>Predicted SL</th>\n",
       "      <th>Predicted KC</th>\n",
       "      <th>Predicted CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual FF</th>\n",
       "      <td>263</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual FC</th>\n",
       "      <td>128</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual SL</th>\n",
       "      <td>85</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual KC</th>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual CH</th>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted FF  Predicted FC  Predicted SL  Predicted KC  \\\n",
       "Actual FF           263            35            15            49   \n",
       "Actual FC           128            33             7            26   \n",
       "Actual SL            85            36            28            28   \n",
       "Actual KC            72            18            28            93   \n",
       "Actual CH            34             8             3             7   \n",
       "\n",
       "           Predicted CH  \n",
       "Actual FF             9  \n",
       "Actual FC             7  \n",
       "Actual SL             4  \n",
       "Actual KC             3  \n",
       "Actual CH             5  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = top10_knn.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  3.8min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l2'],\n",
    "    'dual': [False],\n",
    "    'tol': [0.0001, 0.00005, 0.00001],\n",
    "    'C': [0.2, 0.5, 1.0, 2.0, 3.5, 5.0],\n",
    "    'fit_intercept': [True, False], \n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'solver': ['liblinear', 'newton-cg', 'lbfgs'],\n",
    "    'max_iter': [1000, 3000, 5000, 10000, 20000, 40000, 100000],\n",
    "    'multi_class': ['ovr', 'auto'], \n",
    "    'warm_start': [True, False]\n",
    "    \n",
    "}\n",
    "\n",
    "lr = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "\n",
    "# search = GridSearchCV(\n",
    "#     estimator = knn, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=4,\n",
    "#     verbose=10,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "\n",
    "lr_search = RandomizedSearchCV(estimator=lr, param_distributions=param_grid, n_iter=150, \n",
    "                            scoring='accuracy', n_jobs=-1, iid='warn', refit=True, cv=3, verbose=10, \n",
    "                            random_state=42, error_score='raise-deprecating', return_train_score=True)\n",
    "\n",
    "lr_search.fit(X, y)\n",
    "\n",
    "lr_search_results = pd.DataFrame(lr_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_search_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top10_lr = get_top_n_models(lr_search_results, 'lr', k=20)\n",
    "top10_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = top10_lr.model.values[0]\n",
    "con_matrix_analysis(model, X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the top10s into one df and save to pickle file\n",
    "\n",
    "best_models = pd.concat([top10_rfc_bootstrap, top10_rfc_without_bootstrap, top10_xgb, top10_svm, top10_l1_LinSVC, top10_l2_LinSVC,\n",
    "                         top10_sgd, top10_lda, top10_knn, top10_lr], sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_models.to_pickle(path=(pitcher+'_ordinal_multiclass_best_models_v1.pkl'),compression='zip')\n",
    "\n",
    "best_models.to_pickle(path=(pitcher+'_onehot_multiclass_best_models_v1.pkl'),compression='zip')\n",
    "\n",
    "# best_models.to_pickle(path=(pitcher+'_onehot_pca_multiclass_best_models_v1.pkl'),compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_pickle(pitcher+'multiclass_best_models_v1.pkl', compression='zip')\n",
    "# test.sort_values(by='accuracy', ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
